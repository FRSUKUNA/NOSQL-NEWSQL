import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
from typing import Dict, List, Optional

# Configuration des en-tÃªtes pour les requÃªtes HTTP
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def get_page_content(url, page_type):
    """RÃ©cupÃ¨re le contenu d'une page spÃ©cifique de la documentation Redis."""
    try:
        print(f"RÃ©cupÃ©ration de la page: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # RÃ©cupÃ©rer le contenu principal de la page
        content = soup.find('main') or soup.find('article') or soup.find('div', class_='content')
        if not content:
            print(f"Contenu principal non trouvÃ© pour {url}")
            return []
            
        # Extraire les sections pertinentes
        sections = []
        current_section = {'title': 'Introduction', 'content': []}
        
        for element in content.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'ul', 'ol', 'pre']):
            if element.name in ['h1', 'h2', 'h3', 'h4']:
                # Sauvegarder la section prÃ©cÃ©dente
                if current_section['content']:
                    sections.append(current_section)
                # Commencer une nouvelle section
                current_section = {
                    'title': element.get_text(strip=True),
                    'content': []
                }
            else:
                # Ajouter le contenu Ã  la section courante
                text = element.get_text(strip=True)
                if text and len(text) > 10:  # Ignorer les textes trop courts
                    current_section['content'].append(text)
        
        # Ajouter la derniÃ¨re section
        if current_section['content']:
            sections.append(current_section)
            
        return sections
        
    except Exception as e:
        print(f"Erreur lors de la rÃ©cupÃ©ration de {url}: {str(e)}")
        return []

def extract_innovation_sections(sections, page_type):
    """Extrait les sections pertinentes en fonction du type de page."""
    innovations = {
        'vector_search': [],
        'memory_performance': [],
        'other_innovations': []
    }
    
    try:
        for section in sections:
            section_text = ' '.join(section['content'])
            section_lower = section_text.lower()
            
            # Pour la page Vector Search
            if page_type == 'vector':
                if any(keyword in section_lower for keyword in ['vector', 'embedding', 'similarity', 'semantic']):
                    innovations['vector_search'].extend([
                        f"{section['title']}: {text}"
                        for text in section['content']
                        if any(keyword in text.lower() for keyword in ['vector', 'embedding', 'similarity', 'semantic'])
                    ])
            
            # Pour la page Performance/MÃ©moire
            elif page_type == 'performance':
                if any(keyword in section_lower for keyword in ['memory', 'performance', 'optimization', 'speed']):
                    innovations['memory_performance'].extend([
                        f"{section['title']}: {text}"
                        for text in section['content']
                        if any(keyword in text.lower() for keyword in ['memory', 'performance', 'optimization', 'speed'])
                    ])
            
            # Autres sections intÃ©ressantes
            if 'feature' in section_lower or 'new' in section_lower or 'improvement' in section_lower:
                innovations['other_innovations'].extend([
                    f"{section['title']}: {text}"
                    for text in section['content']
                    if len(text) > 50
                ])
        
        return innovations
        
    except Exception as e:
        print(f"Erreur lors de l'extraction des sections: {str(e)}")
        return innovations

def analyze_innovations(innovations: Dict[str, List[str]]) -> Dict:
    """Analyse les innovations et gÃ©nÃ¨re une synthÃ¨se structurÃ©e."""
    def extract_key_points(texts: List[str], keywords: List[str]) -> List[str]:
        """Extrait les points clÃ©s pertinents des textes."""
        key_points = []
        for text in texts:
            # Simplification du texte pour l'analyse
            sentences = [s.strip() for s in text.split('.') if any(kw in s.lower() for kw in keywords)]
            key_points.extend(sentences)
        return list(set(key_points))[:5]  # Limiter Ã  5 points clÃ©s par catÃ©gorie
    
    vector_keywords = ['vector', 'embedding', 'similarity', 'search', 'nearest neighbor']
    memory_keywords = ['memory', 'performance', 'speed', 'optimization', 'efficiency', 'acceleration']
    
    return {
        'vector_search_innovations': {
            'description': 'AmÃ©liorations liÃ©es Ã  la recherche vectorielle et aux embeddings',
            'key_points': extract_key_points(innovations['vector_search'], vector_keywords)
        },
        'memory_performance_innovations': {
            'description': 'AmÃ©liorations des performances et de la gestion de la mÃ©moire',
            'key_points': extract_key_points(innovations['memory_performance'], memory_keywords)
        },
        'other_notable_features': {
            'description': 'Autres fonctionnalitÃ©s notables',
            'features': list(set(innovations['other_innovations']))[:5]  # Limiter Ã  5 fonctionnalitÃ©s
        }
    }

def generate_innovation_report() -> Dict:
    """GÃ©nÃ¨re un rapport complet sur les innovations de Redis."""
    print("DÃ©but de l'analyse des pages de documentation Redis...")
    
    # URLs des pages Ã  analyser
    pages = [
        {
            'url': 'https://redis.io/docs/latest/develop/ai/search-and-query/vectors/',
            'type': 'vector',
            'title': 'Redis Vector Search'
        },
        {
            'url': 'https://redis.io/docs/latest/operate/rs/databases/memory-performance/',
            'type': 'performance',
            'title': 'Redis Memory Performance'
        }
    ]
    
    try:
        # PrÃ©parer la structure pour les innovations
        all_innovations = {
            'vector_search': [],
            'memory_performance': [],
            'other_innovations': []
        }
        
        # Analyser chaque page
        for page in pages:
            print(f"\nAnalyse de la page: {page['title']}")
            
            # RÃ©cupÃ©rer le contenu de la page
            sections = get_page_content(page['url'], page['type'])
            
            if not sections:
                print(f"Aucune section trouvÃ©e pour {page['title']}")
                continue
            
            # Extraire les innovations de la page
            innovations = extract_innovation_sections(sections, page['type'])
            
            # Fusionner avec les rÃ©sultats existants
            for key in all_innovations:
                all_innovations[key].extend(innovations[key])
        
        # Nettoyer les doublons
        for key in all_innovations:
            all_innovations[key] = list(set(all_innovations[key]))
        
        # Analyser les innovations trouvÃ©es
        analysis = analyze_innovations(all_innovations)
        
        # CrÃ©ation du rapport final
        report = {
            'report_date': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC'),
            'pages_analyzed': [{'title': p['title'], 'url': p['url']} for p in pages],
            'analysis': analysis
        }
        
        # Sauvegarde du rapport
        output_file = 'redis_innovations_report.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=4, ensure_ascii=False)
        
        print(f"\nâœ… Rapport d'analyse des innovations sauvegardÃ© dans {output_file}")
        return report
        
    except Exception as e:
        error_msg = f"Erreur lors de la gÃ©nÃ©ration du rapport: {str(e)}"
        print(error_msg)
        return {'error': error_msg}

def main():
    # GÃ©nÃ©rer le rapport d'innovations
    report = generate_innovation_report()
    
    # Afficher un rÃ©sumÃ© dans la console
    if 'analysis' in report and 'error' not in report:
        print("\n=== SYNTHÃˆSE DES INNOVATIONS REDIS ===")
        
        # Afficher les pages analysÃ©es
        if 'pages_analyzed' in report and report['pages_analyzed']:
            print("\nğŸ“„ PAGES ANALYSÃ‰ES :")
            for i, page in enumerate(report['pages_analyzed'], 1):
                print(f"  {i}. {page['title']}")
                print(f"     {page['url']}")
        
        # Afficher les innovations Vector Search
        vector_points = report['analysis']['vector_search_innovations'].get('key_points', [])
        if vector_points:
            print("\nğŸ” VECTOR SEARCH :")
            for i, point in enumerate(vector_points[:10], 1):  # Limiter Ã  10 points max
                print(f"  {i}. {point}")
        
        # Afficher les innovations MÃ©moire/Performance
        perf_points = report['analysis']['memory_performance_innovations'].get('key_points', [])
        if perf_points:
            print("\nâš¡ MÃ‰MOIRE & PERFORMANCE :")
            for i, point in enumerate(perf_points[:10], 1):  # Limiter Ã  10 points max
                print(f"  {i}. {point}")
        
        # Afficher d'autres fonctionnalitÃ©s notables
        other_features = report['analysis']['other_notable_features'].get('features', [])
        if other_features:
            print("\nâœ¨ AUTRES FONCTIONNALITÃ‰S :")
            for i, feature in enumerate(other_features[:5], 1):  # Limiter Ã  5 fonctionnalitÃ©s
                print(f"  {i}. {feature[:150]}..." if len(feature) > 150 else f"  {i}. {feature}")
        
        print("\nâœ… Analyse terminÃ©e avec succÃ¨s !")
    
    elif 'error' in report:
        print(f"\nâŒ Erreur: {report['error']}")

if __name__ == "__main__":
    main()