[
    {
        "database": "CockroachDB",
        "major_version": "26.1",
        "patch_version": "26.1.0-beta.1",
        "date": "December 17, 2025",
        "changes": [
            "A new flag on thecockroach startcommand enables adebug_userwith preconfigured access to authenticate for SQL and RPC connections. This is part of a Private Preview and disabled by default, preventing such authentication. It is intended only for debugging and troubleshooting when using the Private Preview feature that allows restrictingrootfrom login via SQL and RPC connections, while usingdebug_userto access debug details that would have requiredroot.#158963",
            "Improved the description of thechangefeed.default_range_distribution_strategycluster setting to better explain the available options and their behavior.#158602",
            "crdb_internal.index_usage_statisticsandcrdb_internal.datums_to_bytesare now available in theinformation_schemasystem catalog asinformation_schema.crdb_index_usage_statisticsandinformation_schema.crdb_datums_to_bytes, respectively.#156963",
            "TheALTER COLUMN ...sequence identity commands are run by the declarative schema changer.#157030",
            "Added support forEXECUTE SCHEDULE {schedule_id}to allow immediate execution of a scheduled job. This does not apply toALTER BACKUP SCHEDULE; attempting to execute a backup schedule will result in an error.#158694",
            "CREATE TYPEwith composite type syntax now supports array types in field definitions. For example,CREATE TYPE t AS (a INT[])andCREATE TYPE t AS (a INT ARRAY)now work correctly, matching PostgreSQL behavior.#158888",
            "Added theSTRICToption for locality-aware backups. When enabled, backups fail if data from a KV node with one locality tag would be backed up to a bucket with a different locality tag, ensuring data domiciling compliance.#158999",
            "TheWITH RESOLVED TIMESTAMPoption can be passed toSHOW JOBSorSHOW JOBto include the resolved timestamp, if any, for the jobs in the output columns.#159068",
            "You can now specify a user-defined database user when generatingdebug zipanddebug tsdumpfiles. Use the--userand--urlflags to set the username. Previously, these operations required the root user. This change provides backward compatibility by defaulting the username toroot. This update is part of an ongoing effort to limit root user access.#158961",
            "Fixed a bug where modifying a scheduled backup without changing the schedule could cause the next incremental backup to be skipped.#158820",
            "Fixed a bug that allowed columns to be dropped despite being referenced by a routine. This could occur when a column was only referenced as a target column in the SET clause of an UPDATE statement within the routine. This fix only applies to newly-created routines. In versions prior to v26.1, the fix must be enabled by setting the session variableprevent_update_set_column_drop.#158935",
            "Fixed a bug that caused newly-created routines to incorrectly prevent dropping columns that were not directly referenced, most notably columns referenced by computed column expressions. The fix is gated behind the session settinguse_improved_routine_deps_triggers_and_computed_cols, which is off by default prior to v26.1.#158935",
            "Fixed a bug that could cause incorrect query results when using prepared statements with NULL placeholders. The bug has existed since v21.2 and violated SQL NULL-equality semantics by returning rows with NULL values when the result set should have been empty.From v21.2 to v25.3, the bug occurred when all of the following were true:The query was run with an explicit or implicit prepared statementThe query had an equality filter on a placeholder and a UNIQUE columnThe column contained NULL valuesThe placeholder was assigned to NULL during executionStarting in v25.4, the requirements were loosened: the column no longer needed to be UNIQUE, and the bug could reproduce if the column was included in any index.#159001",
            "The query was run with an explicit or implicit prepared statement",
            "The query had an equality filter on a placeholder and a UNIQUE column",
            "The column contained NULL values",
            "The placeholder was assigned to NULL during execution",
            "Fixed a bug where theschema_lockedtable storage parameter could be bypassed by combiningSET (schema_locked=false)with other schema changes in the sameALTER TABLEstatement using comma syntax. Schema-locked tables now correctly reject such combined statements.#159017",
            "Triggers now perform the descriptor lookup forTG_TABLE_SCHEMAagainst a cache. This can significantly reduce trigger planning latency in multi-region databases.#144217",
            "AFTERtriggers now use a cache for descriptor lookups ofTG_TABLE_SCHEMA, which can significantly reduce trigger planning latency.#158708"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "26.1",
        "patch_version": "26.1.0-alpha.2",
        "date": "December 11, 2025",
        "changes": [
            "A new, optional flag forcockroach startrestricts therootuser from logging in to the system via both SQL and RPC connections. This change affects theunstated, unchangeable root access ruleand addresses compliance requirements. It is currently available inLimited Access.A newdebug_usercertificate has also been introduced for privileged RPC access to collectdebug zipinformation, which would otherwise be unavailable whenrootis restricted.debug_usermust be created manually with theCREATE USERcommand and can be audited usingSHOW USERS. It has privileged access to theserverpbadmin and status endpoints required for debug zip collection.Ensure that none of the certificates used by the cluster or SQL/RPC clients have \"root\" in the SAN (Subject Alternative Name) fields, as the flag will block access to those clients.#155216",
            "A newdebug_usercertificate has also been introduced for privileged RPC access to collectdebug zipinformation, which would otherwise be unavailable whenrootis restricted.debug_usermust be created manually with theCREATE USERcommand and can be audited usingSHOW USERS. It has privileged access to theserverpbadmin and status endpoints required for debug zip collection.",
            "Ensure that none of the certificates used by the cluster or SQL/RPC clients have \"root\" in the SAN (Subject Alternative Name) fields, as the flag will block access to those clients.",
            "Added a new session variable,use_swap_mutations, which controls whether the new update swap and delete swap operators are enabled for use byUPDATEandDELETEstatements.#145019",
            "Fixed a bug where the results ofALTER SEQUENCE's increment andSELECT nextval()operations were not as expected. The value of a sequence after anALTER SEQUENCEstatement has executed on it is now consistent with a sequence created with those values.#154489",
            "SQL statements executed in stored procedures and user-defined functions now record SQL statistics, including latencies and execution metrics. These statistics appear on theSQL ActivityandInsightspages of the DB Console. Limitation: SQL statements within a stored procedure or user-defined function are not collected for active statement diagnostics requests. Statement diagnostics remain available for top-level statement executions.#156905",
            "TheALTER COLUMN ...sequence identity commands are run by the declarative schema changer.#157030",
            "Thecumulative time spent waiting in admission controlis now displayed inEXPLAIN ANALYZEoutput when it is non-zero. This helps identify delays caused by admission control during query execution.#158055",
            "Restarting a sequence with an updated increment has the expected initial value.#158065",
            "Thecumulative time spent waiting in admission controlreported inEXPLAIN ANALYZEnow includes the time spent in quorum replication flow control. This update enhances the precision of wait time analysis, offering a more accurate depiction of query execution time by considering additional wait durations within the quorum replication processes.#158076",
            "Added a new \"hint injection\" ability that allows operators to dynamically inject inline hints into statements, without modifying the text of those statements. Hints can be injected using the built-in functioncrdb_internal.inject_hintwith the target statement fingerprint to rewrite. For example, to add an index hint to the statementSELECT * FROM my_table WHERE col = 3, use:",
            "Theallow_unsafe_internalssetting now defaults tofalse, restricting access to thesystemandcrdb_internalnamespaces. Queries to these namespaces will now fail unless access is manually enabled. Usage is also audited.#158085",
            "Jobs that are paused due to a specific reason, including jobs which pause themselves when encountering errors such as running out of disk space, now record that reason in their displayed status field ofSHOW JOBS.#158350",
            "The following metrics are now marked as essential to support end-user troubleshooting of authentication latency issues:auth.jwt.conn.latencyauth.cert.conn.latencyauth.password.conn.latencyauth.ldap.conn.latencyauth.gss.conn.latencyauth.scram.conn.latencyauth.ldap.conn.latency.internal#158424",
            "auth.jwt.conn.latency",
            "auth.cert.conn.latency",
            "auth.password.conn.latency",
            "auth.ldap.conn.latency",
            "auth.gss.conn.latency",
            "auth.scram.conn.latency",
            "auth.ldap.conn.latency.internal#158424",
            "The log of messages and events recorded by a job is now shown to non-admin users on the DB Console Jobs page.#152853",
            "The DB Console now accurately displaysvCPUcounts on theOverviewpage instead of operating system CPU counts. This update uses cgroups to provide a correct vCPU measurement, reflecting reserved compute resources in Kubernetes and other virtualized environments.#158219",
            "Jobs which are paused for a specific reason now show that reason, and are highlighted in the UI.#158364",
            "ThekvCPUTimeNanosis now recorded incrdb_internal.statement_statisticsandcrdb_internal.transaction_statistics. In the DB Console, aKV CPU Timecolumn is now displayed in theSQL Activity>StatementsandTransactionspages, allowing you to monitor and analyze the CPU time consumed by KV operations during query execution.#158398",
            "TheadmissionWaitTimeis now recorded incrdb_internal.statement_statisticsandcrdb_internal.transaction_statistics. In the DB Console, anAdmission Wait Timecolumn is now displayed in theSQL Activity>StatementsandTransactionspages.#158500",
            "Fixed a bug that could cause an internal error in some cases for PL/pgSQL routines that perform database reads within an exception block.#156902",
            "Fixed a bug where a SQL statement with side effects (e.g.,INSERT) inside a PL/pgSQL routine could be dropped if it used anINTOclause and none of the target variables were referenced. This bug had been present since v23.2.#156966",
            "Fixed a bug where renaming a column that participated in multiple hash-sharded indexes would fail.#158045",
            "Fixed a bug whereORDER BYclauses in user-defined set-returning SQL functions withOUTparameters were ignored when the function was called directly in aSELECTlist (e.g.,SELECT f()). The ordering is now properly preserved and enforced.#158162",
            "The pgwire server now exits promptly on context cancellation.#158269",
            "Fixed a bounded memory leak that could occur during table statistics collection on tables that contain both very wide (10 KiB or more) and small (under 400B)BYTES-like values within the same row, along with virtual computed columns. This bug had been present since stats collection on virtual computed columns was introduced in v24.1.#158370",
            "Temporary schema cleanup no longer retries after poisoned transaction errors, reducing log noise.#158396",
            "When changing the time interval on theMetricspage, the DB Console previously sent duplicate requests for metrics data. This has been fixed, and the UI now issues a single, efficient request when updating the time interval.#158595",
            "Added newupdate swapanddelete swapoperators that allow someUPDATEandDELETEstatements to execute in 1 roundtrip instead of 2 roundtrips. These operators can be used when:All columns in the primary index are constrained to a single exact value by theWHEREclause;Only a single row is modified;There are no foreign-key checks or cascades;There are no uniqueness checks;There are no check constraints;There are no vector indexes modified;There are no passthrough columns toRETURNING;There are no triggers;The table only uses a single column family;There are no mutation columns or mutation indexes (i.e., the table is not undergoing anALTER);There are no columns using composite encoding (e.g.,DECIMAL,FLOAT,JSON, etc.).#145019",
            "All columns in the primary index are constrained to a single exact value by theWHEREclause;",
            "Only a single row is modified;",
            "There are no foreign-key checks or cascades;",
            "There are no uniqueness checks;",
            "There are no check constraints;",
            "There are no vector indexes modified;",
            "There are no passthrough columns toRETURNING;",
            "There are no triggers;",
            "The table only uses a single column family;",
            "There are no mutation columns or mutation indexes (i.e., the table is not undergoing anALTER);",
            "There are no columns using composite encoding (e.g.,DECIMAL,FLOAT,JSON, etc.).#145019",
            "The optimizer now collapses repeated%wildcard characters inLIKEpatterns. This may improve performance of queries using such patterns.#158025",
            "More of the CPU usage of LDR jobs is subject to background job admission control limits.#158361"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "26.1",
        "patch_version": "26.1.0-alpha.1",
        "date": "December 4, 2025",
        "changes": [
            "Docker images now use UBI 10 as the base image.#153990",
            "The changefeed bulk delivery setting was made optional.#154870",
            "To improve changefeed performance, the session variablecreate_table_with_schema_lockedis enabled by default. This means all new tables are created with theschema_lockedstorage parameter.schema_lockedmust be explicitly unset for explicit transactions or for schema changes that do not support automatic disabling (e.g.,ALTER TABLE ... SET LOCALITY).",
            "Index acceleration is now supported for a subset ofjsonb_path_existsfilters used in theWHEREclause.Givenjsonb_path_exists(json_obj, json_path_expression), inverted indexes are supported only when thejson_path_expressionmatches one of the following patterns:",
            "Thejson_path_expressionmust not be in STRICT mode.",
            "Keychain mode:$. [key|wildcard].[key|wildcard].... In this mode, a prefix span is generated for the inverted expression.",
            "Filter with end value mode, using an equality check:$. [key|wildcard]? (@.[key|wildcard].[key|wildcard]... == [string|number|null|boolean]). In this mode, since the end value is fixed, a single-value span is generated.The following cases are not supported:$$[*]$.a.b.c == 12,$.a.b.c > 12, or$.a.b.c < 12(operation expressions)$.a.b ? (@.a > 10)(filter with an inequality check)#150793",
            "$.a.b.c == 12,$.a.b.c > 12, or$.a.b.c < 12(operation expressions)",
            "$.a.b ? (@.a > 10)(filter with an inequality check)",
            "SHOW CHANGEFEED JOBSnow includes adatabase_namefield that displays the database name for database-level changefeeds. For table-level changefeeds, this field isnull. For database-level changefeeds, thefull_table_namesfield now returns an empty list by default and displays only the total count of watched tables.To view the full list of watched tables (as in previous versions), use the newWITH WATCHED_TABLESoption:SHOWCHANGEFEEDJOBSWITHWATCHED_TABLES;This change improves performance when displaying database-level changefeeds that may track many tables.#151131",
            "Added a clamp for the estimated selectivity of inequality predicates that are unbounded on one or both sides (e.g.,x > 5). This reduces the risk of a catastrophic underestimate that causes the optimizer to choose a poorly-constrained scan. The feature is disabled by default and can be enabled with the session settingoptimizer_clamp_inequality_selectivity.#153067",
            "Added a clamp on row-count estimates for very large tables to ensure the optimizer assumes at least one distinct value will be scanned. This reduces the risk of a catastrophic underestimate. The feature is off by default and controlled by theoptimizer_clamp_low_histogram_selectivitysession setting.#153067",
            "The optimizer can now use table statistics that merge the latest full statistic with all newer partial statistics, including those over arbitrary constraints over a single span.#153419",
            "Added thesql.catalog.allow_leased_descriptors.enabledcluster setting, which is false by default. When set to true, queries that access thepg_catalogorinformation_schemacan use cached leased descriptors to populate the data in those tables, with the tradeoff that some of the data could be stale.#154051",
            "Added a default-off cluster setting (sql.log.scan_row_count_misestimate.enabled) that enables logging a warning on the gateway node when optimizer estimates for scans are inaccurate. The log message includes the table and index being scanned, the estimated and actual row counts, the time since the last table stats collection, and the table's estimated staleness.#154370",
            "Fixed a bug where the results ofALTER SEQUENCE's increment andSELECT nextval()operations were not as expected. The value of a sequence after anALTER SEQUENCEstatement has executed on it is now consistent with a sequence created with those values.#154489",
            "Added changefeed settingrange_distribution_strategywith values'default'or'balanced_simple'. This new per-changefeed setting overrides the cluster settingchangefeed.default_range_distribution_strategywhere both exist.Example:CREATECHANGEFEEDFORxinto'null://'WITHrange_distribution_strategy='balanced_simple';#154744",
            "Added theINSPECTcommand, which runs consistency validation check jobs against tables or databases and specified indexes.#154873",
            "Added support for collecting partial statistics when the givenWHEREclause implies the predicate of a partial index with the requested column as the first key column. For example:CREATE TABLE t (a INT, INDEX idx_partial (a) WHERE a > 5); CREATE STATISTICS pstat ON a FROM t WHERE a > 7;#154892",
            "Therow_securitysession variable now behaves as it does in PostgreSQL, allowing users to detect when RLS is applied.#155110",
            "Added thebulkio.index_backfill.vector_merge_batch_sizecluster setting to control how many vectors to merge into a vector index per transaction during create operations. The setting defaults to3.#155284",
            "Updated the scan misestimate logging, which is controlled by thesql.log.scan_row_count_misestimate.enabledcluster setting, to use structured logging. The logs now include the scanned table and index, the estimated and actual row counts, the time since the last table statistics collection, and the table's estimated staleness.#155454",
            "TheEXPERIMENTAL SCRUBcommand is deprecated. Use theINSPECTcommand for data consistency validation.#155485",
            "INSPECTsupports aDETACHEDoption to run the operation without waiting for it.#155774",
            "ALTER TABLE ... DROP STOREDstatements are now executed internally by the declarative schema changer.#155778",
            "Added asql.statements.rows_read.countmetric that counts the number of index rows read by SQL statements.#155820",
            "Added theEXPLAIN (FINGERPRINT)statement, which returns normalized statement fingerprints with constants replaced by underscores. For example,EXPLAIN (FINGERPRINT) SELECT * FROM t WHERE a = 123returnsSELECT * FROM t WHERE a = _.#156152",
            "Introduced two new settings to control the use of canary statistics in query planning:Cluster settingsql.stats.canary_fraction(float, range [0, 1], default: 0): Controls what fraction of queries use \"canary statistics\" (newly collected stats within their canary window) versus \"stable statistics\" (previously proven stats). For example, a value of0.2means 20% of queries will use canary stats while 80% use stable stats. The selection is atomic per query: if a query is chosen for canary evaluation, it uses canary statistics foralltables it references (where available). A query never uses a mix of canary and stable statistics.Session variablecanary_stats_mode(enum: {auto, off, on}, default: auto):on: All queries in the session use canary stats for planning.off: All queries in the session use stable stats for planning.auto: The system decides based onsql.stats.canary_fractionfor each query execution.#156307",
            "Cluster settingsql.stats.canary_fraction(float, range [0, 1], default: 0): Controls what fraction of queries use \"canary statistics\" (newly collected stats within their canary window) versus \"stable statistics\" (previously proven stats). For example, a value of0.2means 20% of queries will use canary stats while 80% use stable stats. The selection is atomic per query: if a query is chosen for canary evaluation, it uses canary statistics foralltables it references (where available). A query never uses a mix of canary and stable statistics.",
            "Session variablecanary_stats_mode(enum: {auto, off, on}, default: auto):on: All queries in the session use canary stats for planning.off: All queries in the session use stable stats for planning.auto: The system decides based onsql.stats.canary_fractionfor each query execution.#156307",
            "on: All queries in the session use canary stats for planning.",
            "off: All queries in the session use stable stats for planning.",
            "auto: The system decides based onsql.stats.canary_fractionfor each query execution.#156307",
            "Introduced a new table storage parameter,sql_stats_canary_window, to enable gradual rollout of newly collected table statistics. It takes a duration string as the value. When set with a positive duration, the new statistics remain in a \"canary\" state for the specified duration before being promoted to stable. This allows for controlled exposure and intervention opportunities before statistics are fully deployed across all queries.#156307",
            "IntroducedSHOW FINGERPRINTS FOR TABLE, which produces an FNV hash for each index in a table. FNV is used for performance reasons and is sensitive to changes in the underlying data, includingNULLs.#156600",
            "Theoptimizer_clamp_low_histogram_selectivityandoptimizer_clamp_inequality_selectivitysettings are now on by default. This causes the optimizer to assume that at least one distinct value \"passes\" each filter in a query, and that open-ended inequality filters select at least 1/10000 rows from the table. This reduces the chances of a catastrophic row count underestimate when stats are inaccurate.#156610",
            "TheALTER TABLE ... SET/ADD GENERATED AS IDENTITYstatement is supported by the declarative schema changer in v26.1 and later.#157144",
            "EXPLAINandEXPLAIN ANALYZEwill now display the number of hints fromsystem.statement_hintsapplied to the executed statement.#157160",
            "ThePlan Detailsin theStatement Activitypage of the DB Console now show whether any hints fromsystem.statement_hintswere applied to the statement execution.#157160",
            "The metricssql.select.started.count,sql.insert.started.count,sql.update.started.count, andsql.delete.started.countare now emitted with labels under the common metric namesql.started.count, using aquery_typelabel to distinguish each operation.#151946",
            "Added the cluster settingstorage.unhealthy_write_duration(defaults to 20s), which is used to indicate to the allocator that a store's disk is unhealthy. The cluster settingkv.allocator.disk_unhealthy_io_overload_scorecontrols the overload score assigned to a store with an unhealthy disk, where a higher score results in preventing lease or replica transfers to the store, or shedding of leases by the store. The default value of that setting is 0, so the allocator behavior is unaffected.#153364",
            "Added two new changefeed metrics for tracking the max skew between a changefeed's slowest and fastest span/table. The metrics are gauge metrics with the nameschangefeed.progress_skew.{span}andchangefeed.progress_skew.{table}.#153975",
            "Added the cluster settingstorage.snapshot.recreate_iter_duration(default 20s), which controls how frequently a long-lived storage engine iterator, backed by an engine snapshot, will be closed and recreated. Currently, it is only used for iterators used in rangefeed catchup scans.#154412",
            "Added cluster settingsql.schema.approx_max_object_count(default: 20,000) to prevent creation of new schema objects when the limit is exceeded. The check uses cached table statistics for performance and is approximate - it may not be immediately accurate until table statistics are updated by the background statistics refreshing job. Clusters that have been running stably with a larger object count should raise the limit or disable the limit by setting the value to 0. In future releases, the default value for this setting will be raised as more CockroachDB features support larger object counts.#154495",
            "Cleaned up redundant and misleading metrics.#154545",
            "Fixed thechangefeed.parallel_io_pending_rowsmetric's y-axis label to match the metric's definition.#154552",
            "Added a metric calledchangefeed.parallel_io_workersto track the number of workers in ParallelIO.#154552",
            "Events related to changefeed operations are now routed to theCHANGEFEEDchannel, while sampled queries and transactions, along with certain SQL performance events, are logged toSQL_EXEC. To continue using the previous logging channels, setlog.channel_compatibility_mode.enabledtotrue.#154670",
            "Successfully completed automatic SQL stats collecton jobs are now automatically purged rather than being retained for the full default job retention period.#155848",
            "The cluster settingstorage.snapshot.recreate_iter_duration(default20s) controls how frequently a long-lived engine iterator, backed by an engine snapshot, will be closed and recreated. Currently, it is only used for iterators used in rangefeed catchup scans.#156303",
            "Add support forCREATE LOGICAL REPLICATION STREAMin situations where the source table has a column with a sequence expression.#156975",
            "cockroach workload <name> runcommands now offer a--with-changefeedflag to additionally run a changefeed that watches for writes to the workload's tables.#155516",
            "TheSQLdashboard has been enhanced with additional insights.TheTransaction Restartsdashboard now displaystxn.restarts.txnpushandtxn.restarts.unknownmetrics. - A newFailed SQL Connectionsgraph shows failed SQL connection attempts. A newSQL Queries Within Routines Per Seconddashboard reports onSELECT,UPDATE,INSERT, andDELETEoperations executed within routines.A newTable Statistics Collectionsdashboard provides information on auto, auto partial, and manual statistics collections.",
            "TheTransaction Restartsdashboard now displaystxn.restarts.txnpushandtxn.restarts.unknownmetrics. - A newFailed SQL Connectionsgraph shows failed SQL connection attempts. A newSQL Queries Within Routines Per Seconddashboard reports onSELECT,UPDATE,INSERT, andDELETEoperations executed within routines.",
            "A newTable Statistics Collectionsdashboard provides information on auto, auto partial, and manual statistics collections.",
            "The background (elastic) store graphs for exhausted duration, and the wait duration histogram, have been separated from the foreground (regular) graphs.#156801",
            "Previously, CockroachDB would omit execution statistics inEXPLAIN ANALYZEoutput for mutation nodes when aRETURNINGclause was used. The bug was present since before v21.1 and is now fixed.#145934",
            "Fixed a bug where CockroachDB could encounter avector encoder doesn't support ForcePut yeterror when executingCOPYcommands concurrently with certain schema changes. The bug had existed since before v23.2.#148549",
            "Fixed a bug causing aREAD COMMITTEDorSNAPSHOTisolation transaction to be committed despite returning a non-ambiguous error.#152010",
            "Fixed a bug in type-checking placeholders withUNKNOWNtypes. It could cause incorrect results in some cases.#152882",
            "Fixed a bug whereEXPORT CSVandEXPORT PARQUETcould cause a node crash when their result rows were used as input to a mutation, such as anINSERT, within the same SQL statement. This bug had been present since before v22.1.#153951",
            "Idle latencyon theTransaction Detailspage in the DB Console is now reported more accurately. Previously, transactions that used prepared statements (e.g., with placeholders) overcounted idle time, while those that included observer statements (common in the SQL CLI) undercounted it.#154028",
            "Fixed a bug that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when the session settingexpect_and_ignore_not_visible_columns_in_copywas enabled. This bug was introduced withexpect_and_ignore_not_visible_columns_in_copyin v22.1.0.#154162",
            "Vector index backfill jobs now correctly report progress in theSHOW JOBSoutput.#154209",
            "Fixed a bug whereRESTOREof a database with aSECONDARY REGIONdid not apply the lease preferences for that region.#154522",
            "Fixed a bug where a changefeed could perform many unnecessary job progress saves during an initial scan.#154598",
            "Fixed a bug where CockroachDB would not log events forTxnRowsReadandTxnRowsWrittenguardrails for internal queries into theSQL_INTERNAL_PERFlogging channel. The bug was present since v21.2.#154670",
            "Fixed a bug that caused internal errors forINSERT .. ON CONFLICT .. DO UPDATEstatements when the target table had both a computed column and aBEFOREtrigger. This bug was present since triggers were introduced in v24.3.0.#154789",
            "Fixed a bug where a changefeed targeting only a subset of a table's column families could become stuck.#154802",
            "Fixed a bug where CockroachDB would hit an internal error when performing an inverted join using an inverted index in which the first prefix column hadDESCdirection. The bug was present since v21.1.#154914",
            "Fixed a bug where thekvflowcontrol.send_queue.scheduled.force_flushmetric was missing a decrement, resulting in a value of greater than0even when there was no ongoing force flush.#154960",
            "Fixed a bug that would causeWITH READ VIRTUAL CLUSTERto be ignored if any other options were passed when runningCREATE VIRTUAL CLUSTER FROM REPLICATION.#154963",
            "Internal assertions that verifyNumRange = 0in the first histogram bucket, used to catch malformed statistics, now run only in test builds to avoid crashing production queries.#155035",
            "Fixed a bug in which range counts in table statistics histograms were not handled correctly after a user-definedENUMtype was modified.#155035",
            "Fixed a bug in thecockroach node draincommand where draining a node using virtual clusters (such as clusters running Physical Cluster Replication (PCR)) could return before the drain was complete, possibly resulting in shutting down the node while it still had active SQL clients and range leases.#155063",
            "Fixed a bug where a race condition in range splits could result in a regressed Raft state on a post-split range. This condition was extremely rare, and only observed during internal testing.#155143",
            "Corrected a potential deadlock during vector index creation.#155192",
            "Fixed a bug that would result in a node crash if a PCR or LDR URI usedsslinline=truewithsslmode=disable.#155232",
            "Fixed a bug where CockroachDB could corrupt the first bucket of table statistic histograms in certain cases, causing underestimates for range counts near the lower end of the domain.#155242",
            "Added proper dependency handling when adding a constraint withNOT VALIDthat references a user-defined function (UDF).#155404",
            "Fixed a bug that prevented the optimizer from recognizing correlated filters when one of the filtered columns had a single distinct value across all rows. This could lead to suboptimal query plans in some cases.#155407",
            "The username remapping functionality specified by theserver.identity_map.configurationcluster setting now matches identities and usernames with a case-insensitive comparison.#155531",
            "Previously, the forecasted statistics shown inSHOW STATISTICS ... WITH FORECASTcould be inconsistent with those in the stats cache, depending on whetherWITH MERGEwas specified. Forecasted statistics are now displayed consistently, regardless of theWITH MERGEclause.#155615",
            "Fixed a bug where CockroachDB could crash when executingEXPLAIN ANALYZEstatements using the pausable portal model. This would occur when the query was executed via the extended PGWire protocol (Parse,Bind,Execute) with themultiple_active_portals_enabledsession variable set. The bug was present since v23.2.#155655",
            "INSPECTcan now be run on tables with indexes that storeREFCURSOR-typed columns.#155772",
            "Fixes a bug whereDROP SCHEMA CASCADEcould run into an error with complex references from triggers.#155777",
            "Fixed a bug where the job responsible for compacting stats for the SQL activity state could enter an unschedulable state. Fixes: #155165#155809",
            "Fixed a bug where reads and writes performed by routines (user-defined functions and stored procedures) and apply joins were not included inbytes read,rows read, androws writtenstatement execution statistics. This bug had been present since before v23.2.#155824",
            "INSPECTnow correctly checks index consistency at the historical timestamp when usingAS OF SYSTEM TIME, even for spans with no current data.#155837",
            "TheINSPECTstatement now detects dangling secondary index entries even when the primary index spans contain no data.#155844",
            "Fixed an internal error that could occur when replacing a user-defined function or stored procedure usingCREATE OR REPLACE, if the existing signature included multipleDEFAULTexpressions. This bug was introduced in v24.2, when support forDEFAULTexpressions was added.#155867",
            "INSPECTno longer fails when checking index consistency on indexes with virtual key columns. Such indexes will now be skipped.#155956",
            "Fixed a bug where DML statements on regional by row tables with unique indexes that do not reference the region could sometimes fail underREAD COMMITTEDisolation.#156105",
            "Fixed a bug where Zone Config Extensions incorrectly prevented users from removing non-voting read replicas from multi-region databases. Users can now setnum_replicasequal tonum_votersto remove read replicas while maintaining the required number of voting replicas for their database's survival goal. This allows reducing storage costs without compromising availability guarantees.#156228",
            "Fixed a bug in theltree2textbuilt-in function where the returnedTEXTvalue was incorrectly wrapped in single quotes. This bug had been present since theltree2textfunction was introduced in v25.4.0.#156485",
            "Fixed a bug that caused incorrect results for queries that filter indexedLTREEcolumns with the<@(contained-by) operator. This bug was present since v25.4.0.#156573",
            "Fixed a bug where the \"atomic\"COPYcommand (controlled via thecopy_from_atomic_enabledsession setting,trueby default) could encounterRETRY_COMMIT_DEADLINE_EXCEEDEDtransaction errors if the whole command took 1 minute or more. This bug occurred only when the vectorized engine was used forCOPY.#156584",
            "Fixed a bug that caused transactions to fail with the error message:failed indeterminate commit recovery: programming error: timestamp change by implicitly committed transaction.#156722",
            "Fixed a bug in JSONPath index acceleration where queries usingjsonb_path_existswith a root key (e.g.,$.b) incorrectly returned no results when the queried JSON was an array. This fix enables unwrapping a single array layer at the root, allowing the path to be evaluated against each element. Only v25.4 releases were affected.#156828",
            "Fixed a bug that prevents largeTRUNCATEoperations from completing due tocommand is too largeerrors.#156867",
            "Fixed a bug that caused incorrectgossip.callbacks.pending_durationmetric values to be recorded.#156939",
            "Fixed a bug where transactions running concurrently with aGRANTorREVOKEon virtual tables or via external connections could observe modifications incorrectly.#156949",
            "Fixed a bug where CockroachDB could encounter an internal error when evaluating aCOPY FROMcommand in a transaction after it was rolled back to a savepoint. The bug was present since before v23.2.#156959",
            "Fixed a bug that could cause internal errors for queries using generic query plans withNULLplaceholder values.#156962",
            "Fixed a bug that could cause a schema change to be stuck in the reverting state if theinfer_rbr_region_col_using_constraintstorage parameter was being set at the same time as adding a constraint that had a foreign key violation.#157834",
            "The cost of generic query plans is now calculated based on worst-case selectivities for placeholder equalities (e.g.,x = $1). This reduces the chance of suboptimal generic query plans being chosen whenplan_cache_mode=auto.#151409",
            "TTL jobs now checkpoint their progress, allowing them to resume without reprocessing already completed spans after a restart.#152618",
            "Queries with filters in the forma LIKE b ESCAPE '\\'are now index-accelerated in certain cases where they were not before.#155064",
            "The optimizer will no longer choose a generic query plan with unbounded cardinality over a custom query plan with bounded cardinality, regardless ofoptimizer_prefer_bounded_cardinality, better optimizing such queries.#155163",
            "Optimized validation queries duringALTER PRIMARY KEYto avoid counting the primary key multiple times.#156889",
            "The optimizer now splits disjunctions on the same column into unions when there are multiple partial indexes with different predicates referencing that column.#157083",
            "Upgraded to Go version 1.25.3#156000",
            "Added initial and catchup scan metrics to Physical Cluster Replication (PCR) underphysical_replication.scanning_rangesandphysical_replication.catchup_ranges.#153893",
            "Added a retry policy for Azure Blob Storage with a default of 60 seconds to mitigate occasional stuck operations. The retry policy is configurable with thecloudstorage.azure.try.timeoutsetting.#154149",
            "Logical Data Replication (LDR) now updates thelogical_replication.scanning_rangesandlogical_replication.catchup_rangesmetrics during fast initial scan.#155274",
            "Added thejobs.registry.max_adoptions_per_loopcluster setting to configure the maximum number of jobs a node can adopt per adoption loop.#155385",
            "Fixed a bug that prevented admin users from having full access to external connections created by other users.#155657",
            "LDR no longer requires the database name to be specified in the external connection URI when setting up a bidirectional stream.#155729",
            "Span config reconciliation jobs no longer fail on the destination after failover from a PCR stream of a system virtual cluster.#156003",
            "Added support of partial indexes to Logical Data Replication, tolerant of mismatched column IDs in the source and destination tables.#156935",
            "Display whether build is FIPS-enabled incockroach version#157223",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.2",
        "date": "December 12, 2025",
        "changes": [
            "The background (elastic) store graphs for exhausted duration, and the wait duration histogram, have been separated from the foreground (regular) graphs.#156869",
            "A mechanism that prevents unsafe replication changes from causing loss of quorum now functions correctly. An internal function has been fixed to properly return errors, enhancing the reliability of replication safeguards.#156523",
            "Fixed a bug where CockroachDB could encounter avector encoder doesn't support ForcePut yeterror when executingCOPYcommands concurrently with certain schema changes. The bug had existed since before v23.2.#157200",
            "Fixed a bug that could cause a schema change to be stuck in the reverting state if theinfer_rbr_region_col_using_constraintstorage parameter was being set at the same time as adding a constraint that had a foreign key violation.#157844"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.1",
        "date": "December 3, 2025",
        "changes": [
            "Added asql.statements.rows_read.countmetric that counts the number of index rows read by SQL statements.#156459",
            "Added asql.statements.index_rows_written.countmetric that counts the number of primary and secondary index rows modified by SQL statements.#156459",
            "Added asql.statements.index_bytes_written.countmetric that counts the number of primary and secondary index bytes modified by SQL statements.#156459",
            "Added asql.statements.bytes_read.countmetric that counts the number of bytes scanned by SQL statements.#156459",
            "CockroachDB now supports index acceleratingjsonb_path_existsfilters with JSONpath expressions that end with an AnyKey (*).#156508",
            "Fixed a bug where CockroachDB would hit an internal error when performing an inverted join using an inverted index in which the first prefix column hadDESCdirection. The bug was present since v21.1.#154970",
            "Fixed a bug in thecockroach node draincommand where draining a node using virtual clusters (such as clusters running Physical Cluster Replication (PCR)) could return before the drain was complete, possibly resulting in shutting down the node while it still had active SQL clients and range leases.#155633",
            "Fixed an internal error that could occur when replacing a user-defined function or stored procedure usingCREATE OR REPLACE, if the existing signature included multipleDEFAULTexpressions. This bug was introduced in v24.2, when support forDEFAULTexpressions was added.#155927",
            "Fixed a bug where the job responsible for compacting stats for the SQL activity state could enter an unschedulable state.#155963",
            "Fixed a bug where DML statements on regional by row tables with unique indexes that do not reference the region could sometimes fail underREAD COMMITTEDisolation.#156136",
            "Fixed a bug that prevented the optimizer from recognizing correlated filters when one of the filtered columns had a single distinct value across all rows. This could lead to suboptimal query plans in some cases.#156286",
            "Fixed a bug where changefeeds using CDC queries could sometimes unexpectedly fail after a schema change with a descriptor retrieval error.#156545",
            "Fixed a bug whereDROP SCHEMA CASCADEwith complex references from triggers could run into an error.#156564",
            "Fixed a bug in theltree2textbuilt-in function where the returnedTEXTvalue was incorrectly wrapped in single quotes. This bug had been present since theltree2textfunction was introduced in v25.4.0.#156667",
            "Fixed a bug where the \"atomic\"COPYcommand (controlled via thecopy_from_atomic_enabledsession setting,trueby default) could encounterRETRY_COMMIT_DEADLINE_EXCEEDEDtransaction errors if the whole command took 1 minute or more. This bug occurred only when the vectorized engine was used forCOPY.#156695",
            "Fixed a bug that caused incorrect results for queries that filter indexedLTREEcolumns with the<@(contained-by) operator. This bug was present since v25.4.0.#156779",
            "Fixed a bug that caused incorrectgossip.callbacks.pending_durationmetric values to be recorded.#156947",
            "Fixed a bug in JSONPath index acceleration where queries usingjsonb_path_existswith a root key (e.g.,$.b) incorrectly returned no results when the queried JSON was an array. This fix enables unwrapping a single array layer at the root, allowing the path to be evaluated against each element. This bug was present since v25.4.0.#156968",
            "Fixed a bug that could cause internal errors for queries using generic query plans withNULLplaceholder values.#156979",
            "Fixed a bug where CockroachDB could encounter an internal error when evaluating aCOPY FROMcommand in a transaction after it was rolled back to a savepoint. The bug was present since before v23.2.#157037",
            "The optimizer will no longer choose a generic query plan with unbounded cardinality over a custom query plan with bounded cardinality, regardless ofoptimizer_prefer_bounded_cardinality, better optimizing such queries.#155460",
            "Logical Data Replication (LDR) no longer requires the database name to be specified in the external connection URI when setting up a bidirectional stream.#155737",
            "Span config reconciliation jobs no longer fail on the destination after failover from a Physical Cluster Replication (PCR) stream of a system virtual cluster.#156812"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-rc.1",
        "date": "October 22, 2025",
        "changes": [
            "Changed scan misestimate logging gated behindsql.log.scan_row_count_misestimate.enabledto use structured logging including the table and index being scanned, the estimated and actual row counts, the time since the last table stats collection, and the table's estimated staleness.#155123",
            "Added a default-off cluster setting (sql.log.scan_row_count_misestimate.enabled) that enables logging a warning on the gateway node when optimizer estimates for scans are inaccurate. The log message includes the table and index being scanned, the estimated and actual row counts, the time since the last table stats collection, and the table's estimated staleness.#155123",
            "Added theINSPECTcommand, which runs consistency validation check jobs against tables or databases and specified indexes.#155441",
            "Added thebulkio.index_backfill.vector_merge_batch_size clustersetting to control how many vectors to merge into a vector index per transaction during create operations. By default, this defaults to 3.#155509",
            "Vector indexing is now enabled by default.#155561",
            "Fixed a bug that caused internal errors forINSERT .. ON CONFLICT .. DO UPDATEstatements when the target table had both a computed column and aBEFOREtrigger. This bug was present since triggers were introduced in v24.3.0.#155077",
            "Disable a feature (kv.lock_table.unreplicated_lock_reliability.split.enabled) that could lead to a node crash.#155366",
            "Previously, we could corrupt the first bucket of table statistic histograms in certain cases, causing underestimates for range counts near the lower end of the domain, which is now fixed.#155415",
            "A potential deadlock during vector index creation has been corrected.#155508",
            "Added proper dependency handling when adding a constraint withNOT VALIDthat references a user-defined function (UDF).#155528"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-beta.3",
        "date": "October 16, 2025",
        "changes": [
            "Fixed a bug that caused internal errors forINSERT .. ON CONFLICT .. DO UPDATEstatements when the target table had both a computed column and aBEFOREtrigger. This bug was present since triggers were introduced in v24.3.0.#155077"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-beta.2",
        "date": "October 10, 2025",
        "changes": [
            "The changefeed bulk delivery setting was made optional.#154953",
            "Added theSHOW INSPECT ERRORScommand. This command can be used to view issues that are identified by running theINSPECTcommand to validate tables and indexes.#154337",
            "Added thesql.catalog.allow_leased_descriptors.enabledcluster setting, which is false by default. When set to true, queries that access thepg_catalogorinformation_schemacan use cached leased descriptors to populate the data in those tables, with the tradeoff that some of the data could be stale.#154491",
            "CockroachDB now supports index acceleration for certainjsonb_path_existsfilters used inWHEREclauses. Givenjsonb_path_exists(json_obj, json_path_expression), an inverted index is supported only whenjson_path_expressionmatches one of the following patterns:Thejson_path_expressionmustnotbe instrictmode.Keychain mode:$.[key|wildcard].[key|wildcard]...In this mode, a prefix span is generated for the inverted expression.Filter with end value mode (equality check):$.[key|wildcard]? (@.[key|wildcard].[key|wildcard]... == [string|number|null|boolean])In this mode, since the end value is fixed, a single value span is generated.The following edge cases arenotsupported:$$[*]$.a.b.c == 12,$.a.b.c > 12, or$.a.b.c < 12(operation expressions)$.a.b ? (@.a > 10)(filter with inequality check)#154631",
            "Thejson_path_expressionmustnotbe instrictmode.",
            "Keychain mode:$.[key|wildcard].[key|wildcard]...",
            "In this mode, a prefix span is generated for the inverted expression.",
            "Filter with end value mode (equality check):$.[key|wildcard]? (@.[key|wildcard].[key|wildcard]... == [string|number|null|boolean])",
            "In this mode, since the end value is fixed, a single value span is generated.",
            "The following edge cases arenotsupported:$$[*]$.a.b.c == 12,$.a.b.c > 12, or$.a.b.c < 12(operation expressions)$.a.b ? (@.a > 10)(filter with inequality check)#154631",
            "$.a.b.c == 12,$.a.b.c > 12, or$.a.b.c < 12(operation expressions)",
            "$.a.b ? (@.a > 10)(filter with inequality check)#154631",
            "The optimizer can now use table statistics that merge the latest full statistic with all newer partial statistics, including those over arbitrary constraints over a single span.#154755",
            "Two new changefeed metrics for tracking the max skew between a changefeed's slowest and fastest span/table have been added. The metrics are gauge metrics with the nameschangefeed.progress_skew.{span,table}.#154166",
            "The metricssql.select.started.count,sql.insert.started.count,sql.update.started.count, andsql.delete.started.countare now emitted with labels under the common metric namesql.started.count, using aquery_typelabel to distinguish each operation.#154388",
            "Added the cluster settingstorage.unhealthy_write_duration(defaults to 20s), which is used to indicate to the allocator that a store's disk is unhealthy. The cluster settingkv.allocator.disk_unhealthy_io_overload_scorecontrols the overload score assigned to a store with an unhealthy disk, where a higher score results in preventing lease or replica transfers to the store, or shedding of leases by the store. The default value of that setting is 0, so the allocator behavior is unaffected.#154459",
            "Added cluster settingsql.schema.approx_max_object_count(default: 20,000) to prevent creation of new schema objects when the limit is exceeded. The check uses cached table statistics for performance and is approximate - it may not be immediately accurate until table statistics are updated by the background statistics refreshing job. Clusters that have been running stably with a larger object count should raise the limit or disable the limit by setting the value to 0. In future releases, the default value for this setting will be raised as more CockroachDB features support larger object counts.#154576",
            "Vector index backfill will now properly track job progress in SHOW JOBS output.#154261",
            "A bug has been fixed that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when theexpect_and_ignore_not_visible_columns_in_copysetting was enabled. This bug has been present sinceexpect_and_ignore_not_visible_columns_in_copywas introduced in v22.1.0.#154289",
            "Idle latencyon theTransaction Detailspage in the DB Console is now reported more accurately. Previously, transactions that used prepared statements (e.g., with placeholders) overcounted idle time, while those that included observer statements (common in the SQL CLI) undercounted it.#154385",
            "Fixed a bug whereRESTOREof a database with aSECONDARY REGIONdid not apply the lease preferences for that region.#154659",
            "A bug where a changefeed could perform many unnecessary job progress saves during an initial scan has been fixed.#154709",
            "A bug where a changefeed targeting only a subset of a table's column families could become stuck has been fixed.#154915",
            "The cost of generic query plans is now calculated based on worst-case selectivities for placeholder equalities (e.g., x = $1). This reduces the chance of suboptimal generic query plans being chosen whenplan_cache_mode=auto.#154899"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-beta.1",
        "date": "October 1, 2025",
        "changes": [
            "The logical cluster now uses an external connection and automatically updates its configuration when that connection changes.#149261",
            "Includednum_txn_retriesandnum_txn_auto_retriesinto thecrdb_internal.{cluster,node}_queriesvirtual tables as well as output of SHOW QUERIES. These columns, when not NULL, have the same information asnum_retriesandnum_auto_retriescolumns ofcrdb_internal.{cluster,node}_transactionsvirtual tables for the same transaction in which the active query is executed.#149503",
            "Tables with vector indexes will no longer be taken offline while the vector index builds.#151074",
            "Introduced the unimplementedSHOW INSPECT ERRORSstatement.#151674",
            "Added a built-in function,crdb_internal.request_transaction_bundle, that allows users to request a transaction diagnostics bundle for a specified transaction fingerprint ID.#153608",
            "Implemented thepg_get_function_arg_defaultbuiltin function. This also causes theinformation_schema.parameters(parameter_default)column to be populated correctly.#153625",
            "Removed thebulkio.backup.deprecated_full_backup_with_subdir.enabledcluster setting, since backups will now fail if this is set to true.#153628",
            "Raised the cache size for the storage engine's block cache to 256 MiB. Note that production systems should always configure this setting.#153739",
            "Deprecated the bespoke restore and import event logs. For any deployment that is reliant on those logs, use the status change event log which now plumbs the SQL user that owns the job.#153889",
            "Theincremental_locationoption is now deprecated and will be removed in a future release. This feature was added so customers could define different TTL policies for incremental backups vs full backups. Users can still do this since incremental backups are by default stored in a distinct directory relative to full backups ({collection_root}/incrementals).#153890",
            "In the DB Console, theActive Executionstable on the Statements and Transactions pages now includes a newIsolation Levelcolumn. The Sessions page also includes a newDefault Isolation Levelcolumn.#153617",
            "Fixed a bug where a CockroachDB node could crash when executing DO statements that contain user-defined types (possibly non-existing) in non-default configuration.#151849",
            "Fixed a deadlock inDROP COLUMN CASCADEoperations when dropping columns referenced bySTOREDcomputed columns.#153683",
            "Fixed a bug whereALTER POLICYwas incorrectly dropping dependency tracking for functions, sequences, or types in policy expressions.#153787",
            "Fixed a bug where we would not show the pgwireRowDescriptionforEXECUTEstatements that were themselves prepared using the pgwireParsecommand.#153905",
            "Fixed a runtime error that could be hit if a new secondary index had a name collision with a primary index.#153986",
            "Fixed a bug where the presence of duplicate temporary tables in a backup caused the restore to fail with arestoring table desc and namespace entries: table already existserror. Informs: #153722#153724"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-alpha.2",
        "date": "September 23, 2025",
        "changes": [
            "CREATE USERandGRANTrole operations now wait for full-cluster visibility of the new user table version rather than blocking on convergence.#150747",
            "Introduced theinspect_errorssystem table.#151821",
            "You now manually create single-column partial statistics on boolean predicate expressions that can become simple index scans. These statistics can be created by adding a constrainingWHEREexpression toCREATE STATISTICS.",
            "Added thebulkio.import.row_count_validation.unsafe.enabledcluster setting (default:false), which triggers an asynchronousINSPECTjob at the end of anIMPORTto validate row counts.#153294",
            "Added the cluster settingkvadmission.use_range_tenant_id_for_non_admin.enabled, which can be used to disable the behavior where Admission Control uses the range's tenant ID for non-admin requests. This behavior is enabled by default.#152181",
            "CockroachDB now logs access to internal system tables and schemas considered unsafe (e.g.,crdb_internalandsystem). A message is emitted to theSENSITIVE_ACCESSlog channel when a user overrides theallow_unsafe_internalssetting or is denied access to these areas.#152532",
            "A newchangefeedfile group that collects changefeed logs has been added to the default logging configuration.#153381",
            "Fixed a bug where theschema_lockedstorage parameter was not being enforced on theTRUNCATEcommand, which could cause changefeed jobs to fail.#152932",
            "Fixed a bug introduced in v21.2 whereIMPORToperations with multiple CSV files could incorrectly reset the bulk summary after processing the first file, causing the actual progress to be overwritten with anilvalue.#153111",
            "Fixed a bug introduced in v25.1.0 that would cause a node panic if aSIGINTsignal was sent during the execution of aCHECK EXTERNAL CONNECTIONcommand.#153380",
            "Fixed a bug where index creation could fail due to validation errors if the schema change was retried or paused/resumed during the backfill.#153583",
            "Changefeeds will now periodically persist their entire span frontiers so that fewer duplicates will need to be emitted during restarts. The default persistence interval is 30s, but this can be configured with thechangefeed.progress.frontier_persistence.intervalcluster setting.#153491",
            "CockroachDB now prevents negative values from appearing in network and disk counters collected from the operating system. These values could previously drop below zero due to hardware changes. Affected counters now reset their baseline values automatically.#153048"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0-alpha.1",
        "date": "September 17, 2025",
        "changes": [
            "CockroachDB can now synchronize SQL role membership from thegroupsclaim contained in a JWT whenserver.jwt_authentication.authorization.enabled = true. The claim name and the fallbackuserinfoJSON key are configurable byserver.jwt_authentication.group_claimandserver.jwt_authentication.userinfo_group_keyrespectively. The behavior matches the existing LDAP role-sync feature.#147318",
            "CockroachDB can now synchronize SQL role membership from thegroupsclaim provided by an OpenID Connect (OIDC) Identity Provider whenserver.oidc_authentication.authorization.enabled = true. . At login, the DB Console gathers thegroupsclaim from the verified ID token and, when available, the access token (if a JWT). Any groups found in either token are combined and deduplicated. If no claim is present in either, the provider's/userinfoendpoint is queried for groups, as a final fallback.#147706",
            "The JWT Authorization settings which were added in#147318are no longer visible to users in v25.3. They will be re-introduced in v25.4.#149189",
            "The following provisioning usability metric counters were added for LDAP-based user provisioning.An enablement tracking counter for organizations enabling LDAP provisioning (auth.provisioning.ldap.enable)A counter for number of organizations & tenants which have enabled ldap to auto-provision users(auth.provisioning.ldap.begin).A counter for the number of auto-provisioned users (auth.provisioning.ldap.success).A telemetry counter for number of logins performed by provisioned users (auth.provisioning.login_success).#150476",
            "An enablement tracking counter for organizations enabling LDAP provisioning (auth.provisioning.ldap.enable)",
            "A counter for number of organizations & tenants which have enabled ldap to auto-provision users(auth.provisioning.ldap.begin).",
            "A counter for the number of auto-provisioned users (auth.provisioning.ldap.success).",
            "A telemetry counter for number of logins performed by provisioned users (auth.provisioning.login_success).#150476",
            "For virtual clusters, hot range logging is now performed by a single job on one node, rather than by tasks on every node.#145549",
            "The CREATE CHANGEFEED statement now supports theextra_headersoption, which can be used to specify extra headers for webhook and kafka sinks. This can be used to add headers to all messages sent to the sink.#146813",
            "Added new metrics:changefeed.stage.pts.create.latency,changefeed.stage.pts.manage.latency,changefeed.stage.pts.manage_error.latency, to measure the performance of managing protected ts records.#148471",
            "Added an OTLP log sink that exports logs in OpenTelemetry Protocol format over gRPC to compatible targets such asotel-collector, Datadog, and Loki.#148525",
            "Kafka v2 changefeed sinks now support a cluster setting that enables detailed error logging for messages exceeding Kafka v2 size limit.#148753",
            "The CockroachDB spatial libraries now rely on GEOS 3.12 instead of GEOS 3.11.#148859",
            "Changefeeds with the protobuf format now support theresolvedoption for emitting resolved timestamps.#149622",
            "Changefeeds using the protobuf format now support wrapped envelopes in kafka sinks#149696",
            "Restore jobs now log errors on retry to the job messages table.#149821",
            "A warning is now emitted when creating or altering a changefeed withresolvedormin_checkpoint_frequencyset below 500ms. This helps users understand the tradeoff between message latency and cluster CPU usage.#149975",
            "The protobuf format for changefeeds now support enriched envelopes.#150501",
            "Added HTTP mode to the OTLP sink, allowing logs to be exported to OpenTelemetry Protocol (OTLP) targets over HTTP. This enhancement enables agentless deployments, where logs can be sent directly to supported targets like Datadog or Grafana, without requiring an intermediary such as the OpenTelemetry Collector or Datadog Agent.#150655",
            "Addedheadersconfiguration option to OTLP log sink.#150696",
            "CockroachDB spatial libraries now rely on GEOS 3.13 instead of GEOS 3.12.#151186",
            "Reduced the maximum backoff for changefeed retries from 10 minutes to 1 minute, which results in faster recovery from transient errors.#146448",
            "Addedchangefeed.sink_backpressure_nanosmetric to track time spent waiting for quota when emitting to the sink.#150666",
            "The download phase of restore operations now will retry downloads before giving up, when faced with an error.#148821",
            "Fixed a memory accounting issue in the client certificate cache that caused multiple allocations to be reported for the same certificate. The cache now accurately tracks memory usage and includes a safeguard to prevent it from negatively affecting SQL operations.#151041",
            "Fixed a rare bug in restore where an object storage error on restore start could cause restore to report success without creating the restored tables or databases.#151148",
            "Tuned S3 client retry behavior to be more reliable in the presence of correlated errors.#151817",
            "Implemented thelevenshtein_less_equal(string, string, int)andlevenshtein_less_equal(string, string, int, int, int, int)built-in functions, which calculate the Levenshtein distance between two strings.#104649",
            "The owner of a database can now set default session variables per database using theALTER ROLE ALL IN DATABASE ... SETorALTER DATABASE ... SETcommands.#130547",
            "Added support for camelCase parameter names (e.g.,SharedAccessKeyName) in Azure Event Hub Kafka sink configuration#144735",
            "Added a newPROVISIONSRCrole option. This role option should be prefixed with the HBA auth method for provisioning, i.e.ldapfollowed by the IDP URI, for exampleldap:ldap.example.com. This is intended to be used only internally for user provisioning and should be view-only when checking set role options for a user.#147272",
            "Added a new cluster settingserver.provisioning.ldap.enabledwhich can be set totrueto conditionally enable user provisioning during SQL cluster authentication. The user authenticates with the LDAP server and CockroachDB will only validate identity lookup on IDP was successful for provisioning the user. All roles created thus will be privileged to perform SQL authentication and will mandatory have a role option forPROVISIONSRCset toldap:<idp_url>. Any group roles that are to be assigned via LDAP authorization must be pre created prior to the authentication start.#148200",
            "Added the ability to automatically provision users authenticating via JWT. This is controlled by the new cluster settingsecurity.provisioning.jwt.enabled. When set totrue, a successful JWT authentication for a non-existent user will create that user in CockroachDB. The newly created role will have thePROVISIONSRCrole option set tojwt_token:<issuer>, identifying the token's issuer as the source of the provisioned user.#149415",
            "TheCITEXTdata type is now supported, enabling case-insensitive comparisons forCITEXTcolumns. Internally,CITEXTis equivalent to using the undetermined level 2 collationund-u-ks-level2. For example, underCITEXT, the expression'test' = 'TEST'returnsTRUE.#147864",
            "The functionality provided by session variableenforce_home_region_follower_reads_enabledwas deprecated in v24.2.4 and is now removed. (The variable itself remains for backward compatibility but has no effect.) Note that the related session variableenforce_home_regionisnotdeprecated and still functions normally.#148314",
            "Added support for automatically determining the region column for aREGIONAL BY ROWtable using a foreign key constraint. The foreign key is specified by setting a new table storage parameterinfer_rbr_region_col_using_constraint, and must contain the region column. This can be useful for applications that are unable to guarantee that a child row is inserted or updated from the same region as the matching parent row.#148540",
            "Added support for invoking a UDF from a view query. Renaming or setting the schema on the routine is currently not allowed if it is referenced by a view.#148616",
            "Updated theSHOW CREATE FUNCTIONandSHOW CREATE PROCEDUREstatements to show fully qualified table names rather than assuming they are qualified with the current database.#148746",
            "Added thehas_system_privilegebuiltin function, which can be used to check if a user has the given system privilege.#149051",
            "Updated schema change job status messages to be more user-friendly and descriptive, instead of using internal schema change architecture terminology.#149096",
            "The logical cluster now uses an external connection and automatically updates its configuration when that connection changes.#149261",
            "Fixed a bug where extra quotes or escaped quote characters would be added to topic names in changefeeds. Can be turned off by settingfeature.changefeed.bare_table_namesto false.#149438",
            "The users with the role optionPROVISIONSRCassigned to them will be unable to change their own password overriding any config set for sql.auth.change_own_password.enabled cluster setting. Changing other role options still has the same privilege requirements as before (either CREATEROLE or CREATELOGIN, depending on the option). The role option for PROVISIONSRC is also only assignable and cannot be altered usingALTER rolecommand.#149463",
            "The session settingoptimizer_prefer_bounded_cardinalityis now enabled by default. This setting instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process.#149486",
            "The session settingoptimizer_min_row_count, which sets a lower bound on row count estimates for relational expressions during query planning, is now set to1by default.#149602",
            "WITH header_row flag is added to EXPORT. Returns error for non-csv type. Another row is prepended to the csv file with the column names.#149686",
            "Users can now ALTER EXTERNAL CONNECTION to change the external connection URI when granted UPDATE privilege on EXTERNAL CONNECTION. Fixes #98610#149869",
            "Thejson ? string,json ?& array,json ?| array, andarray && arrayoperators are now index-accelerated forINVERTED JOINstatements if there is an inverted index on the JSON column referenced on the left-hand side of the expression.#149898",
            "TheSHOW ROLESandSHOW USERScommands now include anestimated_last_login_timecolumn that displays the estimated timestamp of when each user last authenticated to the database. This column showsNULLfor users who have never logged in, and for existing users after upgrading to v25.3 until their next login. The tracking is performed on a best-effort basis and may not capture every login event.#150105",
            "Theoptionscolumn in the output ofSHOW ROLESandSHOW USERSis now returned as an array of strings (e.g.,{NOLOGIN,CREATEDB}) rather than as a single comma-separated string. This enables more efficient querying of role options using array functions likeunnest(). For example:SELECT * FROM [SHOW ROLES] AS r WHERE EXISTS (SELECT 1 FROM unnest(r.options) AS m(option) WHERE option LIKE 'SUBJECT=cn%');#148532",
            "The session settingoptimizer_min_row_count, which sets a lower bound on row count estimates for relational expressions during query planning, is now set to1by default.#150376",
            "LTREEis now supported with ancestry operators and with theconcatoperator. Specifically, CockroachDB now allowsltree @> ltree,ltree[] @> ltree,ltree @> ltree[],ltree <@ ltree,ltree[] <@ ltree, andltree <@ ltree[]binary comparisons, as well asltree[] ?@> ltree,ltree[] ?<@ ltree, andltree || ltreebinary operations. The?@>and?<@are new binary operators that return the first ltree (orNULL) that is an ancestor or descendant of the right ltree argument in the array.#150598",
            "Clusters utilizing cluster virtualization, such as those running Physical Cluster Replication (PCR), apply the same admission control (AC) pacing to various bulk operations used by clusters that are not running with cluster virtualization.#150633",
            "All PostgreSQL built-in functions forLTREEare now supported:subltree(),subpath(),nlevel(),index(),text2ltree(),ltree2text(), andlca(). While thelca()function in PostgreSQL specifically limits up to 8 LTREE args, the CockroachDBlca()function accepts any variable number of ltree args.#150647",
            "CREATE USERandGRANTrole operations now wait for full-cluster visibility of the new user table version rather than blocking on convergence.#150747",
            "Improved the optimizer to hoist projections above joins in more cases, which can lead to better query plans. This behavior can be enabled with the new session variableoptimizer_use_improved_hoist_join_project.#150887",
            "Previously, using a pausable portal with a procedure call could cause a panic, depending on the function body. Now, transaction control statements such as procedure calls (e.g.,CALL myfunc()) are disallowed within pausable portals.#151153",
            "Added theallow_unsafe_internalssession variable to gate access to system database internals. Default access is allowed to support testing.#151362",
            "Whensql_safe_updatesis enabled, theALTER TABLE ... LOCALITYstatement will be blocked when trying to convert an existing table toREGIONAL BY ROW, unless a region column has been added to the table. This protects against undesired behavior that causedUPDATEorDELETEstatements to fail against the table while the locality change was in progress.#151423",
            "Added metrics for statements executed within a stored procedure or function. The following metrics count statements that began execution, including those that failed:sql_routine_select_started_count,sql_routine_update_started_count,sql_routine_insert_started_count, andsql_routine_delete_started_count. The following metrics count only successful executions:sql_routine_select_count,sql_routine_update_count,sql_routine_insert_count, andsql_routine_delete_count. All counters are global and increment before the transaction is committed or aborted.#151689",
            "Introduced theinspect_errorssystem table.#151821",
            "Added a new session variable,disable_optimizer_rules, which allows users to provide a comma-separated list of optimizer rules to disable during query optimization. This allows users to avoid rules that are known to create a suboptimal query plan for specific queries.#151959",
            "The SQL observability statementsSHOW TRANSACTIONS,SHOW QUERIES, andSHOW SESSIONSnow include anisolation_levelcolumn that shows the isolation level of the active transaction, or the session's default isolation level when there is no active transaction.#152352",
            "The default value ofuse_soft_limit_for_distribute_scansession variable is nowtrue. This means that, by default, the soft limit (if available) will be used to determine whether a scan is \"large\" and, thus, should be distributed. For example, withestimated row count: 100 - 10,000, CockroachDB will use100as the estimate to compare against the value ofdistribute_scan_row_count_threshold.#152557",
            "The/health/restart_safetyendpoint indicates when it is unsafe to terminate a node.#142930",
            "Added the following cluster settings for configuring blob file rewrite compactions:storage.value_separation.rewrite_minimum_ageandstorage.value_separation.compaction_garbage_threshold.#148782",
            "The default value ofserver.mem_profile.total_dump_size_limit(which controls how much space can be used by automatically collected heap profiles) has been increased from 256MiB to 512MiB.#148848",
            "Added new experimental values for compression cluster settings to the storage engine.#148849",
            "Thestorage.value_separation.enabledcluster setting is now enabled by default. This enables value separation for SSTables, where values exceeding a certain size threshold are stored in separate blob files rather than inline in the SSTable. This helps improve write performance (write amplification) by avoiding rewriting such values during compactions.#148857",
            "A structured event is now logged to theSQL_SCHEMAchannel when theREFRESH MATERIALIZED VIEWstatement is executed.#149153",
            "Removed thestorage.columnar_blocks.enabledcluster setting; columnar blocks are always enabled.#149371",
            "A new feature is now available that automatically captures Go execution traces on a scheduled interval. This feature incurs a performance penalty and is generally intended for use under the guidance of Cockroach Labs Support. It can be configured using the following cluster settings:obs.execution_tracer.interval: Enables the tracer and sets the interval for capturing traces. Set to a value greater than 0 to activate.obs.execution_tracer.duration: Specifies the duration for each captured trace.obs.execution_tracer.total_dump_size_limit: Sets the maximum disk space allowed for storing execution traces. Older traces are automatically deleted when this limit is reached.#149373",
            "obs.execution_tracer.interval: Enables the tracer and sets the interval for capturing traces. Set to a value greater than 0 to activate.",
            "obs.execution_tracer.duration: Specifies the duration for each captured trace.",
            "obs.execution_tracer.total_dump_size_limit: Sets the maximum disk space allowed for storing execution traces. Older traces are automatically deleted when this limit is reached.#149373",
            "Introduced the cluster settingsql.stats.error_on_concurrent_create_stats.enabled, which modifies how CockroachDB reacts to concurrent auto stats jobs. The default,true, maintains the previous behavior. Settingsql.stats.error_on_concurrent_create_stats.enabledtofalsewill cause the concurrent auto stats job to be skipped with just a log entry and no increased error counters.#149538",
            "The value ofsql.stats.error_on_concurrent_create_stats.enablednow defaults tofalse, suppressing error counters for auto stats jobs that fail due to concurrent stats jobs in progress.#149848",
            "Updated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#150771",
            "Addedauth.ldap.conn.latency.internalmetric to denote the internal authentication time for LDAP auth method.#151105",
            "Introduced two new logging channels:KV_EXECandCHANGEFEED. TheKV_EXECchannel is intended for KV events that do not fall into theKV_DISTRIBUTIONchannel. TheCHANGEFEEDchannel is intended for changefeed-related events that are currently logged to theTELEMETRYchannel. This change does not include logic to move existing logs to the new channels.#151692",
            "Restricted access to internal tables in thecrdb_internalschema. Only a predefined allowlist of internal objects is accessible when the session variableallow_unsafe_internalsis enabled or when the caller is internal.#151804",
            "In a future major release, changefeed events will be logged to theCHANGEFEEDlogging channel instead ofTELEMETRY. To test the impact of this change before upgrading, set the cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects changefeed logs to theCHANGEFEEDchannel and should be tested only in non-production environments.#151807",
            "In a future major release, SQL performance events will be logged to theSQL_EXECchannel instead of theSQL_PERFandSQL_INTERNAL_PERFchannels. To test the impact of this change, you can set the new cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects SQL performance logs to theSQL_EXECchannel. This setting should not be used in production environments, as it may affect downstream logging pipelines.#151827",
            "Restricted access to allcrdb_internalbuilt-ins unless the session variableallow_unsafe_internalsis set totrue, or the caller is internal.#151887",
            "In a future major release,sampled_queryandsampled_transactionevents will move from theTELEMETRYchannel to theSQL_EXEClogging channel. To test for potential logging pipeline impacts of these changes, setlog.channel_compatibility_mode.enabledtofalse. Avoid testing in production, as this setting changes live log behavior.#151949",
            "Delegate queries (such asSHOW DATABASES) are now excluded from unsafe SQL checks that restrict access to thesystemdatabase andcrdb_internalschema. This change ensures that these commands continue to function even when access to internal components is otherwise restricted.#152084",
            "The Physical Cluster Replication (PCR) reader tenant is always destroyed on cutover#152509",
            "SYSTEMprivileges are inherited in read-only mode in standby Physical Cluster Replication (PCR) clusters.#149708",
            "You can now output transaction traces to the logs in Jaeger-compatible JSON format. This is controlled by thesql.trace.txn.jaeger_json_output.enabledcluster setting, which is disabled by default. When enabled, traces triggered by probabilistic sampling or statement latency thresholds will be formatted for easier ingestion by tools that support the Jaeger tracing format.#151414",
            "You can now exclude internal transactions from probabilistic transaction tracing and latency-based logging by setting thesql.trace.txn.include_internal.enabledcluster setting to false. This setting is enabled by default to preserve the current behavior, but disabling it is recommended when debugging customer workloads to reduce noise in trace output.#151433",
            "The internal generator used bycockroach workloadnow supports parsing DDL schemas into a structured YAML format, enabling more flexible and detailed workload generation configurations.#149513",
            "Improved the performance of thedebug zipquery that collectstransaction_contention_eventsdata. This change reduces the risk of encountering memory budget exceeded or query execution canceled due to statement timeout errors.#149570",
            "Thecockroach workloadinternals have been updated with built-in generators and wrappers for various SQL typesenabling modular, extensible, and reusable workload data generation.#149728",
            "Updated the internals ofcockroach workloadso there is one primary CLI entry point for workload generation, wiring together DDL parsing, schema construction, generator factory, and output routines.#150321",
            "Updated the redaction policy for cluster settings indebug zipoutput. All \"sensitive\" settings are now redacted in all debug zips, whether or not redaction is explicitly requested. In redacted debug zips, both \"sensitive\" and \"non-reportable\" settings are redacted. This replaces the previous behavior, which redacted all string-type settings only in redacted debug zips.#150364",
            "Added SQL workload extraction and rewriting support to the internals ofcockroach workload, enabling placeholderdriven data-generation workflows from CockroachDB debug logs.#150614",
            "Updated the help text for the--databaseand--urlCLI flags to document support for virtual cluster syntax. The--databaseflag now shows examples of both simple database names and thecluster:virtual-cluster/databaseformat. The--urlflag examples now include the virtual cluster syntax in PostgreSQL connection URLs.#150624",
            "Updatedcockroach workloadinternals to read inittime schema and SQL artifacts and run SQL workloads with placeholderdriven data generation.#150836",
            "Added support for simpleCHECKconstraints and bit/bytes column generators tocockroach workload's workload generator.#150926",
            "Added a new file,cluster_settings_history.txt, to debug zips. This file contains a history of cluster setting changes based on the system event log table. The history is only available while the corresponding events remain in the table. Sensitive settings are always redacted, and non-reportable settings are redacted when the debug zip is generated with redaction enabled.#151066",
            "Renamed the 'Hot Ranges' page in the DB Console to 'Top Ranges' to clarify that it shows the highest-ranked ranges by various metrics, not necessarily those experiencing high activity.#149713",
            "Fixed a bug whereDrop Unused Indexrecommendations were not populated on the Schema Insights tab after a hard refresh of the Insights page.#149838",
            "Updated the DB Console so that the tenant dropdown now appears in insecure mode when multiple virtual clusters are available.#150535",
            "Fixed an issue where hot range logging for virtual clusters omitted some hot ranges.#143775",
            "Removed unnecessary Kafka topic creation that could cause changefeed startup to fail when usingchangefeed.new_kafka_sink_enabled=false.#146476",
            "Fixed a bug that would cause aCALLstatement executed via a portal in the extended wire protocol to result in an error likeunknown portal \"\"if the stored procedure containedCOMMITorROLLBACKstatements. The bug had existed since PL/pgSQL transaction control statements were introduced in v24.1. The fix is off by default in versions prior to v25.3.#147923",
            "Fixed a bug present since v24.1 where the allocator could make rebalancing decisions based on stale data, failing to account for recent local lease transfers not yet reflected in store capacity or gossip.#148476",
            "A bug where a changefeed that was created before v25.2 could fail after upgrading to v25.2 with the error messageboth legacy and current checkpoint set on change aggregator spechas now been fixed.#148617",
            "CockroachDB now supports decodingVECTORandBOX2Dtypes from the binary format of the PostgreSQL extended protocol (pgwire).#148719",
            "TheRESET ALLstatement no longer affects the following session variables:is_superuserrolesession_authorizationtransaction_isolationtransaction_prioritytransaction_statustransaction_read_onlyThis better matches PostgreSQL behavior forRESET ALL. In addition, theDISCARD ALLstatement no longer errors whendefault_transaction_use_follower_readsis enabled.#148770",
            "is_superuser",
            "session_authorization",
            "transaction_isolation",
            "transaction_priority",
            "transaction_status",
            "transaction_read_only",
            "CockroachDB now prohibitsORDER BYand join equality operations onREFCURSORtypes, matching PostgreSQL behavior.#148863",
            "Previously, CockroachDB could hit an internal error when performing aDELETE,UPDATE, orUPSERTwhere the initial scan of the mutation is locking and is on a table different from the one being mutated. A possible workaround wasSET enable_implicit_select_for_update = false, but this could increase contention. The bug was introduced in v25.2 and is now fixed.#149093",
            "Fixes a race condition when advancing a changefeed aggregator's frontier. When hit, the race condition could result in an internal error that would shut down the kvfeed and cause the changefeed to retry.#149119",
            "CockroachDB now supports case-insensitive matching for keyword identifiers in JSONPath queries. Note that the special identifiersTRUE,FALSE, andNULLare parsed case-insensitively in CockroachDB, but are case-sensitive in PostgreSQL. For example,SELECT '$.active == TrUe'::jsonpath;succeeds in CockroachDB, but fails in PostgreSQL.#149251",
            "In v25.1, automatic partial statistics collection was enabled by default (by setting thesql.stats.automatic_partial_collection.enabledcluster setting totrue). Partial statistics collection may encounter certain expected scenarios that were previously reported as failed stats jobs with PostgreSQL error code55000. These errors are benign and are no longer reported. Instead, the stats job will be marked as \"succeeded,\" though no new statistics will be created.#149279",
            "Fixed a minor bug that caused inconsistent behavior with the very rarely used\"char\"type (distinct fromCHAR).#149433",
            "CockroachDB now allowsEXPLAINof mutation statements in read-only transaction mode, matching PostgreSQL behavior. Note thatEXPLAIN ANALYZEof mutations is still disallowed, since this variant actually executes the statement.#149449",
            "Fixed an issue where some SQL metrics were not reported whenserver.child_metrics.enabledwas enabled,server.child_metrics.include_aggregate.enabledwas disabled, andsql.metrics.application_name.enabledandsql.metrics.database_name.enabledwere also disabled. Specifically, metrics with no children now report their aggregate metrics regardless of theserver.child_metrics.include_aggregate.enabledcluster setting.#149540",
            "Fixed a bug where database login could fail during LDAP, JWT, or OIDC authentication if the user's external group memberships did not correspond to any existing roles in the database. The login will now succeed, and no roles will be granted or revoked in this scenario.#149638",
            "Fixed a slow memory leak that was introduced in v25.1.8, v25.2.1, v25.2.2, and v25.3 betas. The leak would accumulate whenever a node executed a part of the distributed plan (although the gateway node of the plan was not affected), and could only be mitigated by restarting the node.#149800",
            "Attempting to create a vector index with the legacy schema changer will now fail gracefully instead of crashing the node.#149812",
            "Improved split and scatter behavior forCREATE INDEXwhen statistics are available for key columns.#150238",
            "Fixed a bug that was preventing the row-level TTL table storage parameters (e.g.,ttl_select_batch_size,ttl_delete_batch_size,ttl_delete_rate_limit,ttl_select_rate_limit) from being set to0, which is their default value.#150253",
            "Fixed an issue where discarding zone configs on sequences did not actually remove the configuration.#150255",
            "Fixed a bug where modifying a changefeed withALTER CHANGEFEEDthat either unset or left thegc_protect_expires_afteroption unset would cause the changefeed's max PTS age to become unbounded instead of being set to the default value configured by thechangefeed.protect_timestamp.max_agecluster setting.#150283",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150291",
            "Fixed a bug where the entire schema would become inaccessible if a table was referenced as an implicit record type by a user-defined function (UDF) while the table was undergoing anIMPORT.#150350",
            "Fixed invalid zone configurations that were generated when adding a super region to a 3-region database with a secondary region and region survivability. Previously, this could result in assigning more than the allowed number of replicas.#150413",
            "Addressed a bug onschema_lockedtables when a column is dropped, andschema_lockedis toggled for the user.#150435",
            "Fixed thepg_catalog.pg_typeenties for the \"any\" and \"trigger\" pseudotypes.#150777",
            "Fixed an issue where Row Level Security (RLS) policies with missing dependencies during table-level restores could cause inconsistent state or restore failures.#151045",
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to go undetected, potentially causing incomplete backups.#151058",
            "Previously, CockroachDB could encounter an internal errortrying to add a column of UNKNOWN type at ...in rare cases when handlingCASEorORoperations. This bug was present since v20.2 and is now fixed.#151093",
            "Fixed a bug wheredebug.zipfiles collected from clusters withdisallow_full_table_scansenabled were missing system table data.#151185",
            "Fix handling of empty arrays in JSONPath lax mode comparisons. Empty arrays now return false for comparisons in lax mode and null in strict mode, matching PostgreSQL behavior.#151226",
            "Fixed a bug whereDROP USERsucceeded even though a role owned default privileges, which could leave invalid privilege entries in the system.#151472",
            "Fixed a bug where sequences could lose references to triggers, allowing them to be dropped incorrectly.#151546",
            "Previously, CockroachDB could incorrectly elevate the number of rows deleted on tables with multiple column families. The bug was present v19.2 and is now fixed. Note that the data was deleted correctly, but the \"rows affected\" number was wrong.#151563",
            "Added an automatic repair for dangling or invalid entries in thesystem.commentstable.#151737",
            "Previously, CockroachDB could hit an errorERROR: span with results after resume span...when evaluating some queries withORDER BY ... DESCin an edge case. This bug was present since v22.1 and is now fixed.#151774",
            "Fixed a bug where updating column default expressions would incorrectly remove sequence ownerships for the affected column.#151947",
            "Fixed a bug where executing certain statements withBETWEEN SYMMETRICexpressions could panic if used with values of different types, such as... b'bytes' BETWEEN SYMMETRIC 'a' AND 'c'.#151951",
            "Fixed a bug whereSHOW TABLESwould show inaccurate row counts if the most recent statistics collection was partial.#152033",
            "Fixed a bug that preventedRESTOREfrom working if there were computed columns orON UPDATEexpressions that referenced user-defined functions (UDFs). This bug was introduced in v25.3.0.#152193",
            "Fixed a bug that allowed foreign-key violations to result from some combinations of concurrentREAD COMMITTEDandSERIALIZABLEtransactions. If bothSERIALIZABLEand weaker-isolation transactions will concurrently modify rows involved in foreign-key relationships, theSERIALIZABLEtransactions must have the following session variables set in order to prevent any possible foreign-key violations:SET enable_implicit_fk_locking_for_serializable = on;SET enable_shared_locking_for_serializable = on;SET enable_durable_locking_for_serializable = on;#152245",
            "SET enable_implicit_fk_locking_for_serializable = on;",
            "SET enable_shared_locking_for_serializable = on;",
            "SET enable_durable_locking_for_serializable = on;#152245",
            "Added theuse_soft_limit_for_distribute_scansession variable (default:false), which controls whether CockroachDB uses the soft row count estimate when deciding whether an execution plan should be distributed. In v25.1, the physical planning heuristics were changed such that large constrained table scans, estimated to scan at least 10,000 rows (controlled viadistribute_scan_row_count_threshold), would force plan distribution whendistsql=auto. However, if the scan had a \"soft limit\" CockroachDB would still use the full estimate (for example,10,000inestimated row count: 10010,000), sometimes unnecessarily distributing queries and increasing latency. Theuse_soft_limit_for_distribute_scansession variable addresses this by allowing the planner to use the soft limit when deciding whether a scan is \"large\".#152300",
            "pg_class.pg_dependnow contains entries withdeptype='i'(internal) for identity columns that own sequences. These previously haddeptype='a'(auto).#152309",
            "Fixed a bug that caused an error when dropping a column and aUNIQUE WITHOUT INDEXconstraint that referenced it in the same transaction.#152447",
            "Fixed a bug where views could not reference thecrdb_regioncolumn from their underlying tables in expressions.#152670",
            "Some queries with filters of the formx IS NOT DISTINCT FROM ynow have more optimal query plans.#146494",
            "Mutation statements (UPDATEandDELETE) that perform lookup joins into multi-region tables (perhaps as part of aCASCADE) are now more likely to parallelize the lookups across ranges, improving their performance.#148186",
            "LIKEfilter expressions of the formx LIKE '%'are now normalized toTRUEifxis non-NULLwithin aSELECTexpression.#148763",
            "Filters of the formx LIKE '%'are now normalized tox IS NOT NULL, enabling performance improvements on both nullable and non-nullable columns. Previously, such filters were normalized directly toTRUE, which only applied to non-NULLcolumns.#149614",
            "Updated the storage engine to reduce write amplification by storing Raft log values in separate blob files. This reduces write bandwidth, especially on stores with many replicas. This in turn can increase throughput and reduce latency. This behavior is active as long as thestorage.value_separation.enabledcluster setting is enabled.#149712",
            "Improved the efficiency and throughput of catch-up scans used by Change Data Capture (CDC) and Physical Cluster Replication (PCR) in cases where substantial catch-up work is required.#150738",
            "Certain types of simple queries on tables with row-level security enabled are now more efficiently executed.#151337",
            "LTREEis now index-accelerated with the@>operator.#152353",
            "LTREEis now index-accelerated with the<@operator.#152353",
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152399",
            "Upgraded to Go 1.23.12#152207",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.4",
        "patch_version": "25.4.0",
        "date": "November 3, 2025",
        "changes": [
            "Observability",
            "CockroachDB Cloud",
            "Backward-incompatible changes",
            "Features that require upgrade finalization",
            "Key cluster setting changes",
            "Deprecations",
            "Known limitations",
            "Online table backfills: Add vector indexes without service interruption",
            "Distributed horizontal scaling: Automatically partition vector indexes across nodes as data grows, unlike single-node PostgreSQL pgvector",
            "Incremental index maintenance: No background rebuilds required when inserting or updating vectors",
            "Multiple distance metrics: L2 distance, cosine distance, and inner product for diverse ML workloads",
            "pgvector compatibility: Standard PostgreSQL vector operations and SQL semantics",
            "Unified architecture: Combine vector search with operational data, transactions, and consistency",
            "OIDC Authorization (DB Console): Automatically sync roles from ID tokens, access tokens, or userinfo endpoints",
            "JWT Authorization (SQL clients): Automatically sync roles from JWT group claims or userinfo endpoints",
            "JWT User Provisioning: Auto-create SQL users on first authentication with proper audit tagging",
            "Security-first design: Empty group lists block login; role changes apply on every authentication",
            "A Jaeger trace and text trace of the full transaction execution path.",
            "Individual Statement Diagnostic Bundles for each statement executed within the transaction.",
            "CHANGEFEED dedicated channel for Change Data Capture (CDC) logs, previously routed to DEV and TELEMETRY.",
            "KV_EXEC channel for KV execution logs, separated from general distribution logs.",
            "sampled_queryandsampled_transactionlogs moved from TELEMETRY toSQL_EXECfor better categorization.",
            "Improved Security: Enables the principle of least privilege by allowing users or services to monitor cluster performance without broader access to sensitive data or configuration.",
            "Targeted Access: Provides focused access to operational metrics, empowering teams to monitor health and performance efficiently.",
            "Enhanced Collaboration: Facilitates secure collaboration by allowing different teams (e.g., SREs, developers) to access relevant metrics without over-provisioned permissions.",
            "bulkio.backup.deprecated_full_backup_with_subdir.enabledRemoved thebulkio.backup.deprecated_full_backup_with_subdir.enabledcluster setting. This optional ability to specify a target subdirectory with theBACKUPcommand when creating a full backup was deprecated in v22.1.#153628",
            "sql.schema.approx_max_object_count(default:20000)Added cluster settingsql.schema.approx_max_object_countto prevent creation of new schema objects when the limit is exceeded. The check uses cached table statistics for performance and is approximate - it may not be immediately accurate until table statistics are updated by the background statistics refreshing job. Clusters that have been running stably with a larger object count should raise the limit or disable the limit by setting the value to0. In future releases, the default value for this setting will be raised as more CockroachDB features support larger object counts.#154576",
            "Partial statistics with constraining predicates: The ability to manually create single-column partial statistics on boolean predicate expressions using a constrainingWHEREclause inCREATE STATISTICSstatements. For details, refer to therelease note.",
            "Changefeed span frontier persistence: Changefeeds now periodically persist their entire span frontiers so that fewer duplicates need to be emitted during restarts. The default persistence interval is 30 seconds, configurable with thechangefeed.progress.frontier_persistence.intervalcluster setting. For details, refer to therelease note.",
            "changefeed.progress.frontier_persistence.interval(default:30s)Changefeeds will now periodically persist their entire span frontiers so that fewer duplicates will need to be emitted during restarts. The default persistence interval is 30s, but this can be configured with thechangefeed.progress.frontier_persistence.intervalcluster setting.#153491",
            "log.channel_compatibility_mode.enabled(default:true)In a future major release, changefeed events will be logged to theCHANGEFEEDlogging channel instead ofTELEMETRY. To test the impact of this change before upgrading, set the cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects changefeed logs to theCHANGEFEEDchannel and should be tested only in non-production environments.#151807In a future major release, SQL performance events will be logged to theSQL_EXECchannel instead of theSQL_PERFandSQL_INTERNAL_PERFchannels. To test the impact of this change, you can set the new cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects SQL performance logs to theSQL_EXECchannel. This setting should not be used in production environments, as it may affect downstream logging pipelines.#151827In a future major release,sampled_queryandsampled_transactionevents will move from theTELEMETRYchannel to theSQL_EXEClogging channel. To test for potential logging pipeline impacts of these changes, setlog.channel_compatibility_mode.enabledtofalse. Avoid testing in production, as this setting changes live log behavior.#151949",
            "In a future major release, changefeed events will be logged to theCHANGEFEEDlogging channel instead ofTELEMETRY. To test the impact of this change before upgrading, set the cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects changefeed logs to theCHANGEFEEDchannel and should be tested only in non-production environments.#151807",
            "In a future major release, SQL performance events will be logged to theSQL_EXECchannel instead of theSQL_PERFandSQL_INTERNAL_PERFchannels. To test the impact of this change, you can set the new cluster settinglog.channel_compatibility_mode.enabledtofalse. This redirects SQL performance logs to theSQL_EXECchannel. This setting should not be used in production environments, as it may affect downstream logging pipelines.#151827",
            "In a future major release,sampled_queryandsampled_transactionevents will move from theTELEMETRYchannel to theSQL_EXEClogging channel. To test for potential logging pipeline impacts of these changes, setlog.channel_compatibility_mode.enabledtofalse. Avoid testing in production, as this setting changes live log behavior.#151949",
            "sql.catalog.allow_leased_descriptors.enabled(default:false)Added thesql.catalog.allow_leased_descriptors.enabledcluster setting, which is false by default. When set to true, queries that access thepg_catalogorinformation_schemacan use cached leased descriptors to populate the data in those tables, with the tradeoff that some of the data could be stale.#154491",
            "sql.log.scan_row_count_misestimate.enabled(default:false)Added a cluster setting (sql.log.scan_row_count_misestimate.enabled) that enables logging a warning on the gateway node when optimizer estimates for scans are inaccurate. The log message includes the table and index being scanned, the estimated and actual row counts, the time since the last table stats collection, and the table's estimated staleness.#155123",
            "sql.stats.error_on_concurrent_create_stats.enabled(default:true)Introduced the cluster settingsql.stats.error_on_concurrent_create_stats.enabled, which modifies how CockroachDB reacts to concurrent auto stats jobs. The default,true, maintains the previous behavior. Settingsql.stats.error_on_concurrent_create_stats.enabledtofalsewill cause the concurrent auto stats job to be skipped with just a log entry and no increased error counters.#149538",
            "sql.trace.txn.include_internal.enabled(default:true)You can now exclude internal transactions from probabilistic transaction tracing and latency-based logging by setting thesql.trace.txn.include_internal.enabledcluster setting to false. This setting is enabled by default to preserve the current behavior, but disabling it is recommended when debugging customer workloads to reduce noise in trace output.#151433",
            "sql.trace.txn.jaeger_json_output.enabled(default:false)You can now output transaction traces to the logs in Jaeger-compatible JSON format. This is controlled by thesql.trace.txn.jaeger_json_output.enabledcluster setting, which is disabled by default. When enabled, traces triggered by probabilistic sampling or statement latency thresholds will be formatted for easier ingestion by tools that support the Jaeger tracing format.#151414",
            "storage.unhealthy_write_duration(default:20s)Added the cluster settingstorage.unhealthy_write_duration(defaults to 20s), which is used to indicate to the allocator that a store's disk is unhealthy. The cluster settingkv.allocator.disk_unhealthy_io_overload_scorecontrols the overload score assigned to a store with an unhealthy disk, where a higher score results in preventing lease or replica transfers to the store, or shedding of leases by the store. The default value of that setting is 0, so the allocator behavior is unaffected.#154459",
            "feature.vector_index.enablednow defaults totrue. Vector indexing is now enabled by default.#155561",
            "storage.value_separation.enablednow defaults totrue. This enablesvalue separationfor SSTables, where values exceeding a certain size threshold are stored in separate blob files rather than inline in the SSTable. This helps improve write performance (write amplification) by avoiding rewriting such values during compactions.#148857",
            "storage.columnar_blocks.enabledRemoved thestorage.columnar_blocks.enabledcluster setting; columnar blocks are always enabled.#149371",
            "sql.ttl.replan_flow_thresholdUpdated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#150771",
            "Updated the redaction policy for cluster settings indebug zipoutput. All \"sensitive\" settings are now redacted in all debug zips, whether or not redaction is explicitly requested. In redacted debug zips, both \"sensitive\" and \"non-reportable\" settings are redacted. This replaces the previous behavior, which redacted all string-type settings only in redacted debug zips.#150364",
            "Added a new file,cluster_settings_history.txt, to debug zips. This file contains a history of cluster setting changes based on the system event log table. The history is only available while the corresponding events remain in the table. Sensitive settings are always redacted, and non-reportable settings are redacted when the debug zip is generated with redaction enabled.#151066",
            "The functionality provided by session variableenforce_home_region_follower_reads_enabledwas deprecated in v24.2.4 and is now removed. (The variable itself remains for backward compatibility but has no effect.) Note that the related session variableenforce_home_regionisnotdeprecated and still functions normally.#148314",
            "The cluster settingsstorage.columnar_blocks.enabledandbulkio.backup.deprecated_full_backup_with_subdir.enabledhave been removed. For details, refer toRemoved settings.",
            "The bespoke restore and import event logs have been deprecated. For any deployment that is reliant on those logs, use the status change event log which now plumbs the SQL user that owns the job.#153889",
            "Theincremental_locationbackup option is now deprecated and will be removed in a future release. This feature was added so customers could define different TTL policies for incremental backups vs full backups. Users can still do this since incremental backups are by default stored in a distinct directory relative to full backups ({collection_root}/incrementals).#153890"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.6",
        "date": "December 12, 2025",
        "changes": [
            "A mechanism that prevents unsafe replication changes from causing loss of quorum now functions correctly. An internal function has been fixed to properly return errors, enhancing the reliability of replication safeguards.#156522",
            "Fixed a bug where the \"atomic\"COPYcommand (controlled via thecopy_from_atomic_enabledsession setting,trueby default) could encounterRETRY_COMMIT_DEADLINE_EXCEEDEDtransaction errors if the whole command took 1 minute or more. This bug occurred only when the vectorized engine was used forCOPY.#156694",
            "Attempting to create a vector index with the legacy schema changer will now fail gracefully instead of crashing the node.#156781",
            "Fixed a bug that could cause internal errors for queries using generic query plans withNULLplaceholder values.#156978",
            "Fixed a bug where CockroachDB could encounter an internal error when evaluating aCOPY FROMcommand in a transaction after it was rolled back to a savepoint. The bug was present since before v23.2.#157038",
            "Fixed a bug where CockroachDB could encounter avector encoder doesn't support ForcePut yeterror when executingCOPYcommands concurrently with certain schema changes. The bug had existed since before v23.2.#157199",
            "Fixed a bug that could cause a schema change to be stuck in the reverting state if theinfer_rbr_region_col_using_constraintstorage parameter was being set at the same time as adding a constraint that had a foreign key violation.#157843",
            "The cost of generic query plans is now calculated based on worst-case selectivities for placeholder equalities (e.g.,x = $1). This reduces the chance of suboptimal generic query plans being chosen whenplan_cache_mode=auto.#156791",
            "Span config reconciliation jobs no longer fail on the destination after failover from a PCR stream of a system virtual cluster.#156811"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.5",
        "date": "November 14, 2025",
        "changes": [
            "Added thesql.statements.bytes_read.countmetric that counts the number of bytes scanned by SQL statements.#156592",
            "Added thesql.statements.index_rows_written.countmetric that counts the number of primary and secondary index rows modified by SQL statements.#156592",
            "Added thesql.statements.rows_read.countmetric that counts the number of index rows read by SQL statements.#156592",
            "Added thesql.statements.index_bytes_written.countmetric that counts the number of primary and secondary index bytes modified by SQL statements.#156592",
            "Fixed a bug where the job responsible for compacting stats for the SQL activity state could enter an unschedulable state.#155964",
            "Fixed a bug where CockroachDB didn't include reads and writes performed by routines (user-defined functions and stored procedures) as well as apply joins into thebytes read,rows read, androws writtenstatement execution statistics. The bug had been present since before v23.2.#156501",
            "Fixed a bug where changefeeds using CDC queries could sometimes unexpectedly fail after a schema change with a descriptor retrieval error.#156551"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.4",
        "date": "October 30, 2025",
        "changes": [
            "Fixed a bug in thecockroach node draincommand where draining a node using virtual clusters (such as clusters running Physical Cluster Replication (PCR)) could return before the drain was complete, possibly resulting in shutting down the node while it still had active SQL clients and range leases.#156313"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.3",
        "date": "October 17, 2025",
        "changes": [
            "Added the cluster settingkvadmission.use_range_tenant_id_for_non_admin.enabled, which can be used to disable the behavior where admission control uses the range's tenant ID for non-admin requests. This behavior is disabled by default.#153460",
            "Fixed a bug where anINSERTstatement could fail with a type checking error while adding aBIT(n)column.#152965",
            "Fixed a bug where index creation could fail due to validation errors if the schema change was retried or paused/resumed during the backfill.#153597",
            "Fixed a bug introduced in v25.1.0 that would cause a node panic if aSIGINTsignal was sent during the execution of aCHECK EXTERNAL CONNECTIONcommand.#153602",
            "Fixed a bug whereALTER POLICYwas incorrectly dropping dependency tracking for functions, sequences, or types in policy expressions.#153804",
            "Fixed a bug introduced in v25.1 where CockroachDB nodes could crash when executingDOstatements that referenced (possibly nonexistent) user-defined types in non-default configurations. The crash only occurred if additional logging was enabled (for example, with thesql.log.all_statements.enabledcluster setting).#153913",
            "Fixed a runtime error that could be hit if a new secondary index had a name collision with a primary index.#154016",
            "Fixed a bug where theschema_lockedstorage parameter was not being enforced on theTRUNCATEcommand, which could cause changefeed jobs to fail.#154041",
            "Fixed a bug that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when the session settingexpect_and_ignore_not_visible_columns_in_copywas enabled. This bug was introduced withexpect_and_ignore_not_visible_columns_in_copyin v22.1.0.#154286",
            "Disabled thekv.lock_table.unreplicated_lock_reliability.split.enabledfeature, which could lead to a node crash.#155414",
            "Fixed a bug where the presence of duplicate temporary tables in a backup caused the restore to fail with an error containing the textrestoring table desc and namespace entries: table already exists.#154397"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.2",
        "date": "September 22, 2025",
        "changes": [
            "Introduced support for running CockroachDB on s390x. Production binaries are delivered via IBM Passport Advantage.",
            "Added a new session variable,disable_optimizer_rules, which allows users to provide a comma-separated list of optimizer rules to disable during query optimization. This allows users to avoid rules that are known to create a suboptimal query plan for specific queries.#152350",
            "Whensql_safe_updatesis enabled, theALTER TABLE ... LOCALITYstatement will be blocked when trying to convert an existing table toREGIONAL BY ROW, unless a region column has been added to the table. This protects against undesired behavior that causedUPDATEorDELETEstatements to fail against the table while the locality change was in progress.#152594",
            "auth.ldap.conn.latency.internalhas been added to denote the internal authentication time for ldap auth method.#152341",
            "Addressed a bug onschema_lockedtables when a column is dropped, andschema_lockedis toggled for the user.#151527",
            "Fixed a bug that could cause excessive memory allocations when compacting timeseries keys.#151815",
            "Fixed a bug whereDROP USERsucceeded even though a role owned default privileges, which could leave invalid privilege entries in the system.#151818",
            "Previously, CockroachDB could hit an errorERROR: span with results after resume span...when evaluating some queries withORDER BY ... DESCin an edge case. This bug was present since v22.1 and is now fixed.#152138",
            "Fixed a bug whereSHOW TABLESwould show inaccurate row counts if the most recent statistics collection was partial.#152200",
            "Fixed a bug that preventedRESTOREfrom working if there were computed columns orON UPDATEexpressions that referenced user-defined functions (UDFs). This bug was introduced in v25.3.0.#152217",
            "Fixed a bug where updating column default expressions would incorrectly remove sequence ownerships for the affected column.#152315",
            "Fixed a bug that allowed foreign-key violations to result from some combinations of concurrentREAD COMMITTEDandSERIALIZABLEtransactions. If bothSERIALIZABLEand weaker-isolation transactions will concurrently modify rows involved in foreign-key relationships, theSERIALIZABLEtransactions must have the following session variables set in order to prevent any possible foreign-key violations:SET enable_implicit_fk_locking_for_serializable = on;SET enable_shared_locking_for_serializable = on;SET enable_durable_locking_for_serializable = on;#152374",
            "SET enable_implicit_fk_locking_for_serializable = on;",
            "SET enable_shared_locking_for_serializable = on;",
            "SET enable_durable_locking_for_serializable = on;#152374",
            "Added an automatic repair for dangling or invalid entries in thesystem.commentstable.#152473",
            "Added theuse_soft_limit_for_distribute_scansession variable (default:false), which controls whether CockroachDB uses the soft row count estimate when deciding whether an execution plan should be distributed. In v25.1, the physical planning heuristics were changed such that large constrained table scans, estimated to scan at least 10,000 rows (controlled viadistribute_scan_row_count_threshold), would force plan distribution whendistsql=auto. However, if the scan had a \"soft limit\" CockroachDB would still use the full estimate (for example,10,000inestimated row count: 10010,000), sometimes unnecessarily distributing queries and increasing latency. Theuse_soft_limit_for_distribute_scansession variable addresses this by allowing the planner to use the soft limit when deciding whether a scan is \"large\".#152556",
            "Fixed a bug where views could not reference thecrdb_regioncolumn from their underlying tables in expressions.#152680",
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152632",
            "Tunes S3 client retry behavior to be more reliable in the presence of correlated errors.#151873"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.1",
        "date": "August 29, 2025",
        "changes": [
            "Updated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#151483",
            "Fixed a bug where the entire schema would become inaccessible if a table was referenced as an implicit record type by a user-defined function (UDF) while the table was undergoing anIMPORT.#150440",
            "Fixed invalid zone configurations that were generated when adding a super region to a 3-region database with a secondary region and region survivability. Previously, this could result in assigning more than the allowed number of replicas.#150620",
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to go undetected, potentially causing incomplete backups.#151080",
            "Fixed a memory accounting issue in the client certificate cache that caused multiple allocations to be reported for the same certificate. The cache now accurately tracks memory usage and includes a safeguard to prevent it from negatively affecting SQL operations.#151136",
            "Previously, CockroachDB could encounter an internal errortrying to add a column of UNKNOWN type at ...in rare cases when handlingCASEorORoperations. This bug was present since v20.2 and is now fixed.#151160",
            "Fixed a bug wheredebug.zipfiles collected from clusters withdisallow_full_table_scansenabled were missing system table data.#151247",
            "Fixed a bug where sequences could lose references to triggers, allowing them to be dropped incorrectly.#151593",
            "Previously, CockroachDB could hit an errorERROR: span with results after resume span...when evaluating some queries withORDER BY ... DESCin an edge case. This bug was present since v22.1 and is now fixed.#152183",
            "Updated Go version to 1.23.11.#150868"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-rc.1",
        "date": "July 23, 2025",
        "changes": [
            "TheCITEXTdata type is now supported, enabling case-insensitive comparisons forCITEXTcolumns. Internally,CITEXTis equivalent to using the undetermined level 2 collationund-u-ks-level2. For example, underCITEXT, the expression'test' = 'TEST'returnsTRUE.#149819",
            "Added support for automatically determining the region column for aREGIONAL BY ROWtable using a foreign key constraint. The foreign key is specified by setting a new table storage parameterinfer_rbr_region_col_using_constraint, and must contain the region column. This can be useful for applications that are unable to guarantee that a child row is inserted or updated from the same region as the matching parent row.#150366",
            "The session settingoptimizer_min_row_count, which sets a lower bound on row count estimates for relational expressions during query planning, is now set to1by default.#150376",
            "Theoptionscolumn in the output ofSHOW ROLESandSHOW USERSis now returned as an array of strings (e.g.,{NOLOGIN,CREATEDB}) rather than as a single comma-separated string. This enables more efficient querying of role options using array functions likeunnest(). For example:SELECT * FROM [SHOW ROLES] AS r WHERE EXISTS (SELECT 1 FROM unnest(r.options) AS m(option) WHERE option LIKE 'SUBJECT=cn%');#149537",
            "TheSHOW ROLESandSHOW USERScommands now include anestimated_last_login_timecolumn that displays the estimated timestamp of when each user last authenticated to the database. This column showsNULLfor users who have never logged in, and for existing users after upgrading to v25.3 until their next login. The tracking is performed on a best-effort basis and may not capture every login event.#149537",
            "A new feature is now available that automatically captures Go execution traces on a scheduled interval. This feature incurs a performance penalty and is generally intended for use under the guidance of Cockroach Labs Support. This feature can be configured using the following cluster settings:obs.execution_tracer.interval: Enables the tracer and sets the interval for capturing traces. Set to a value greater than 0 to activate.obs.execution_tracer.duration: Specifies the duration for each captured trace.obs.execution_tracer.total_dump_size_limit: Sets the maximum disk space allowed for storing execution traces. Older traces are automatically deleted when this limit is reached.#149705",
            "obs.execution_tracer.interval: Enables the tracer and sets the interval for capturing traces. Set to a value greater than 0 to activate.",
            "obs.execution_tracer.duration: Specifies the duration for each captured trace.",
            "obs.execution_tracer.total_dump_size_limit: Sets the maximum disk space allowed for storing execution traces. Older traces are automatically deleted when this limit is reached.#149705",
            "The value ofsql.stats.error_on_concurrent_create_stats.enablednow defaults tofalse, suppressing error counters for auto stats jobs that fail due to concurrent stats jobs in progress.#149857",
            "Fixed a slow memory leak that was introduced in v25.1.8, v25.2.1, v25.2.2, and v25.3 betas. The leak would accumulate whenever a node executed a part of the distributed plan (the gateway node of the plan was not affected), and could only be mitigated by restarting the node.#149920",
            "Fixed an issue where some SQL metrics were not reported whenserver.child_metrics.enabledwas enabled,server.child_metrics.include_aggregate.enabledwas disabled, andsql.metrics.application_name.enabledandsql.metrics.database_name.enabledwere also disabled. Specifically, metrics with no children now report their aggregate metrics regardless of theserver.child_metrics.include_aggregate.enabledcluster setting.#149929",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150296",
            "Fixed an issue where discarding zone configs on sequences did not actually remove the configuration.#150360",
            "Mutation statements (UPDATEandDELETE) that perform lookup joins into multi-region tables (perhaps as part of aCASCADE) are now more likely to parallelize the lookups across ranges, improving their performance.#150016"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-beta.3",
        "date": "July 14, 2025",
        "changes": [
            "Added support for invoking a UDF from a view query. Renaming or setting the schema on the routine is currently not allowed if it is referenced by a view.#149514",
            "The session settingoptimizer_prefer_bounded_cardinalityis now enabled by default. This setting instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process.#149675",
            "Fixed a bug that would cause aCALLstatement executed via a portal in the extended wire protocol to result in an error likeunknown portal \"\"if the stored procedure containedCOMMITorROLLBACKstatements. The bug had existed since PL/pgSQL transaction control statements were introduced in v24.1. The fix is off by default in versions prior to v25.3.#149385",
            "In v25.1, automatic partial statistics collection was enabled by default (by setting thesql.stats.automatic_partial_collection.enabledcluster setting totrue). Partial statistics collection may encounter certain expected scenarios that were previously reported as failed stats jobs with PostgreSQL error code55000. These errors are benign and are no longer reported. Instead, the stats job will be marked as \"succeeded,\" though no new statistics will be created.#149626"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-beta.2",
        "date": "July 9, 2025",
        "changes": [
            "For virtual clusters, hot range logging is now performed by a single job on one node, rather than by tasks on every node.#148926",
            "CockroachDB now prohibitsORDER BYand join equality operations onREFCURSORtypes, matching PostgreSQL behavior.#149292",
            "Fixed an issue where CockroachDB could hit an internal error when performing aDELETE,UPDATE, orUPSERTwhere the initial scan of the mutation is locking and is on a table different from the one being mutated. A possible workaround wasSET enable_implicit_select_for_update = false, but this could increase contention. The bug was introduced in v25.2 and is now fixed.#149302"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-beta.1",
        "date": "July 2, 2025",
        "changes": [
            "Directionality may no longer be assigned to any vector index column. Prefix columns are not scannable in a vector index, so directionality is not relevant to them.#147307",
            "Changed the basic sequence caching option to cache at the per-node level by default. ThePER SESSION CACHEsequence option is added to provide the previous per-session cache behavior.#148290",
            "Removed the 'started' column inSHOW JOBS, which was a duplicate of the 'created' column.#148464",
            "Introduced the following cluster settings for enabling and configuringvalue separation in the storage engine:storage.value_separation.enabled,storage.value_separation.minimum_size, andstorage.value_separation.max_reference_depth.#148535",
            "Non-admin users no longer have access to changefeed jobs they do not own and which are not owned by a role of which they are a member, regardless of whether they have theCHANGEFEEDprivilege on the table or tables those jobs may be watching. Admin users, or those with globalSHOWJOB/CONTROLJOBprivileges, can still interact with all jobs, regardless of ownership.#148537",
            "In order to selectively capture traces for transactions running in an active workload without having to capture them via statement diagnostic bundles, customers can now use thesql.trace.txn.sample_ratecluster setting to enable tracing for a fraction of their workload. Thesql.trace.txn.enable_thresholdwill still need to be set to a positive value to provide a filter for how slow a transaction needs to be after being sampled to merit emitting a trace. Traces are emitted to theSQL_EXEClogging channel.#148542",
            "Added the following cluster settings for configuring blob file rewrite compactions:storage.value_separation.rewrite_minimum_ageandstorage.value_separation.compaction_garbage_threshold.#148837",
            "Added thereplicas.cpunanospersecondmetric. Notably, when child labels are enabled, this metric exposes evaluation-related Replica CPU usage by tenant.#146526",
            "CockroachDB now raises an error when encountering improper inline SSL credentials instead of panicking.#148242",
            "Restore will now re-attemptAdminSplitKV requests instead of immediately failing and pausing the job.#148484",
            "Fixed a bug where using column families on tables with vector indexes would cause the index to fail to return results.#147307",
            "Large mutation statements (INSERT,UPDATE,DELETE,UPSERT) are now less likely to encounter contention with automatic table statistics collection in some cases. The bug was present since v19.1.#148488",
            "The optimizer will no longer apply a fast-path to deletes cascading toREGIONAL BY ROWtables. This prevents the cascading delete from accessing more regions than necessary.#148105"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-alpha.3",
        "date": "June 23, 2025",
        "changes": [
            "CockroachDB can now synchronize SQL role membership from the groups claim contained in a JWT when the cluster settingserver.jwt_authentication.authorization.enabledis set totrue. The claim name and the fallbackuserinfoJSON key are configurable by the cluster settingsserver.jwt_authentication.group_claimandserver.jwt_authentication.userinfo_group_keyrespectively. This behavior matches the existing LDAP role-sync feature.#147318",
            "Fixed a bug that caused a routine with anINSERTstatement to unnecessarily block dropping a hash-sharded index or computed column on the target table. This fix applies only to newly created routines. In releases prior to v25.3, the fix must be enabled by setting the session variableuse_improved_routine_dependency_trackingtoon.#146250",
            "Partial indexes can now reference user-defined functions.#147817",
            "Computed column expressions andON UPDATEexpressions can now reference user-defined functions.#147817",
            "IMPORT TABLEas wellPGDUMPandMYSQLDUMPformats ofIMPORTare now fully removed. These have been deprecated since v23.2.#148248",
            "Removed the stale--ossflag from thedev ui watchsubcommand. This flag was no longer in use, as the UI development workflow now exclusively targets the CCL build. This change simplifies the tool by removing an unused build path and potential confusion for developers.#147978",
            "Fixed a bug that allowed a column to be dropped from a table even if it was referenced in theRETURNINGclause of anUPDATEorDELETEstatement in a routine. In releases prior to v25.3, the fix must be enabled by setting the session variableuse_improved_routine_dependency_trackingtoon.#146250",
            "Fixed a bug wherelibpqclients using the async API could hang with large result sets (Python: psycopg; Ruby: ActiveRecord, ruby-pg).#148222",
            "Restore no longer gets stuck in therevertingstate after failed cleanup of dropped temporary system tables.#148098"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-alpha.2",
        "date": "June 16, 2025",
        "changes": [
            "Changefeed source metadata now includes thecrdb_internal_table_idfield, enabling downstream consumers to uniquely identify tables even if table names change.#147341",
            "Changefeeds emitting to Kafka sinks that were created in CockroachDB v24.2.1+, or v23.2.10+ and v24.1.4+ with thechangefeed.new_kafka_sink.enabledcluster setting enabled now include the message key, size, and MVCC timestamp in message too large error logs.#147543",
            "Added support for query tagging, which allows users to add query tags to their SQL statements via comments. These query tags are included in:All log entries generated during the execution of a SQL statement and are prefixed byquerytag-.Traces and are prefixed byquerytag-.In thecrdb_internal.cluster_execution_insightsandcrdb_internal.node_execution_insightsvirtual tables in a newquery_tagsJSONB column. This feature is disabled by default and can be enabled using thesql.sqlcommenter.enabledcluster setting. Comments must follow theSQLCommenter specification.#145435",
            "All log entries generated during the execution of a SQL statement and are prefixed byquerytag-.",
            "Traces and are prefixed byquerytag-.",
            "In thecrdb_internal.cluster_execution_insightsandcrdb_internal.node_execution_insightsvirtual tables in a newquery_tagsJSONB column. This feature is disabled by default and can be enabled using thesql.sqlcommenter.enabledcluster setting. Comments must follow theSQLCommenter specification.#145435",
            "Added a session variableinitial_retry_backoff_for_read_committedthat controls the initial backoff duration when retrying an individual statement in an explicitREAD COMMITTEDtransaction. A duration of0disables exponential backoff. If a statement in an explicitREAD COMMITTEDtransaction is failing with the40001errorERROR: restart transaction: read committed retry limit exceeded; set by max_retries_for_read_committed=..., then you should setinitial_retry_backoff_for_read_committedto a duration proportional to the typical execution time of the statement (in addition to also increasingmax_retries_for_read_committed).#146860",
            "Added theSHOW CREATE ALL ROUTINESstatement, which can be used to showCREATEstatements for all user-defined functions (UDFs) and procedures in the current database.#147452",
            "Added the metricssql.txn.auto_retry.countandsql.statements.auto_retry.count, which count the number of automatic retries of SQL transactions and statements, respectively, within the database. These metrics differ from the relatedtxn.restarts.*metrics, which count retryable errors emitted by the KV layer that must be retried. The newsql.txn.auto_retry.countandsql.statements.auto_retry.countmetrics count auto-retry actions taken by the SQL layer in response to some of those retryable errors.#147682",
            "Increased the default value for themax_retries_for_read_committedsession variable from10to100. Testing has shown that some high-contention workloads running underREAD COMMITTEDisolation benefit from more statement retries.#147869",
            "The session variableinitial_retry_backoff_for_read_committednow defaults to2(milliseconds). Testing has shown that some high-contention workloads running underREAD COMMITTEDisolation benefit from exponential backoff.2might be too quick of an initial backoff for longer-running statements, but setting this value much higher than the normal duration of execution will cause excessive delay.#147869",
            "Added analter_changefeedstructured log event to provide more visibility into when anALTER CHANGEFEEDevent occurred and what changed.#147679",
            "Added new timeseries metrics to thestorage.value_separation.*namespace for observing the behavior ofstorage engine value separation.#147728",
            "The Hot Ranges page node filter has been moved out of the main filter container and now filters nodes on the backend to reduce load time.#147089",
            "The Insights page in the DB Console now displays SQL commenter query tags for statement executions. These tags provide application context (such as application name, user ID, or feature flags) embedded in SQL comments using thesqlcommenterformat. This information can help correlate slow query performance with specific application states. The Query Tags column is available in the Statement Executions view's Statement Insights table, but it is hidden by default. To display it, use the Columns selector.#147439",
            "Retry counts for statements executing underREAD COMMITTEDisolation are now more accurate.#147682",
            "Fixed an issue where self-referencing triggers did not have their dependencies properly recorded, which could lead to broken dependencies.#147018",
            "Fixed a security issue where optimizer predicate reordering could leak information about hidden rows protected by row-level security (RLS) policies.#147348",
            "Fixed a bug on the SQL Activity Statements and Transactions pages where the time picker failed to support sub-hour time ranges whensql.stats.aggregation.intervalwas set to a value under 1 hour. Previously, selecting a short time window (e.g., 10 minutes) would query for a full hour of data. This fix ensures that the selected time range is respected, enabling more precise analysis of recent activity.#147447",
            "FUNCTIONandPROCEDUREare now shown via\\h SHOW CREATEin the CLI doc.#147666",
            "Fixed a bug where functions lost their row-level security (RLS) policy backreferences, leading to schema change failures.#147696",
            "Fixed a bug whereALTER TABLEwas modifying identity attributes on columns not backed by a sequence.#147698",
            "Fixed an error incrdb_internal.table_spanswhen a table's schema had been dropped.#147766",
            "Fixed a bug where introspection queries (e.g., querying thecrdb_internalsystem catalog) could fail if a dropped constraint referenced a column that was also being dropped.#147773",
            "Fixed a bug where adding multiple columns in a single statement withAddGeometryColumnwould cause runtime errors.#147998"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0-alpha.1",
        "date": "June 9, 2025",
        "changes": [
            "The client for the SQL connection will now receive an error along with an error in theOPSchannel if trying to connect with an unsupported cipher.#146522",
            "Enhanced the/status/v2/hotrangesendpoint by adding two new filtering options:per_node_limit(int32): Specifies the maximum number of hot ranges to return per node. Defaults to128if not set.stats_only(bool): When set totrue, returns only the statistics for hot ranges without fetching descriptor information, such as databases, tables, and indexes.#144091",
            "per_node_limit(int32): Specifies the maximum number of hot ranges to return per node. Defaults to128if not set.",
            "stats_only(bool): When set totrue, returns only the statistics for hot ranges without fetching descriptor information, such as databases, tables, and indexes.#144091",
            "Changefeeds now round down the progress of each range to 1 second, in order to cover more ranges in fine-grained checkpointing.#146979",
            "Reduced the maximum backoff for changefeed retries from 10 minutes to 1 minute, which results in faster recovery from transient errors.#146448",
            "The secret keys in Azure cloud storage URIs are now redacted.#147022",
            "Added a new session variablecreate_table_with_schema_locked, which can be used to ensure all tables created by a session have the storage parameterschema_lockedset.#143892",
            "The following syntax is now supported:GRANT ... ON ALL ROUTINES IN SCHEMA ...REVOKE ... ON ALL ROUTINES IN SCHEMA ...ALTER DEFAULT PRIVILEGES GRANT ... ON ROUTINES ...ALTER DEFAULT PRIVILEGES REVOKE ... ON ROUTINES ...TheROUTINESkeyword makes the command apply to both functions and stored procedures. Note thatALTER DEFAULT PRIVILEGES ... ON FUNCTIONSalready applied to stored procedures (which aligns with the PostgreSQL behavior), and that is not changing.#144189",
            "GRANT ... ON ALL ROUTINES IN SCHEMA ...",
            "REVOKE ... ON ALL ROUTINES IN SCHEMA ...",
            "ALTER DEFAULT PRIVILEGES GRANT ... ON ROUTINES ...",
            "ALTER DEFAULT PRIVILEGES REVOKE ... ON ROUTINES ...",
            "The variable arguments of polymorphic built-in functions (e.g.,concat,num_nulls,format,concat_ws) no longer need to have the same type, matching PostgreSQL behavior. As a result, CockroachDB's type inference engine will no longer be able to infer argument types in some cases where it previously could, and there is a possibility that CockroachDB applications will encounter new errors. The new session variableuse_pre_25_2_variadic_builtinsrestores the previous behavior (and limitations).#144522",
            "Added new cluster settings:sql.metrics.application_name.enabledandsql.metrics.database_name.enabled. These settings default tofalseand can be set totrueto display the application name and database name, respectively, on supported metrics.#144610",
            "Added support for query tagging, which allows users to add query tags to their SQL statements via comments. These query tags are included in:All log entries generated during the execution of a SQL statement and are prefixed byquerytag-.Traces and are prefixed byquerytag-.In thecrdb_internal.cluster_execution_insightsandcrdb_internal.node_execution_insightsvirtual tables in a newquery_tagsJSONB column. This feature is disabled by default and can be enabled using thesql.sqlcommenter.enabledcluster setting. Comments must follow theSQLCommenter specification.#145435",
            "All log entries generated during the execution of a SQL statement and are prefixed byquerytag-.",
            "Traces and are prefixed byquerytag-.",
            "In thecrdb_internal.cluster_execution_insightsandcrdb_internal.node_execution_insightsvirtual tables in a newquery_tagsJSONB column. This feature is disabled by default and can be enabled using thesql.sqlcommenter.enabledcluster setting. Comments must follow theSQLCommenter specification.#145435",
            "~~*and!~~*are now supported aliases forILIKEandNOT ILIKE.#146764",
            "Theinformation_schema.triggerstable is now populated with trigger metadata. Users can query this table to see all triggers defined in their database, including the trigger name, timing (BEFORE/AFTER), event type (INSERT/UPDATE/DELETE), and associated function. Each trigger event appears as a separate row in the table.#147237",
            "Thepg_catalog.pg_triggertable now returns metadata about database triggers.#147248",
            "Deterministic collations are now supported withLIKE. A deterministic collation considers strings to be equal only if they consist of the same byte sequence.#147045",
            "Assigning to an element of a composite-typed variable in a PL/pgSQL routine now respects case-sensitivity rules. For example, a field named\"FOO_Bar\"can be assigned likeNEW.\"FOO_Bar\" = 100.#143579",
            "Prometheus metrics are now also available at the/metricsendpoint, in addition to the existing/_status/varsendpoint. The new/metricsendpoint emits statically labeled metrics and will evolve more rapidly as CockroachDB migrates metrics to use labels instead of defining different metric names. For compatibility, users can continue to use/_status/vars, where metric names will remain stable.#143536",
            "Added the new latency metrics:sql.service.latency.historical,sql.service.latency.consistent,sql.exec.latency.historical, andsql.exec.latency.consistentfor easier query optimizations.#142826",
            "Partial index schema changes are supported in replicating tables whenlogical_replication.consumer.immediate_mode_writeris not set tolegacy-kv.#144508",
            "The cluster settingserver.client_cert_expiration_cache.capacityhas been deprecated. The client certificate cache now evicts client certificates based on expiration time.#144181",
            "Logs for hot ranges (hot_ranges_statsevents) have been moved to theHEALTHlogging channel.#144567",
            "Added a new metric,kv.loadsplitter.cleardirection, which increments when the load-based splitter observes that more than 80% of replica access samples are moving in a single direction (either left/descending or right/ascending).#143927",
            "When theserver.telemetry.hot_ranges_stats.enabledcluster setting is enabled, nodes check for hot ranges every minute instead of every 4 hours. A node logs its hot ranges when any single replica exceeds 250 ms of CPU time per second. In multi-tenant deployments, the check runs every 5 minutes and logs hot ranges for the entire cluster.#144414",
            "Added the metricchangefeed.checkpoint.timestamp_countthat measures the number of unique timestamps in a changefeed span-level checkpoint. It may be useful to monitor this metric to determine if quantization settings should be changed.#145117",
            "In a physical cluster replication (PCR) deployment, it is not possible for the standby system virtual cluster, or the reader virtual cluster to upgrade the reader virtual cluster by setting the version cluster setting. It is necessary to:Upgrade the standby system virtual cluster.Upgrade the primary system virtual cluster.Upgrade the primary virtual cluster.Wait for the replicated time to advance past the time the primary virtual cluster upgraded.Shut down the reader virtual cluster.Upgrade the destination host cluster.Re-initialize the reader virtual cluster withALTER VIRTUAL CLUSTER SET REPLICATION READ VIRTUAL CLUSTER.#146127",
            "Upgrade the standby system virtual cluster.",
            "Upgrade the primary system virtual cluster.",
            "Upgrade the primary virtual cluster.",
            "Wait for the replicated time to advance past the time the primary virtual cluster upgraded.",
            "Shut down the reader virtual cluster.",
            "Upgrade the destination host cluster.",
            "Re-initialize the reader virtual cluster withALTER VIRTUAL CLUSTER SET REPLICATION READ VIRTUAL CLUSTER.#146127",
            "Added job tracing support to changefeeds.#144412",
            "Node attributes (attrs) will now appear in thenode statusCLI command.#143421",
            "Updated the\\d <table name>command to show policy and Row Level Security information similar to what is shown in the output ofSHOW CREATE TABLE.#146215",
            "Added the--validate-zip-fileflag to thecockroach debug zipcommand. This flag performs a quick validation check to ensure that the generated zip file is not corrupted. The flag is enabled by default.#146192",
            "The SQL shell now supports the compact output mode whenauto_traceis enabled.#146432",
            "Schema insights that recommend replacing an index were previously a two-statement command consisting of aCREATE INDEXand aDROP INDEXstatement. When these two DDL statements were run as a single batched command, it was possible for one statement to succeed and one to fail. This is because DDL statements do not have the same atomicity guarantees as other SQL statements in CockroachDB. Index-replacement insights are now a singleCREATE INDEXstatement followed by a comment with additional DDL statements to be run manually: anALTER INDEX ... NOT VISIBLEstatement, which makes the old index invisible to the optimizer, followed by aDROP INDEXstatement that should only be run after making the old index invisible and verifying that workload performance is satisfactory.#144101",
            "Updated the titles of the disk throughput graphs on the Metrics page Hardware dashboard to display only \"Bytes/s\" instead of including a specific magnitude, \"MiB/s\". The titles of the graphs are now \"Disk Read Bytes/s\" and \"Disk Write Bytes/s\".#147462",
            "Fixed a bug where using valueschangefeed.aggregator.flush_jitter,min_checkpoint_frequencysuch thatchangefeed.aggregator.flush_jitter * min_checkpoint_frequency < 1would cause a panic. Jitter will now be disabled in this case.#144304",
            "Fixed a bug that could cause queries that perform work in parallel to ignore the requested quality-of-service level. Affected operations include lookup joins, DistSQL execution, and foreign-key checks.#144427",
            "Improved the performance ofSHOW CREATE TABLEon multi-region databases with large numbers of objects.#144900",
            "Fixed a bug where runningDROP INDEXon a hash-sharded index did not properly detect dependencies from functions and procedures on the shard column. This caused theDROP INDEXstatement to fail with an internal validation error. Now the statement returns a correct error message, and usingDROP INDEX ... CASCADEworks as expected by dropping the dependent functions and procedures.#145107",
            "Fixed a bug that prevented variable references using ordinal syntax (like$1) from reflecting updates to the variable. Referencing variables declared in PL/pgSQL blocks (instead of parameters) via ordinal syntax is now disallowed. The bug had existed since v24.1.#144347",
            "Fixed a bug that caused index expression elements of primary keys to be shown incorrectly in the output ofSHOW CREATE TABLE.#144716",
            "Fixed a bug that could lead to schema changes hanging after a cluster recovered from availability issues.#145462",
            "Previously, on a table with multiple column families, CockroachDB could encounter aNon-nullable column \":\" with no valueerror in rare cases during table statistics collection. The bug was present since v19.2 and is now fixed.#145481",
            "Fixed a bug that could cause a row-level TTL job to fail with the error \"comparison of two different versions of enum\" if anENUMtype referenced by the table experienced a schema change.#145374",
            "Fixed a bug where the physical cluster replication (PCR) reader catalog job could hit validation errors when schema objects had dependencies between them (for example, when a sequence's default expression was being removed).#145972",
            "Creating a vector index on a table that contains aNULLvector value will no longer cause an internal error.#145983",
            "Fixed an internal assertion failure that could occur during operations likeALTER TYPEorALTER DATABASE ... ADD REGIONwhen temporary tables were present.#145551",
            "Row-level security (RLS)SELECTpolicies duringUPDATEoperations are now only applied when referenced columns appear in theSETorWHEREclauses, matching the behavior of PostgreSQL. This improves compatibility.#145344",
            "Fixed an issue where using inline log configuration could cause internal errors on the DB Console's Logs page for a node at#/node/{nodeID}/logs.#145329",
            "Fixed an integer overflow in thesplit_partfunction when using extremely negative field positions like Go'smath.MinInt64.#146271",
            "Fixed incorrect application ofSELECTpolicies toRETURNINGclauses inINSERTandUPDATEwhen no table columns were referenced.#145890",
            "Fixed a bug that preventedTRUNCATEfrom succeeding if any indexes on the table had back-reference dependencies, such as from a view or function referencing the index.#146287",
            "Fixed a bug whereALTER TABLEoperations with multiple commands could generate invalid zone configurations.#146369",
            "Fixed a bug where an invalid comment in thesystem.commenttable for a schema object could make it inaccessible.#146213",
            "Fixed a bug where a CockroachDB node could crash when executingDOstatements that contain currently unsupported DDL statements likeCREATE TYPEin a non-default configuration (additional logging needed to be enabled, e.g., via thesql.log.all_statements.enabledcluster setting). This bug was introduced in v25.1.#146406",
            "Prevent use of future timestamps when usingAS OF SYSTEM TIMEwithCREATE TABLE ... ASand materialized views. Previously, such timestamps could cause errors, delays, or hangs.#146446",
            "Fixed an internal error that could be hit whenADD COLUMN UNIQUEandALTER PRIMARY KEYwere executed within the same transaction.#146567",
            "Fixed a bug that prevented temporary views and sequences from being created if thepg_tempschema was explicitly specified in the qualified name of the object being created.#146586",
            "Fixed a bug where CockroachDB would not use the vectorized fast path forCOPYwhen it was supported. The bug was only present in previous v25.2 releases.#146696",
            "Errors triggered by DB Console activity no longer cause the node to crash.#145563",
            "Fixed a bug to prevent HTTP connections from stopping server shutdown.#146744",
            "The MVCC timestamp is now emitted correctly when themvcc_timestampis used with CDC queries.#146836",
            "Fixed a bug in v25.2.0 where a vector search operator could drop user-supplied filters if the same vector column was indexed twice and a vector index with no prefix columns was defined after a vector index with prefix columns.#146259",
            "Fixed a bug that could cause thecockroachprocess tosegfaultwhen collecting runtime execution traces (typically collected via theAdvanced Debugpage in the Console).#146883",
            "Fixed a data race in thecloudstoragesink.#146297",
            "Fixed a bug where thekv.rangefeed.closed_timestamp.slow_rangeswould not be incremented when a rangefeed closed timestamp was slower than the target threshold.#146949",
            "Fixed a bug that could cause anAFTERtrigger to fail withclient already committed or rolled back the transactionif the query also contained foreign-key cascades. The bug had existed sinceAFTERtriggers were introduced in v24.3.#146890",
            "Prevent dropping columns or indexes that are still referenced by triggers. Previously, these operations could succeed silently, potentially breaking trigger functionality.#146683",
            "Fixed a bug where searching a vector with a query vector that doesn't match the dimensions of the vector column in the table would cause a node to crash.#146848",
            "Specifying types for a subset of columns in a generator function's column definition list now results in a syntax error instead of an internal error.#145492",
            "Fixed a bug that caused the SQL Activity > Statement Fingerprint page to fail to load details for statements run with application names containing a#character.#147021",
            "CockroachDB could previously incorrectly evaluateto_regclass,to_regnamespace,to_regproc,to_regprocedure,to_regrole, andto_regtypebuiltin functions when the query using them happened to be evaluated in distributed fashion. The bug has been present since the introduction of these builtins in v23.1 and is now fixed.#147362",
            "Fixed a bug that caused the optimizer to ignore index hints when optimizing some forms of prepared statements. This could result in one of two unexpected behaviors: a query errors with the messageindex cannot be used for this querywhen the index can actually be used; or a query uses an index that does not adhere to the hint. The hints relevant to this bug are regular index hints, e.g.,SELECT * FROM tab@index,FORCE_INVERTED_INDEX, andFORCE_ZIGZAG.#147368",
            "Fixed a bug where thepg_catalog.pg_policytable could contain duplicate OID values when multiple tables had policies with the same policy ID. All rows inpg_policynow have unique OIDs as required.#147373",
            "Fixed a bug where therolbypassrlscolumn inpg_rolesandpg_authidtables always returned false, even for roles with theBYPASSRLSoption.#147357",
            "Fixed a bug that could cause stable expressions to be folded in cached query plans. The bug could cause stable expressions likecurrent_settingto return the wrong result if used in a prepared statement. The bug was introduced in point releases v23.2.22, v24.1.14, v24.3.9, and v25.1.2, and the v25.2 alpha.#147187",
            "Fixed an issue where updating child metrics and reinitializing metrics at the same time could cause scrape errors.#147486",
            "Fixed a runtime panic in thesubstring_indexfunction that occurred when the count argument was the minimum 64-bit integer value.#147546",
            "Fixed a memory leak in index backfill jobs where completed spans were duplicated in memory on each progress update after resuming from a checkpoint. This could cause out-of-memory (OOM) errors when backfilling indexes on large tables with many ranges. This bug affected release version v25.2.0 and pre-release versions v25.2.0-alpha.3 through v25.2.0-rc.1.#147511",
            "Fixed a bug where prepared statements on schema changes could fail with runtime errors.#147658",
            "Fixed an issue with logical data replication (LDR) where the presence of a unique index may cause spurious dead letter queue (DLQ) entries if the unique index has a smaller index ID than the primary key index.#147117",
            "Scheduled backups now prevent multiple compaction jobs from running in parallel on its backups.#145930",
            "Removal of triggers during a restore now accounts for back references that existed because of triggers.#147306",
            "Prepared statements are now more efficiently cached.#144021",
            "TTL jobs now respond to cluster topology changes by restarting and rebalancing across available nodes.#145214",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.3",
        "patch_version": "25.3.0",
        "date": "August 4, 2025",
        "changes": [
            "Observability",
            "Performance",
            "CockroachDB Cloud",
            "Backward-incompatible changes",
            "Features that require upgrade finalization",
            "Key cluster setting changes",
            "Deprecations",
            "Known limitations",
            "Enhanced Security: Centralized user management improves security policy enforcement and reduces manual error risks.",
            "Increased Efficiency: Automates user provisioning, de-provisioning, and role assignments.",
            "Simplified Auditing: Provides a single source of truth for user identities.",
            "Reduced Overhead: Eliminates separate SQL user management processes. This integration allows the entire SQL user lifecycle to be managed from LDAP/AD systems, improving overall security and operational efficiency.",
            "Enhanced Security: Granular control over outbound network connections from your CockroachDB cluster, minimizing the attack surface and preventing unauthorized data exfiltration.",
            "PCI DSS Compliance: Directly addresses specific PCI DSS requirements (e.g., controlling and restricting egress traffic), assisting organizations in achieving and maintaining compliance for their cardholder data environments (CDE).",
            "Data Protection: Ensures that sensitive data egress, such as backups or change data capture (CDC), is confined to approved, secure destinations.",
            "Reduced Risk: Mitigates the risk of data breaches and unauthorized access by enforcing strict network boundaries around your database.",
            "Enhanced Data Security: Customers control key lifecycle (creation, rotation, revocation), improving data protection.",
            "PCI DSS Compliance: Addresses PCI DSS Requirement 3 for protecting stored cardholder data.",
            "Operational Control: Provides greater control and visibility over data encryption strategy.",
            "Data Revocation Capability: Enables immediate data access revocation by disabling the encryption key in Azure Key Vault.",
            "This release contains no backward-incompatible changes.",
            "TheCITEXTdata type",
            "Support for automatically determining the region column for a REGIONAL BY ROW table using a foreign key constraint",
            "Lock loss detection for weaker isolation levels",
            "Automatic user provisioning via the LDAP/Active Directory integration",
            "Theestimated_last_login_timecolumn inSHOW ROLES/SHOW USERSoutput",
            "sql.metrics.application_name.enabled- Default tofalseand can be set totrueto display the application name on supported metrics.#144610",
            "sql.metrics.database_name.enabled- Default tofalseand can be set totrueto display the database name on supported metrics.#144610",
            "sql.sqlcommenter.enabled- This feature is disabled by default and can be enabled using thesql.sqlcommenter.enabledcluster setting. Comments must follow theSQLCommenter specification.#145435",
            "sql.trace.txn.sample_rateandsql.trace.txn.enable_threshold- In order to selectively capture traces for transactions running in an active workload without having to capture them via statement diagnostic bundles, customers can now use thesql.trace.txn.sample_ratecluster setting to enable tracing for a fraction of their workload. Thesql.trace.txn.enable_thresholdwill still need to be set to a positive value to provide a filter for how slow a transaction needs to be after being sampled to merit emitting a trace. Traces are emitted to theSQL_EXEClogging channel.",
            "The value ofsql.stats.error_on_concurrent_create_stats.enablednow defaults tofalse, suppressing error counters for auto stats jobs that fail due to concurrent stats jobs in progress.#149857",
            "The cluster settingserver.client_cert_expiration_cache.capacityhas been deprecated. The client certificate cache now evicts client certificates based on expiration time.#144181",
            "To prevent unnecessary queuing in admission control CPU queues, thegoschedstats.always_use_short_sample_period.enabledsetting default was changed totrue#146014",
            "IMPORT TABLEas wellPGDUMPandMYSQLDUMPformats ofIMPORTare now fully removed. These have been deprecated since v23.2.#148248",
            "Removed the 'started' column inSHOW JOBS, which was a duplicate of the 'created' column.#148464"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.9",
        "date": "November 14, 2025",
        "changes": [
            "Added thesql.statements.rows_read.countmetric that counts the number of index rows read by SQL statements.#156595",
            "Added thesql.statements.index_rows_written.countmetric that counts the number of primary and secondary index rows modified by SQL statements.#156595",
            "Added thesql.statements.index_bytes_written.countmetric that counts the number of primary and secondary index bytes modified by SQL statements.#156595",
            "Added thesql.statements.bytes_read.countmetric that counts the number of bytes scanned by SQL statements.#156595",
            "Fixed a bug where changefeeds using CDC queries could sometimes unexpectedly fail after a schema change with a descriptor retrieval error.#156552"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.8",
        "date": "October 30, 2025",
        "changes": [
            "In order to selectively capture traces for transactions running in an active workload without having to capture them via statement diagnostic bundles, customers can now use thesql.trace.txn.sample_ratecluster setting to enable tracing for a fraction of their workload. Thesql.trace.txn.enable_thresholdwill still need to be set to a positive value to provide a filter for how slow a transaction needs to be after being sampled to merit emitting a trace. Traces are emitted to theSQL_EXEClogging channel.#156409",
            "Fixed a bug in thecockroach node draincommand where draining a node using virtual clusters (such as clusters running Physical Cluster Replication (PCR)) could return before the drain was complete, possibly resulting in shutting down the node while it still had active SQL clients and range leases.#156312"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.7",
        "date": "October 17, 2025",
        "changes": [
            "Fixed a bug where anINSERTstatement could fail with a type checking error while adding aBIT(n)column.#152964",
            "Fixed a bug where index creation could fail due to validation errors if the schema change was retried or paused/resumed during the backfill.#153596",
            "Fixed a bug introduced in v25.1.0 that would cause a node panic if aSIGINTsignal was sent during the execution of aCHECK EXTERNAL CONNECTIONcommand.#153601",
            "Fixed a bug whereALTER POLICYwas incorrectly dropping dependency tracking for functions, sequences, or types in policy expressions.#153808",
            "Fixed a runtime error that could be hit if a new secondary index had a name collision with a primary index.#154015",
            "Fixed a bug that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when the session settingexpect_and_ignore_not_visible_columns_in_copywas enabled. This bug was introduced withexpect_and_ignore_not_visible_columns_in_copyin v22.1.0.#154290",
            "Disabled thekv.lock_table.unreplicated_lock_reliability.split.enabledfeature, which could lead to a node crash.#155418",
            "Fixed a bug where the presence of duplicate temporary tables in a backup caused the restore to fail with an error containing the textrestoring table desc and namespace entries: table already exists.#154398"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.6",
        "date": "September 22, 2025",
        "changes": [
            "Added a new session variable,disable_optimizer_rules, which allows users to provide a comma-separated list of optimizer rules to disable during query optimization. This allows users to avoid rules that are known to create a suboptimal query plan for specific queries.#152349",
            "Whensql_safe_updatesis enabled, theALTER TABLE ... LOCALITYstatement will be blocked when trying to convert an existing table toREGIONAL BY ROW, unless a region column has been added to the table. This protects against undesired behavior that causedUPDATEorDELETEstatements to fail against the table while the locality change was in progress.#152600",
            "Updated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#151485",
            "Fixed a bug wheredebug.zipfiles collected from clusters withdisallow_full_table_scansenabled were missing system table data.#151224",
            "Addressed a bug onschema_lockedtables when a column is dropped, andschema_lockedis toggled for the user.#151528",
            "Fixed a bug that could cause excessive memory allocations when compacting timeseries keys.#151814",
            "Fixed a bug whereDROP USERsucceeded even though a role owned default privileges, which could leave invalid privilege entries in the system.#151879",
            "Previously, CockroachDB could hit an errorERROR: span with results after resume span...when evaluating some queries withORDER BY ... DESCin an edge case. This bug was present since v22.1 and is now fixed.#152184",
            "Fixed a bug whereSHOW TABLESwould show inaccurate row counts if the most recent statistics collection was partial.#152186",
            "Fixed a bug where updating column default expressions would incorrectly remove sequence ownerships for the affected column.#152314",
            "Fixed a bug that allowed foreign-key violations to result from some combinations of concurrentREAD COMMITTEDandSERIALIZABLEtransactions. If bothSERIALIZABLEand weaker-isolation transactions will concurrently modify rows involved in foreign-key relationships, theSERIALIZABLEtransactions must have the following session variables set in order to prevent any possible foreign-key violations:SET enable_implicit_fk_locking_for_serializable = on;SET enable_shared_locking_for_serializable = on;SET enable_durable_locking_for_serializable = on;#152375",
            "SET enable_implicit_fk_locking_for_serializable = on;",
            "SET enable_shared_locking_for_serializable = on;",
            "SET enable_durable_locking_for_serializable = on;#152375",
            "Added an automatic repair for dangling or invalid entries in thesystem.commentstable.#152471",
            "Added theuse_soft_limit_for_distribute_scansession variable (default:false), which controls whether CockroachDB uses the soft row count estimate when deciding whether an execution plan should be distributed. In v25.1, the physical planning heuristics were changed such that large constrained table scans, estimated to scan at least 10,000 rows (controlled viadistribute_scan_row_count_threshold), would force plan distribution whendistsql=auto. However, if the scan had a \"soft limit\" CockroachDB would still use the full estimate (for example,10,000inestimated row count: 10010,000), sometimes unnecessarily distributing queries and increasing latency. Theuse_soft_limit_for_distribute_scansession variable addresses this by allowing the planner to use the soft limit when deciding whether a scan is \"large\".#152559",
            "Fixed a bug where views could not reference thecrdb_regioncolumn from their underlying tables in expressions.#152679",
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152631",
            "Tunes S3 client retry behavior to be more reliable in the presence of correlated errors.#151874"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.5",
        "date": "August 22, 2025",
        "changes": [
            "Kafka v2 changefeed sinks now support a cluster setting that enables detailed error logging for messages exceeding Kafka v2 size limit.#149829",
            "Introduced a cluster setting,sql.stats.error_on_concurrent_create_stats.enabled, which modifies how CockroachDB reacts to concurrent auto stats jobs. The default,true, maintains the previous behavior. Settingsql.stats.error_on_concurrent_create_stats.enabledtofalsewill cause the concurrent auto stats job to be skipped with just a log entry and no increased error counters.#149837",
            "Fixed an issue where the mvcc_timestamp field was incorrectly returning zero values when used with CDC queries. The timestamp is now emitted correctly.#147114",
            "Fixed a bug where database login could fail during LDAP, JWT, or OIDC authentication if the user's external group memberships did not correspond to any existing roles in the database. The login will now succeed, and no roles will be granted or revoked in this scenario.#149747",
            "Fixed a bug that would cause aCALLstatement executed via a portal in the extended wire protocol to result in an error likeunknown portal \"\"if the stored procedure containedCOMMITorROLLBACKstatements. The bug had existed since PL/pgSQL transaction control statements were introduced in v24.1. The fix will be off by default in versions prior to v25.3, and can be toggled on by settinguse_proc_txn_control_extended_protocol_fix = true.#149851",
            "Fixed a slow memory leak that was introduced in v25.1.8, v25.2.1, v25.2.2, and v25.3 betas. The leak would accumulate whenever a node executed a part of the distributed plan (the gateway node of the plan was not affected), and could only be mitigated by restarting the node.#149919",
            "Fixed an issue where some SQL metrics were not reported whenserver.child_metrics.enabledwas enabled,server.child_metrics.include_aggregate.enabledwas disabled, andsql.metrics.application_name.enabledandsql.metrics.database_name.enabledwere also disabled. Specifically, metrics with no children now report their aggregate metrics regardless of theserver.child_metrics.include_aggregate.enabledcluster setting.#149937",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150295",
            "Fixed an issue where discarding zone configs on sequences did not actually remove the configuration.#150359",
            "Fixed a bug where the entire schema would become inaccessible if a table was referenced as an implicit record type by a user-defined function (UDF) while the table was undergoing anIMPORT.#150439",
            "Fixed invalid zone configurations that were generated when adding a super region to a 3-region database with a secondary region and region survivability. Previously, this could result in assigning more than the allowed number of replicas.#150619",
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151082",
            "Fixed a memory accounting issue in the client certificate cache that caused multiple allocations to be reported for the same certificate. The cache now accurately tracks memory usage and includes a safeguard to prevent it from negatively affecting SQL operations.#151146",
            "Previously, CockroachDB could encounter an internal errortrying to add a column of UNKNOWN type at ...in rare cases when handlingCASEorORoperations. This bug was present since v20.2 and is now fixed.#151161",
            "Previously, CockroachDB could hit an errorERROR: span with results after resume span...when evaluating some queries withORDER BY ... DESCin an edge case. This bug was present since v22.1 and is now fixed.#152185",
            "Upgrade to Go 1.23.11#150988"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.4",
        "date": "August 1, 2025",
        "changes": [
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151095"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.3",
        "date": "July 28, 2025",
        "changes": [
            "Changefeeds emitting to Kafka sinks that were created in CockroachDB v24.2.1+, or v23.2.10+ and v24.1.4+ with thechangefeed.new_kafka_sink.enabledcluster setting enabled now include the message key, size, and MVCC timestamp in message too large error logs.#147929",
            "Added the metricssql.txn.auto_retry.countandsql.statements.auto_retry.count, which count the number of automatic retries of SQL transactions and statements, respectively, within the database. These metrics differ from the relatedtxn.restarts.*metrics, which count retryable errors emitted by the KV layer that must be retried. The newsql.txn.auto_retry.countandsql.statements.auto_retry.countmetrics count auto-retry actions taken by the SQL layer in response to some of those retryable errors.#148207",
            "Added a session variableinitial_retry_backoff_for_read_committedthat controls the initial backoff duration when retrying an individual statement in an explicitREAD COMMITTEDtransaction. A duration of0disables exponential backoff. If a statement in an explicitREAD COMMITTEDtransaction is failing with the40001errorERROR: restart transaction: read committed retry limit exceeded; set by max_retries_for_read_committed=..., then you should setinitial_retry_backoff_for_read_committedto a duration proportional to the typical execution time of the statement (in addition to also increasingmax_retries_for_read_committed).#148207",
            "Updated the \"Learn more\" link on theHot Rangespage to direct users to a newer, more comprehensive reference guide about hotspots.#148522",
            "Fixed a data race in thecloudstoragesink.#147163",
            "Fixed a bug where searching a vector with a query vector that doesn't match the dimensions of the vector column in the table would cause a node to crash.#147875",
            "Fixed a bug where functions lost their row-level security (RLS) policy backreferences, leading to schema change failures.#147905",
            "Fixed an error incrdb_internal.table_spansthat could occur when a table's schema had been dropped.#147977",
            "Fixed a bug where adding multiple columns in a single statement withAddGeometryColumnwould cause runtime errors.#148146",
            "Fixed a bug wherelibpqclients using the async API could hang with large result sets (Python: psycopg; Ruby: ActiveRecord, ruby-pg).#148468",
            "Previously, CockroachDB could hit an internal error when performing aDELETE,UPDATE, orUPSERTwhere the initial scan of the mutation is locking and is on a table different from the one being mutated. A possible workaround wasSET enable_implicit_select_for_update = false, but this could increase contention. The bug was introduced in v25.2 and is now fixed.#149301",
            "TheRESET ALLstatement no longer affects the following session variables:is_superuserrolesession_authorizationtransaction_isolationtransaction_prioritytransaction_statustransaction_read_onlyThis better matches PostgreSQL behavior forRESET ALL. In addition, theDISCARD ALLstatement no longer errors whendefault_transaction_use_follower_readsis enabled.#149388",
            "is_superuser",
            "session_authorization",
            "transaction_isolation",
            "transaction_priority",
            "transaction_status",
            "transaction_read_only",
            "In v25.1, automatic partial statistics collection was enabled by default (by setting thesql.stats.automatic_partial_collection.enabledcluster setting totrue). Partial statistics collection may encounter certain expected scenarios that were previously reported as failed stats jobs with PostgreSQL error code55000. These errors are benign and are no longer reported. Instead, the stats job will be marked as \"succeeded,\" though no new statistics will be created.#149625",
            "Fixed a slow memory leak that was introduced in v25.1.8, v25.2.1, v25.2.2, and v25.3 betas. The leak would accumulate whenever a node executed a part of the distributed plan (the gateway node of the plan was not affected), and could only be mitigated by restarting the node.#149921",
            "Fixed an issue where some SQL metrics were not reported whenserver.child_metrics.enabledwas enabled,server.child_metrics.include_aggregate.enabledwas disabled, andsql.metrics.application_name.enabledandsql.metrics.database_name.enabledwere also disabled. Specifically, metrics with no children now report their aggregate metrics regardless of theserver.child_metrics.include_aggregate.enabledcluster setting.#150185",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150338",
            "Fixed a bug where the entire schema would become inaccessible if a table was referenced as an implicit record type by a user-defined function (UDF) while the table was undergoing anIMPORT.#150441",
            "Restore no longer gets stuck in the reverting state after failed cleanup of dropped temporary system tables.#148485"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.2",
        "date": "June 25, 2025",
        "changes": [
            "Whenserver.telemetry.hot_ranges_stats.enabledcluster setting is enabled, nodes now log hot ranges every minute if they exceed 250ms of CPU time per second. In multi-tenant deployments, this check occurs every 5 minutes at the cluster level, improving visibility into transient performance issues.#146887",
            "Added a new metric,kv.loadsplitter.cleardirection, which increments when the load-based splitter observes that more than 80% of replica access samples are moving in a single direction (either left/descending or right/ascending).#147169",
            "The Hot Ranges page node filter has been moved out of the main filter container and now filters nodes on the backend to reduce load time.#147778",
            "Fixed a bug that could cause thecockroachprocess tosegfaultwhen collecting runtime execution traces (typically collected via theAdvanced Debugpage in the Console).#146886",
            "Fixed a bug where thekv.rangefeed.closed_timestamp.slow_rangeswould not be incremented when a rangefeed closed timestamp was slower than the target threshold.#146975",
            "Fixed a bug that could cause anAFTERtrigger to fail withclient already committed or rolled back the transactionif the query also contained foreign-key cascades. The bug had existed sinceAFTERtriggers were introduced in v24.3.#146977",
            "Fixed a bug that caused the SQL Activity > Statement Fingerprint page to fail to load details for statements run with application names containing a#character.#147223",
            "Previously, CockroachDB could incorrectly evaluate theto_regclass,to_regnamespace,to_regproc,to_regprocedure,to_regrole, andto_regtypebuilt-in functions when the query using them was evaluated in a distributed fashion. The bug was introduced with these built-in functions in v23.1 and is now fixed.#147376",
            "Fixed a bug that caused the optimizer to ignore index hints when optimizing some forms of prepared statements. This could result in one of two unexpected behaviors: a query errors with the messageindex cannot be used for this querywhen the index can actually be used; or a query uses an index that does not adhere to the hint. The hints relevant to this bug are regular index hints, e.g.,SELECT * FROM tab@index,FORCE_INVERTED_INDEX, andFORCE_ZIGZAG.#147417",
            "Fixed a bug where thepg_catalog.pg_policytable could contain duplicate OID values when multiple tables had policies with the same policy ID. All rows inpg_policynow have unique OIDs as required.#147438",
            "Fixed a bug that could cause stable expressions to be folded in cached query plans. The bug could cause stable expressions likecurrent_settingto return the wrong result if used in a prepared statement. The bug was introduced in v23.2.22, v24.1.14, v24.3.9, v25.1.2, and the v25.2 alpha.#147460",
            "Fixed a runtime panic in thesubstring_indexfunction that occurred when the count argument was the minimum 64-bit integer value.#147549",
            "Fixed a memory leak in index backfill jobs where completed spans were duplicated in memory on each progress update after resuming from a checkpoint. This could cause out-of-memory (OOM) errors when backfilling indexes on large tables with many ranges. This bug affected release version v25.2.0 and pre-release versions v25.2.0-alpha.3 through v25.2.0-rc.1.#147563",
            "Fixed a bug where prepared statements on schema changes could fail with runtime errors.#147671",
            "Fixed a bug whereALTER TABLEwas modifying identity attributes on columns not backed by a sequence.#147711",
            "TTL jobs now respond to cluster topology changes by restarting and rebalancing across available nodes.#147083",
            "Fixed an issue in Logical Data Replication (LDR) where unique indexes with lower index IDs than the primary key could cause incorrect DLQ entries during replication.#147350"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.10",
        "date": "December 12, 2025",
        "changes": [
            "The background (elastic) store graphs for exhausted duration, and the wait duration histogram, have been separated from the foreground (regular) graphs.#156868",
            "A mechanism that prevents unsafe replication changes from causing loss of quorum now functions correctly. An internal function has been fixed to properly return errors, enhancing the reliability of replication safeguards.#156521",
            "Fixed a bug that could cause internal errors for queries using generic query plans withNULLplaceholder values.#156977",
            "The cost of generic query plans is now calculated based on worst-case selectivities for placeholder equalities (e.g.,x = $1). This reduces the chance of suboptimal generic query plans being chosen whenplan_cache_mode=auto.#156797",
            "Span config reconciliation jobs no longer fail on the destination after failover from a PCR stream of a system virtual cluster.#156810"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.1",
        "date": "June 4, 2025",
        "changes": [
            "Added thesql.metrics.application_name.enabledandsql.metrics.database_name.enabledcluster settings. These settings default tofalse. Set them totrueto include the application and database name, respectively, in supported metrics.#144932",
            "Added the metricchangefeed.checkpoint.timestamp_countthat measures the number of unique timestamps in a changefeed span-level checkpoint. It may be useful to monitor this metric to determine if quantization settings should be changed.#145223",
            "Logs for hot ranges (hot_ranges_statsevents) have been moved to theHEALTHlogging channel.#146762",
            "Schema insights that recommend replacing an index were previously a two-statement command consisting of aCREATE INDEXand aDROP INDEXstatement. When these two DDL statements were run as a single batched command, it was possible for one statement to succeed and one to fail. This is because DDL statements do not have the same atomicity guarantees as other SQL statements in CockroachDB. Index-replacement insights are now a singleCREATE INDEXstatement followed by a comment with additional DDL statements to be run manually: anALTER INDEX ... NOT VISIBLEstatement, which makes the old index invisible to the optimizer, followed by aDROP INDEXstatement that should only be run after making the old index invisible and verifying that workload performance is satisfactory.#145993",
            "Improved the performance ofSHOW CREATE TABLEon multi-region databases with large numbers of objects.#145004",
            "Fixed a bug that could cause queries that perform work in parallel to ignore the requested quality-of-service level. Affected operations include lookup joins, DistSQL execution, and foreign-key checks.#145363",
            "Fixed a bug where runningDROP INDEXon a hash-sharded index did not properly detect dependencies from functions and procedures on the shard column. This caused theDROP INDEXstatement to fail with an internal validation error. Now the statement returns a correct error message, and usingDROP INDEX ... CASCADEworks as expected by dropping the dependent functions and procedures.#145386",
            "Fixed a bug that could lead to schema changes hanging after a cluster recovered from availability issues.#145545",
            "Previously, on a table with multiple column families, CockroachDB could encounter aNon-nullable column \":\" with no valueerror in rare cases during table statistics collection. The bug was present since v19.2 and is now fixed.#145576",
            "Fixed a bug that could cause a row-level TTL job to fail with the error \"comparison of two different versions of enum\" if anENUMtype referenced by the table experienced a schema change.#145917",
            "Fixed a bug where the physical cluster replication (PCR) reader catalog job could hit validation errors when schema objects had dependencies between them (for example, when a sequence's default expression was being removed).#145999",
            "Creating a vector index on a table that contains aNULLvector value will no longer cause an internal error.#146017",
            "Row-level security (RLS)SELECTpolicies duringUPDATEoperations are now only applied when referenced columns appear in theSETorWHEREclauses, matching the behavior of PostgreSQL. This improves compatibility.#146128",
            "Fixed an internal assertion failure that could occur during operations likeALTER TYPEorALTER DATABASE ... ADD REGIONwhen temporary tables were present.#146196",
            "Fixed incorrect application of row-level security (RLS)SELECTpolicies toRETURNINGclauses inINSERTandUPDATEwhen no table columns were referenced.#146292",
            "Fixed a bug that preventedTRUNCATEfrom succeeding if any indexes on the table had back-reference dependencies, such as from a view or function referencing the index.#146326",
            "Fixed a bug that could lead to a node stall.#146409",
            "Fixed an integer overflow in thesplit_partfunction when using extremely negative field positions like Go'smath.MinInt64.#146413",
            "Fixed a bug where an invalid comment in thesystem.commenttable for a schema object could make it inaccessible.#146418",
            "Fixed a bug where a CockroachDB node could crash when executingDOstatements that contain currently unsupported DDL statements likeCREATE TYPEin a non-default configuration (additional logging needed to be enabled, e.g., via thesql.log.all_statements.enabledcluster setting). This bug was introduced in v25.1.#146501",
            "Prevent use of future timestamps when usingAS OF SYSTEM TIMEwithCREATE TABLE ... ASand materialized views. Previously, such timestamps could cause errors, delays, or hangs.#146605",
            "Fixed a bug where CockroachDB would not use the vectorized fast path forCOPYwhen it was supported. The bug was only present in previous v25.2 releases.#146697",
            "Fixed an internal error that could be hit whenADD COLUMN UNIQUEandALTER PRIMARY KEYwere executed within the same transaction.#146743",
            "Fixed a bug whereALTER TABLEoperations with multiple commands could generate invalid zone configurations.#146750",
            "Fixed a bug in v25.2.0 where a vector search operator could drop user-supplied filters if the same vector column was indexed twice and a vector index with no prefix columns was defined after a vector index with prefix columns.#146849",
            "Fixed an issue where updating child metrics and reinitializing metrics at the same time could cause scrape errors.#147531",
            "Fixed a runtime panic in thesubstring_indexfunction that occurred when the count argument was the minimum 64-bit integer value.#147550",
            "Fixed a memory leak in index backfill jobs where completed spans were duplicated in memory on each progress update after resuming from a checkpoint. This could cause out-of-memory (OOM) errors when backfilling indexes on large tables with many ranges. This bug affected release version v25.2.0 and pre-release versions v25.2.0-alpha.3 through v25.2.0-rc.1.#147564"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-rc.1",
        "date": "May 12, 2025",
        "changes": [
            "Non-integer array indices are now supported in JSONPath queries (e.g.,SELECT jsonb_path_query('[1, 2, 3]', '$[2.5]');). Indices are rounded toward 0.#144819",
            "Thevector_l2_opsoperator class can now be specified for a vector index. Becausevector_l2_opsis the default, it is possible to omit the operator class from an index definition.#144902",
            "When creating a vector index with theUSINGsyntax,hnswcan now be specified as the index type, although acspannvector index is still provided. This change increases compatibility with third-party tools.#144902",
            "Added support for numeric JSONPath methods.abs(),.floor(),.ceiling(). For example,SELECT jsonb_path_query('-0.5', '$.abs()');.#145121",
            "DisabledIMPORT INTOfor tables with vector indexes, because importing into vector indexes is not implemented.#145262",
            "Added support forlike_regexflags in JSONPath queries. For example,SELECT jsonb_path_query('{}', '\"a\" like_regex \".*\" flag \"i\"');.#145300",
            "Vector index creation is now prevented until the entire cluster upgrade has been finalized on v25.2 or later.#145449",
            "NULLvectors can now be inserted into tables with vector indexes.#144858",
            "Fixed a bug that caused vector indexes to return incorrect or no results from a standby reader in a physical cluster replication (PCR) setup. This bug existed in alpha versions of v25.2 and in v25.2.0-beta.1.#145157",
            "Fixed a bug that allowed a set-returning PL/pgSQL function to be created before the version change was finalized. This bug existed in v25.2 alpha and beta releases.#145381",
            "Fixed a bug where CockroachDB could encounter an internal error when fetching from theWITH HOLDcursor withFETCH FIRSTandFETCH ABSOLUTE. The bug was only present in v25.2 alpha and beta releases.#145409",
            "Some internal queries executed by the jobs system are now less likely to perform full table scans of thesystem.jobstable, making them more efficient. This change can be reverted by disabling thejobs.avoid_full_scans_in_find_running_jobs.enabledcluster setting.#144825",
            "SQL queries run on the source cluster by logical data replication (LDR) and physical cluster replication (PCR) will account to internal metrics likesql.statements.active.internalinstead of the metrics likesql.statements.activethat are used to monitor application workload.#145111"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-beta.3",
        "date": "April 28, 2025",
        "changes": [
            "CREATE VECTOR INDEXandALTER PRIMARY KEYnow send a notice that vector indexes will be offline during the change operation when thesql_safe_updatessession setting is disabled.#144601",
            "Vector indexes do not support mutation while being created withCREATE INDEXor rebuilt withALTER PRIMARY KEY. To prevent inadvertent application downtime, set thesql_safe_updatessession setting tofalsewhen usingCREATE INDEXorALTER PRIMARY KEYwith a vector index.#144601",
            "The variable arguments of polymorphic built-in functions (e.g.,concat,num_nulls,format,concat_ws, etc.) no longer need to have the same type, matching PostgreSQL behavior. As a result, CockroachDB's type inference engine will no longer be able to infer argument types in some cases where it previously could, and there is a possibility that CockroachDB applications will encounter new errors. The new session variableuse_pre_25_2_variadic_builtinsrestores the previous behavior (and limitations).#144600",
            "Fixed a bug that could cause a changefeed to complete erroneously when one of its watched tables encounters a schema change.#144717",
            "Fixed a bug in the DB Console where tables with page size dropdowns failed to update when a new page size option was selected. Tables now update correctly.#144666",
            "Fixed the following bugs in theSchedulespage of the DB Console:Where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.Where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144807",
            "Where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.",
            "Where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144807",
            "Fixed a bug in theSQL Activity Statementspage where filtering byStatement Typereturned no results. The filter now works as expected.#144851",
            "Fixed a bug in the DB Console where theDrop unused indextag appeared multiple times for an index on theIndexestab of theTable Detailspage.#144656",
            "Triggers now perform the descriptor lookup forTG_TABLE_SCHEMAagainst a cache. This can significantly reduce trigger planning latency in multi-region databases.#144521",
            "The vector search optimizer rule now supports additional projections beyond the distance column, including the implicit projections added for virtual columns.#144583"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-beta.2",
        "date": "April 23, 2025",
        "changes": [
            "Added thejsonb_path_matchfunction, which returns the result of a predicate query.#144271",
            "The.type()method is now supported in JSONPath queries. For example,SELECT jsonb_path_query('[1, 2, 3]', '$.type()');.#144405",
            "Removed theST_3DLengthfunction.#144549",
            "Added thejsonb_path_query_firstfunction, which returns the first result fromjsonb_path_query.#144271",
            "Parenthesized expressions are now supported in JSONPath queries. For example,SELECT jsonb_path_query('{\"a\": {\"b\": true}}', '($.a).b');#144298",
            "The.size()method is now supported in JSONPath expressions. For example,SELECT jsonb_path_query('[1, 2, 3]', '$.size()');.#144405",
            "Added thejsonb_path_query_arrayfunction, which returns the result ofjsonb_path_querywrapped in a JSON array.#144271",
            "Logical data replication (LDR) now supports partial indexes by default.#144513",
            "Fixed a rare corruption bug that could affectIMPORT, physical cluster replication (PCR),CREATE TABLE AS(CTAS), and materialized view refreshes.#144663",
            "Vector indexes created in v25.2.0-beta.1 are not compatible with later releases. Drop and re-create these indexes before using them with later releases.#144581"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-beta.1",
        "date": "April 14, 2025",
        "changes": [
            "Set-returning functions (SRF) are now supported in PL/pgSQL. A PL/pgSQL SRF can be created by declaring the return type asSETOF <type>orTABLE.#143820",
            "Usage ofTG_ARGVin trigger functions is now disallowed by default. The session settingallow_create_trigger_function_with_argv_referencescan be set totrueto allow usage (with 1-based indexing).#143827",
            "The return type of theworkload_index_recsbuilt-in function now includes two columns. The first column,index_rec, remains aSTRINGtype and contains the index recommendation. The second column,fingerprint_ids, is new and has theBYTES[]type.#142927",
            "The job description forAUTO CREATE PARTIAL STATSnow clearly indicates that the job is for automatic partial statistics collection, improvingsystem.jobsvisibility and debugging.#143283",
            "A newexecution timestatistic is now reported onEXPLAIN ANALYZEoutput for most operators. Previously, this statistic was only available on the DistSQL diagrams inEXPLAIN ANALYZE (DISTSQL)output.#143857",
            "() is unknownis now supported in JSONPath queries. For example,SELECT jsonb_path_query('{}', '($ < 1) is unknown');.#143668",
            "starts with \"\"is now supported in JSONPath queries. For example,SELECT jsonb_path_query('\"abcdef\"', '$ starts with \"abc\"');.#143675",
            "Thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting was retired.#143124",
            "debug zipqueries are now attributed to internal SQL metrics. As a result, users will no longer see their impact on the SQL charts in the DB Console.#143711",
            "Fixed an issue where hot range logging for virtual clusters omitted some hot ranges.#143775",
            "MVCC garbage collection is now fully subject to IO admission control. Previously, it was possible for MVCC GC to cause store overload (such as LSM inversion) when a large amount of data would become eligible for garbage collection. Should any issues arise from subjecting MVCC GC to admission control, thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting can be set tofalseto restore the previous behavior.#143122",
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144027",
            "Fixed an issue where change data capture queries on tables without columns would fail with an internal error:unable to determine result columns.#142068",
            "Previously, statement bundle collection could encounternot enough privilegeserrors when retrieving necessary information (e.g., cluster settings, table statistics, etc.) when the user that requested the bundle was different from the user that actually ran the query. This is now fixed. The bug was present since v20.2 and would result in partially incomplete bundles.#144178",
            "Fixed an issue where databases, tables, and indexes were not appearing on the Hot Ranges page for application virtual clusters.#143441"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-alpha.3",
        "date": "April 7, 2025",
        "changes": [
            "lastis now supported for array indexing in JSONPath queries. For example,SELECT jsonb_path_query('[1, 2, 3, 4]', '$[1 to last]');.#143658",
            "String comparisons are now supported in JSONPath queries. For example,SELECT jsonb_path_query('{}', '\"a\" < \"b\"');.#143240",
            "Added theST_3DLengthfunction, which returns the 3D or 2D length ofLINESTRINGandMULTILINESTRINGspatial types.#139450",
            "Updated edge cases in thewidth_bucket()function to returncount + 1for a positive infinity operand, and0for a negative infinity operand, instead of an error.#142932",
            "Unary arithmetic operators are now supported in JSONPath queries. For example,SELECT jsonb_path_query('[1, 2, 3]', '-$');.#143613",
            "Implemented variouspower()and^edge cases to match PostgreSQL behaviour. Some expressions that previously returnedNaNnow return specific numbers; some expressions that previously returnedInfinityorNaNnow return errors; and some expressions with infinite exponents now return different results.#142932",
            "Null comparisons are now supported in JSONPath queries. For example,SELECT jsonb_path_query('{}', 'null != 1');.#143240",
            "Wildcard key accessors are now supported in JSONPath queries. For example,SELECT jsonb_path_query('{\"a\": 1, \"b\": true}', '$.*');.#143588",
            "like_regexpredicate evaluation is now supported in JSONPath queries. For example,SELECT jsonb_path_query('{}', '\"hello\" like_regex \"^he.*$\"');.#143240",
            "Theserver.client_cert_expiration_cache.capacitycluster setting has been removed. Thesecurity.certificate.expiration.clientandsecurity.certificate.ttl.clientmetrics now report the lowest value observed for a user in the last 24 hours.#143384",
            "Previously, the user provided in the source URI in the logical data replication (LDR) stream required theREPLICATIONSOURCEprivilege at the system level. With this change, the user only needs this privilege on the source tables (i.e., a table-level privilege).#143456",
            "The lock and latch wait time components of a query's cumulative contention time are now tracked separately and surfaced as annotations inEXPLAIN ANALYZEoutput.#113649",
            "The metric that measures cumulative contention time now includes time spent waiting to acquire latches, in addition to time spent acquiring locks. This metric is displayed in both the DB Console and theEXPLAIN ANALYZEoutput.#113649",
            "Fixed a bug where index backfills unnecessarily merged new data written to an index, which could lead to extra contention.#142768",
            "Column IDs are now validated when starting animmediatemode logical data replication stream.#143773",
            "Fixed a bug where a GC threshold error (which appears as \"batch timestamp must be after replica GC threshold ...\") could cause a schema change that backfills data to fail. Now, the error will cause the backfill to be retried at a higher timestamp to avoid the error.#143451",
            "Fixed a bug where index backfill progress before aPAUSE/RESUMEwould not get tracked.#142602",
            "Fixed a bug that could cause a function reference to be left behind if a procedure referred to another procedure that depended on a a table, and that table was dropped withCASCADE.#143538",
            "Fixed a potential deadlock that could occur during client certificate updates while metrics were being collected. This issue affected the reliability of certificate expiration reporting.#143663",
            "Previously, the fieldsmaximum memory usageandmax sql temp disk usagein theEXPLAIN ANALYZEoutput could be under-reported for distributed plans when memory-intensive operations were fully performed on the remote nodes. This is now fixed. The bug existed in v22.1 and later.#143777",
            "TheALTER VIRTUAL CLUSTER SET REPLICATION READ VIRTUAL CLUSTERsyntax is now supported for adding a reader virtual cluster for an existing physical cluster replication (PCR) standby cluster.#143752",
            "Schema changes that require data to be backfilled no longer hold a protected timestamp for the entire duration of the backfill, which means there is less overhead caused by MVCC garbage collection after the backfill completes.#143451",
            "Fixed a bug that caused the optimizer to over-estimate the cost of inverted index scans in some cases. Now, plans with inverted index scans should be selected in more cases where they are optimal.#120079"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-alpha.2",
        "date": "March 31, 2025",
        "changes": [
            "num_nulls()andnum_nonnulls()no longer require that all arguments have the same type.#141193",
            "concat()no longer requires that all arguments have the same type.#141193",
            "pg_column_size()no longer requires that all arguments have the same type.#141193",
            "Users can now begin logical data replication (LDR) on an existing table if the user has a table-levelREPLICATIONDESTprivilege. Furthermore, users can now begin LDR onto an automatically created table if the user has the parent database levelCREATEprivilege. Finally, during bidirectional LDR, the user in the original source URI, who will begin the reverse LDR stream, will authorize via this table-levelREPLICATIONDESTprivilege.#142840",
            "concat_ws()now accepts arguments of any type in the second and later positions (the separator must still be a string).#141193",
            "Filters are now supported in JSONPath queries, using the format$ ? (predicate). This allows results to be filtered. For example,SELECT jsonb_path_query('{\"a\": [1,2,3]}', '$.a ? (1 == 1)');.#143097",
            "format()no longer requires that all post-format string arguments have the same type.#141193",
            "json_build_object(),jsonb_build_object(),json_build_array(), andjsonb_build_array()no longer require that all arguments have the same type.#141193",
            "Added thejsonb_path_existsfunction, which accepts a JSON object and JSONPath query and returns whether the query returned any items.#143028",
            "Addition, subtraction, multiplication, division, and modulo operators are now supported in JSONPath queries.#143210",
            "AllALTER VIRTUAL CLUSTER REPLICATION JOBcommands for physical cluster replication (PCR), except forALTER VIRTUAL CLUSTER SET REPLICATION SOURCE, will require theREPLICATIONDESTprivilege, in addition toMANAGEVIRTUALCLUSTER.ALTER VIRTUAL CLUSTER SET REPLICATION SOURCEnow requires theREPLICATIONSOURCEprivilege. If the ingestion job was created before v25.1, the user can still alter the replication job without theREPLICATIONDESTprivilege.#142772",
            "The lock and latch wait time components of a query's cumulative contention time are now tracked separately and surfaced as annotations inEXPLAIN ANALYZEoutput.#113649",
            "The metric that measures cumulative contention time now includes time spent waiting to acquire latches, in addition to time spent acquiring locks. This metric is displayed in both the DB Console and theEXPLAIN ANALYZEoutput.#113649",
            "The Replica Quiescence graph on the Replication dashboard in the DB Console now displays the number of replicas quiesced with leader leases.#143215",
            "Fixed a bug where index backfills unnecessarily merged new data written to an index, which could lead to extra contention.#142768",
            "Fixed a bug that could leave behind a dangling reference to a dropped role if that role had default privileges granted to itself. The bug was caused by defining privileges such as:ALTER DEFAULT PRIVILEGES FOR ROLE self_referencing_role GRANT INSERT ON TABLES TO self_referencing_role.#143287",
            "Fixed a bug that caused changefeeds to fail on startup when scanning a single key.#143102",
            "Fixed a bug where secondary indexes could be unusable by DML statements while a primary key swap was occurring, if the new primary key did not contain columns from the old primary key.#141850",
            "Fixed a crash due touse of enum metadata before hydrationwhen using LDR with user-defined types.#143311",
            "MVCC garbage collection is now fully subject to IO admission control. Previously, it was possible for MVCC GC to cause store overload (such as LSM inversion) when a large amounts of data would become eligible for garbage collection. Should any issues arise from subjecting MVCC GC to admission control, thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting can be set tofalseto restore the previous behavior.#143122",
            "Fixed a bug where CockroachDB would encounter an internal error when decoding the gists of plans withCALLstatements. The bug had been present since v23.2.#143252",
            "Fixed a bug where calling a stored procedure could drop the procedure if it hadOUTparameters that were not used by the calling routine. This bug had existed since PL/pgSQLCALLstatements were introduced in v24.1.#143173",
            "Fixed a bug where CockroachDB incorrectly resolved routine overloads in some cases. Previously, it allowed creating routines with signatures differing only in type width (e.g.,f(p VARCHAR(1))andf(p VARCHAR(2))), which is not permitted in PostgreSQL. This required precise type casting during invocation. Similarly, when dropping a routine, CockroachDB previously required exact types, unlike PostgreSQL, which is more lenient (e.g.,DROP FUNCTION f(VARCHAR)would fail in the preceding example). This bug had existed since v23.1.#143159",
            "The reader virtual cluster now starts if the user begins a physical cluster replication (PCR) stream from a cursor viaALTER VIRTUAL CLUSTER virtual_cluster START REPLICATION OF physical_cluster ON pgurl WITH READ VIRTUAL CLUSTER.#143072",
            "Index backfills and row-level TTL deletions that encounter transaction contention will now be retried with smaller batch sizes more quickly, which reduces the latency of these jobs under high-contention workloads.#142702",
            "Queries that useSHOW TABLESwithout using theestimated_row_countcolumn no longer need to look up the table statistics.#59838",
            "pg_column_size()is now regarded as Stable, matching PostgreSQL. As a result, it will no longer be allowed in computed column expressions or partial index predicate expressions.#141193"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0-alpha.1",
        "date": "March 24, 2025",
        "changes": [
            "The default value of theautocommit_before_ddlsession variable is nowtrue. This will cause any schema change statement that is sent during a transaction to make the current transaction commit before executing the schema change in a separate transaction. CockroachDB does not have full support for multipleschema changes in a transaction. Users who do not want the autocommit behavior can preserve the previous behavior by changing the default value ofautocommit_before_ddlwith:ALTER ROLE ALL SET autocommit_before_ddl = false;.#139871",
            "Added theserver.oidc_authentication.provider.custom_cacluster setting to support custom root CA for verifying certificates while authenticating with the OIDC provider.#140583",
            "When changefeeds are created with aresolvedoption lower than themin_checkpoint_frequencyoption, an error message was displayed to inform the user. This message is now a notice and includes extra information if either option was set to its default value.#142094",
            "Added the logging ofchangefeed_canceledevents to the telemetry log.#142139",
            "Updated the response headers of HTTP requests to include\"Cache-control: no-store\"instead of\"Cache-control:no-cache\", which means that HTTP requests to the server will no longer be cached in the client. Requests for UI assets, such asbundle.jsand fonts, will still include\"Cache-control:no-cache\"to ensure they are cached and that the DB console loads quickly.#142277",
            "Added theheaders_json_column_nameoption to the Kafka sink, allowing users to specify a column in their table(s) of typeJSONBto be used as the Kafka headers for each row.#142092",
            "Improved S3 credential caching for STS credentials.#142434",
            "Theplan_cache_modesession setting now defaults toauto, enabling generic query plans for some queries.#135668",
            "SHOW JOBSis now based on a new mechanism for storing information about the progress and status of running jobs.#138104",
            "SHOW VIRTUAL CLUSTER WITH REPLICATION STATUSnow displays theingestion_job_idcolumn after thenamecolumn.#138967",
            "Since v23.2 table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS. This can be reverted by setting the cluster settingsql.stats.non_indexed_json_histograms.enabledtotrue.#139766",
            "optimizer_use_merged_partial_statisticsis now enabled by default, meaning the optimizer will use partial stats if available to estimate more up-to-date statistics.#139925",
            "Theoptimizer_prefer_bounded_cardinalitysession setting has been added that instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default.#139985",
            "Theoptimizer_min_row_countsession setting has been added that sets a lower bound on row count estimates for relational expressions during query planning. A value of0, which is the default, indicates no lower bound. If this is set to a value greater than0, a row count of0can still be estimated for expressions with a cardinality of0, e.g., for a contradictory filter. Setting this to a value higher than0, such as1, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate.#140065",
            "Fixed a bug existing only in pre-release versions of v25.1 that could cause unexpected errors during planning forVALUESexpressions containing function calls with multiple overloads.#140277",
            "Theoptimizer_check_input_min_row_countsession setting has been added to control the minimum row count estimate for buffer scans of foreign key and uniqueness checks. It defaults to0.#140735",
            "Added thejsonpathtype, without parsing, evaluation, or table creation. Currently accepts any non-empty string.#140204",
            "Added thesubstring_indexbuilt-in function, which extracts a portion of a string based on a specified delimiter and occurrence count, which follows MySQL behavior.#141929",
            "Added compression support for changefeed webhook sinks. This reduces network bandwidth and storage usage, improving performance and lowering costs. Users can enable compression by setting thecompression=<algorithm>option. Supported algorithms aregzipandzstd.#138872",
            "Holdable cursors declared usingCURSOR WITH HOLDare now supported. A holdable cursor fully executes a query upon transaction commit and stores the result in a row container, which is maintained by the session.#141943",
            "Thesplit_partbuilt-in function now supports negativereturn_index_posvalues, returning the |n|th field from the end when specified.#141944",
            "Added a parser for thejsonpathtype. Accepts setting mode (strict/lax), key accessors (.name), and array wildcards ([*]).#142010",
            "Added the new optionWITH IGNORE_FOREIGN_KEYSto theSHOW CREATE TABLEstatement so that foreign key constraints are not included in the output schema. This option is also acceptable inSHOW CREATE VIEW, but has no influence there. It cannot be combined with the existingWITH REDACToption.#142151",
            "CREATE TABLE AS SELECT ... FROM ... AS OF SYSTEM TIME xis now supported. It cannot be executed within an explicit transaction.#142147",
            "Invocations of stored procedures viaCALLstatements will now be counted toward the newly addedsql.call_stored_proc.count.startedandsql.call_stored_proc.countmetrics. Previously, they were counted against thesql.misc.count.startedandsql.misc.countmetrics.#142249",
            "Statements such asREFRESH MATERIALIZED VIEWandCREATE MATERIALIZED VIEWcan now be executed with anAS OF SYSTEM TIMEclause. These statements can still not be used in an explicit transaction.#142259",
            "Added support for the following in thejsonpathparser:Double-quoted key accessors withinjsonpath(SELECT '$.\"1key\".\"key2\"'::JSONPATH;).Array integer indexing (ex.$.a[1]).Array ranges (ex.$.a[1 to 3]).Array unions (ex$.a[1, 2 to 4, 7, 8]).#142241",
            "Double-quoted key accessors withinjsonpath(SELECT '$.\"1key\".\"key2\"'::JSONPATH;).",
            "Array integer indexing (ex.$.a[1]).",
            "Array ranges (ex.$.a[1 to 3]).",
            "Array unions (ex$.a[1, 2 to 4, 7, 8]).#142241",
            "Fixed a regression due to join-elimination rules that left a Project operator below aJOIN, preventing optimizer rules from applying.#142252",
            "AddedALTER VIRTUAL CLUSTER .. SET REPLICATION SOURCEso users can configure the producer jobs on the source cluster for physical cluster replication (PCR). Currently, they can only configure theEXPIRATION WINDOW. This patch also removes theEXPIRATION WINDOWoption from the consumer side of the statement,ALTER VIRTUAL CLUSTER SET REPLICATION.#142501",
            "Added thejsonb_path_queryfunction, which takes in a JSON object and ajsonpathquery, and returns the resulting JSON object.#142336",
            "Updated theCREATE TRIGGERstatementonly implemented in the declarative schema changererror message to include a helpful suggestion and link to relevant docs.#141738",
            "Removed thestorage.queue.store-failuresmetric.#139150",
            "Customers must provide URIs as external connections to create logical data replication (LDR) statements.#139383",
            "The following cluster settings have been deprecated:sql.metrics.statement_details.plan_collection.enabledsql.metrics.statement_details.plan_collection.period#138042",
            "sql.metrics.statement_details.plan_collection.enabled",
            "sql.metrics.statement_details.plan_collection.period#138042",
            "Reduced noise when using dynamically provisioned logging sinks.#139565",
            "Added metrics for monitoring changefeed span-level checkpoint creation:changefeed.checkpoint.create_nanos, which measures the time it takes to create a changefeed checkpoint.changefeed.checkpoint.total_bytes, which measures the total size of a changefeed checkpoint in bytes.changefeed.checkpoint.span_count, which measures the number of spans in a changefeed checkpoint.#139375",
            "changefeed.checkpoint.create_nanos, which measures the time it takes to create a changefeed checkpoint.",
            "changefeed.checkpoint.total_bytes, which measures the total size of a changefeed checkpoint in bytes.",
            "changefeed.checkpoint.span_count, which measures the number of spans in a changefeed checkpoint.#139375",
            "The following schema changes are now allowlisted to run during LDR.ALTER INDEX RENAME.ALTER INDEX .. NOT VISIBLE.ALTER TABLE .. ALTER COLUMN .. SET DEFAULT.ALTER TABLE .. ALTER COLUMN .. DROP DEFAULT.ALTER TABLE .. ALTER COLUMN SET VISIBLE.#141858",
            "ALTER INDEX RENAME.",
            "ALTER INDEX .. NOT VISIBLE.",
            "ALTER TABLE .. ALTER COLUMN .. SET DEFAULT.",
            "ALTER TABLE .. ALTER COLUMN .. DROP DEFAULT.",
            "ALTER TABLE .. ALTER COLUMN SET VISIBLE.#141858",
            "Addedsql.statement_timeout.countto track the number of SQL statements that fail due to exceeding the statement timeout.#142078",
            "Added thesql.transaction_timeout.countmetric to track the number of SQL statements that fail due to exceeding the transaction timeout.#142105",
            "Added thejobs.row_level_ttl.num_delete_batch_retriesmetric to track the number of times the TTL job had to reduce the batch size and try again.#141953",
            "To create a logical data replication (LDR) stream, users require theREPLICATIONDESTprivilege, instead of theREPLICATIONprivilege.#142345",
            "To create a physical cluster replication (PCR) stream, users require theREPLICATIONDESTprivilege, in addition to the already requiredMANAGEVIRTUALCLUSTERprivilege.#142345",
            "Removed thekv.snapshot_receiver.excise.enablecluster setting. Excise is now enabled unconditionally.#142651",
            "Introduced the cluster settingserver.child_metrics.include_aggregate.enabled, which modifies the behavior of Prometheus metric reporting (/_status/vars). By default, it is set totrue, which maintains the existing behavior. It can be sert tofalseto stop the reporting of the aggregate time series that prevents issues with double counting when querying metrics.#141601",
            "When configuring thesql.ttl.default_delete_rate_limitcluster setting, a notice is displayed informing that the TTL rate limit is per leaseholder per node with a link to the docs.#142061",
            "Added a newenvelopetypeenrichedfor changefeeds.#140112",
            "Added support for theenrichedenvelope type to Avro format changefeeds.#140525",
            "The cluster settingchangefeed.new_webhook_sink_enabled/changefeed.new_webhook_sink.enabledis no longer supported. The new webhook sink has been enabled by default since v23.2, and the first version webhook sink has been removed.#141940",
            "The cluster settingchangefeed.new_pubsub_sink_enabled/changefeed.new_pubsub_sink.enabledis no longer supported. The new Google Cloud Pub/Sub sink has been enabled by default since v23.2, and the first version Pub/Sub sink has been removed.#141948",
            "DROP INDEXcan now only be run whensql_safe_updatesis set tofalse.#139456",
            "Improved the performance of the debug zip query that collectstransaction_contention_eventsdata, reducing the chances ofmemory budget exceededorquery execution canceled due to statement timeouterrors.#139735",
            "Removed the deprecated--storage-engineparameter from the CLI.#139744",
            "The/_admin/v1/settingsAPI (and therefore cluster settings console page) now returns cluster settings using the same redaction logic as queryingSHOW CLUSTER SETTINGSandcrdb_internal.cluster_settings. This means that only settings flagged as \"sensitive\" will be redacted, all other settings will be visible. The same authorization is required for this endpoint, meaning the user must be anadmin, haveMODIFYCLUSTERSETTINGS, orVIEWCLUSTERSETTINGSroles to use this API. The exception is that if the user hasVIEWACTIVITYorVIEWACTIVITYREDACTED, they will see console-only settings.#138688",
            "TheOverloaddashboard in the DB Console now shows only the v2 replication admission control metrics, where previously it displayed both v1 and v2 metrics. Additionally, the aggregate size of queued replication entries is now shown.#139066",
            "Jobs can now choose to emit messages that are shown on theJobs Detailspage in v25.1 and later.#139246",
            "An event is posted when a store is getting close to full capacity.#139199",
            "Percentile latencies are no longer available forSQL Activity. The implementation of these percentiles was error-prone and difficult to understand because it was computed differently from the other SQL statistics collected. Customers interested in viewing percentile latencies per statement fingerprint are encouraged to use the experimental per-fingerprint histograms that can be enabled with thesql.stats.detailed_latency_metrics.enabledcluster setting. This will enable externalized histogram metrics via the Prometheus scrape endpoint.#139500",
            "Surfaced commit latency on theTransactionspages#139946",
            "Removed thePaused Followergraph from theReplicationdashboard in the DB Console as followers are no longer paused by default from v25.1.#141427",
            "DB console'sindex.htmlpage now includes a Content-Security-Policy (CSP) header to help prevent malicious XSS attacks.#142282",
            "Previously, storage parameters with the same key would lead to ambiguity. This has now been fixed and an error surfaced if duplicate storage parameters are specified.#139172",
            "Fixed a bug where the errorbatch timestamp T must be after replica GC thresholdcould occur during a schema change backfill operation, causing the schema change job to retry infinitely. Now, this error is treated as permanent, and will cause the job to enter thefailedstate.#139203",
            "Previously, whenever CockroachDB collected a statement bundle when plan-gist-based matching was used, theplan.txtfile would be incomplete. This bug is now fixedit had been present since the introduction of the plan-gist-based matching feature in v23.1, but was partially addressed in the v24.2 release.#127604",
            "Previously,EXPLAIN ANALYZEof mutation statements would always getactual row count: 1execution statistic for the corresponding mutation node in the plan, regardless of how many rows were actually modified. The bug has been present since before v22.2 and is now fixed.#139278",
            "Fixed a bug where sometimes activating diagnostics for SQL activity appeared unresponsive, with no state or status update upon activating. Now, the status should always reflect that diagnostics are active or that a statement bundle is downloadable.#139342",
            "Theto_regclass,to_regtype,to_regrole, and related functions now returnNULLfor any numerical input argument.#139777",
            "Fixed a rare bug in which a query might fail with the errorcould not find computed column expression for column in tablewhile dropping a virtual computed column from the table. This bug was introduced in v23.2.4.#139388",
            "The optimizer could produce incorrect query plans for queries using trigram similarity filters (e.g.,col % 'val') whenpg_trgm.similarity_thresholdwas set to0. This bug was introduced in v22.2.0 and is now fixed. Note that this issue does not affect v24.2.0 and later releases when theoptimizer_use_trigram_similarity_optimizationsession variable (introduced in v24.2.0) is set to its default valuetrue, as it would skip this behavior.#139265",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter abatch timestamp must be after replica GC thresholderror.#139532",
            "Fixed a bug that existed only in pre-release versions of v25.1. The bug could cause creation of a PL/pgSQL routine with a common table expression (CTE) to fail with an error like the following:unexpected root expression: with.#140083",
            "Configuring replication controls on a partition name of an index that is not unique across all indexes will correctly impact only that partition.#140167",
            "TheData distributionpage in Advanced Debug will no longer crash if there areNULLvalues forraw_sql_configincrdb_internal.zones.#140066",
            "Fixed a bug where dropping a table with a trigger using the legacy schema changer could leave an orphaned reference in the descriptor. This occurred when two tables were dependent on each other via a trigger, and the table containing the trigger was dropped.#140995",
            "Addressed a bug that could cause concurrent DML operations to prevent primary key changes from succeeding.#141189",
            "Fixed a bug that prevented transaction retry errors encountered during implicit transactions from being automatically retried internally if theautocommit_before_ddlsession variable was enabled and the statement was a schema change.#141369",
            "A step in the v25.1 upgrade finalization process that required backfilling jobs now uses locks to ensure it makes progress even when there is contention on the jobs table, which will prevent the possibility of becoming stuck under heavy load.#141420",
            "Fixed a bug that could preventSHOW CREATE TABLEfrom working if a database was offline (e.g., due to aRESTOREon that database).#141195",
            "Fixed a bug that prevented starting multi-table logical data replication (LDR) streams on tables that used user-defined types.#141634",
            "Fixed a bug that could causenil pointer dereferenceerrors when executing statements with UDFs. The error could also occur when executing statements with some built-in functions, likeobj_description.#141596",
            "Fixed a bug where a node that was drained as part of decommissioning may have interrupted SQL connections that were still active during drain (and for which drain would have been expected to wait).#141411",
            "Fixed a bug where the fraction completed and internal checkpoints during an index backfill operation would stop getting written if any of the periodic fraction/checkpoint write operations failed. Additional logging was added so that progress is logged in addition to being written to the job record. This bug affected schema change operations, such as creating an index or adding a non-nullable column to a table.#141714",
            "Fixed a bug that could cause gateway nodes to panic when performing anUPSERTon a table with aBOOLprimary key column and a partial index with the primary key column as the predicate expression.#141728",
            "Fixed a bug where CockroachDB could incorrectly evaluate casts to someOIDtypes (likeREGCLASS) in some cases. The bug has been present since at least v22.1.#141946",
            "Transactions that enter theabortedstate now release locks they are holding immediately, provided there is noSAVEPOINTactive in the transaction.#140160",
            "Fixed a bug when running withautocommit_before_ddlthat could cause a runtime error when binding a previously prepared DDL statement.#142034",
            "Fixed a bug where orphaned leases were not properly cleaned up.#141429",
            "Previously, theCREATE LOGICALLY REPLICATEDsyntax would always create the destination side table with the source side name, instead of the user-provided name. This change ensures the user-provided name is used.#142235",
            "Fixed a bug that would preventCREATE TRIGGERandDROP TRIGGERstatements from working if theautocommit_before_ddlsetting was enabled, and if the statement was either sent as a prepared statement or as part of a batch of multiple statements.#142202",
            "Fixed a bug that could cause the upgrade to v25.1 to crash if a job was missing from the virtual table, for example, if a malformed job had no payload information.#142284",
            "The TTL deletion job now includes a retry mechanism that progressively reduces the batch size when encountering contention. This improves the chances of successful deletion without requiring manual adjustments to TTL job settings.#141953",
            "Fixed an issue where removed nodes could leave persistent entries incrdb_internal.gossip_alerts.#142385",
            "Invalid default expressions could cause backfilling schema changes to retry forever.#142490",
            "Fast failback could succeed even if the destination cluster's protected timestamp had been removed, causing the reverse stream to enter a crashing loop. This fix ensures the failback command fast fails.#142231",
            "Fixed an issue where dropping a database with triggers could fail due to an undropped back reference to a trigger function.#142670",
            "Fixed a bug where replication controls on indexes and partitions would not get properly updated during an index backfill (in the declarative schema changer) to its new ID; effectively discarding the replication controls set on it before the backfill.#141800",
            "Addressed a bug whereCREATE SEQUENCEcould succeed under with aDROP SCHEMAorDROP DATABASEin progress.#142696",
            "Fixed a bug in client certificate expiration metrics.#142682",
            "Physical cluster replication (PCR) reader catalogs could have orphan rows insystem.namespaceafter an object is renamed.#142829",
            "Fixed a bug where during validation of a table-level zone configuration, inherited values were incorrectly populated from the default range instead of from the parent database.#142760",
            "Fixed a bug that would send a replica outside of a tenant known region, whenSURVIVE REGION FAILUREwas set and exactly 3 regions were configured.#142838",
            "Improved directory traversal performance by switching fromfilepath.Walktofilepath.WalkDir.#139108",
            "Removed a potential storage read from the Raft commit pipeline. This reduces the worst-case KV write latency.#139609",
            "Theoptimizer_check_input_min_row_countsession setting now defaults to1, resulting in better query plans for foreign key and uniqueness checks.#140735",
            "This change restores the changefeed checkpoint immediately to the change frontier. This potentially reduces duplicate messages in the event that the frontier writes a checkpoint before it receives updates and covers the previous checkpoint from the aggregators, overwriting the checkpoint with less information.#139969",
            "Upgraded to Go v1.23.6.#140626",
            "Enabled the use of profile-guided optimization in thecockroachbinary.#142697",
            "Upgraded to Go v1.23.7.#142698",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "25.2",
        "patch_version": "25.2.0",
        "date": "May 12, 2025",
        "changes": [
            "Feature categoriesCockroachDB CloudPerformance and High AvailabilityChange Data CaptureObservabilitySecuritySQLLicensing",
            "CockroachDB Cloud",
            "Performance and High Availability",
            "Change Data Capture",
            "Observability",
            "Additional informationBackward-incompatible changesKey cluster setting changesDeprecationsKnown limitationsAdditional resources",
            "Backward-incompatible changes",
            "Key cluster setting changes",
            "Deprecations",
            "Known limitations",
            "Additional resources",
            "The default value of theautocommit_before_ddlsession variable is nowtrue. This will cause any schema change statement that is sent during a transaction to make the current transaction commit before executing the schema change in a separate transaction. Users who do not want the autocommit behavior can preserve the previous behavior by changing the default value ofautocommit_before_ddlwith:ALTER ROLE ALL SET autocommit_before_ddl = false;.#139871",
            "DROP INDEXcan now only be run whensql_safe_updatesis set tofalse.#139456",
            "Vector indexes do not support mutation while being created withCREATE INDEXor rebuilt withALTER PRIMARY KEY. To prevent inadvertent application downtime, set thesql_safe_updatessession setting tofalsewhen usingCREATE INDEXorALTER PRIMARY KEYwith a vector index.#144601",
            "The variable arguments of polymorphic built-in functions (e.g.,concat,num_nulls,format,concat_ws, etc.) no longer need to have the same type, matching PostgreSQL behavior. As a result, CockroachDB's type inference engine will no longer be able to infer argument types in some cases where it previously could, and there is a possibility that CockroachDB applications will encounter new errors. The new session variableuse_pre_25_2_variadic_builtinsrestores the previous behavior (and limitations).#144600",
            "Row-level security",
            "Creating a set-returning PL/pgSQL function",
            "Support for thejsonpathdata type",
            "feature.vector_index.enabled- Set toTRUEto enable vector indexes. Default isFALSE(not enabled).",
            "server.child_metrics.include_aggregate.enabled- WhenTRUE, reports both aggregate and child Prometheus metrics, which can be helpful for quick top-level insights or backward compatibility, but should be disabled if youre seeing inflated values in Prometheus queries due to double counting. Defaults toTRUE.",
            "ui.default_timezone- Allows you to set the time zone for displayed timestamps in the DB Console. (Refer toDB Console timezone configuration.) Replaces the deprecatedui.display_timezonecluster setting. If that value had been set, it will automatically be applied to the new settingui.default_timezone, which takes precedence.",
            "server.oidc_authentication.provider.custom_ca- Supports a custom root CA for verifying certificates while authenticating with an OIDC provider.",
            "sql.stats.automatic_full_collection.enabled- It is now possible to automatically collect partial table statistics, but disable automatic collection of full table statistics. To do so, change this setting toFALSE. It defaults toTRUE. In addition to this cluster setting, you can use the table settingsql_stats_automatic_full_collection_enabled.",
            "sql.stats.detailed_latency_metrics.enabled- Percentile latencies are no longer available forSQL Activity. The implementation of these percentiles was error-prone and difficult to understand because it was computed differently from the other SQL statistics collected. Customers interested in viewing percentile latencies per statement fingerprint are encouraged to use the experimental per-fingerprint histograms that can be enabled with thesql.stats.detailed_latency_metrics.enabledcluster setting. This will enable externalized histogram metrics via the Prometheus scrape endpoint.#139500",
            "To prevent unnecessary queuing in admission control CPU queues, set thegoschedstats.always_use_short_sample_period.enabledcluster setting totruefor any production cluster.",
            "Theui.display_timezonecluster settingis now deprecated and will be removed in a future release. If it has been set, its value will automatically be applied to the new settingui.default_timezone, which takes precedence. For further detail, refer toDB Console timezone configuration.",
            "TheEXPERIMENTAL CHANGEFEED FORSQL statement is now deprecated and will be removed in a future release. Instead, create a sinkless changefeed that emits messages directly to a SQL client with theCREATE CHANGEFEEDstatement."
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.9",
        "date": "April 2, 2025",
        "changes": [
            "Added theWITH IGNORE_FOREIGN_KEYSoption toSHOW CREATE TABLE, which omits foreign key constraints from the output schema. This option is also allowed inSHOW CREATE VIEW, but has no effect. It cannot be combined with theWITH REDACToption.#143368",
            "Added thesql.transaction_timeout.countmetric to track the number of SQL statements that fail due to exceeding the transaction timeout.#142156",
            "Added thesql.statement_timeout.countto track the number of SQL statements that fail due to exceeding the statement timeout.#142156",
            "Theserver.client_cert_expiration_cache.capacitycluster setting has been removed. Thesecurity.certificate.expiration.clientandsecurity.certificate.ttl.clientmetrics now report the lowest value observed for a user in the last 24 hours.#143593",
            "Fixed a bug that prevented starting multi-table Logical Data Replication (LDR) streams on tables that used user-defined types.#141793",
            "The TTL deletion job now includes a retry mechanism that progressively reduces the batch size when encountering contention. This improves the chances of successful deletion without requiring manual adjustments to TTL knobs. Also added thejobs.row_level_ttl.num_delete_batch_retriesmetric to track the number of times the TTL job had to reduce the batch size and try again.#142323",
            "Fixed a bug when running with theautocommit_before_ddlsession setting that could cause a runtime error when binding a previously prepared DDL statement.#141987",
            "Fixed a bug where CockroachDB could incorrectly evaluate casts to some OID types (likeREGCLASS) in some cases. The bug had been present since at least v22.1.#141958",
            "Fixed a bug that could cause gateway nodes to panic when performing anUPSERTon a table with aBOOLprimary key column and a partial index with the primary key column as the predicate expression.#141823",
            "Fixed a bug that would prevent theCREATE TRIGGERandDROP TRIGGERstatements from working if theautocommit_before_ddlsetting was enabled, and if the statement was either sent as a prepared statement or as part of a batch of multiple statements.#142303",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter abatch timestamp must be after replica GC thresholderror.#141720",
            "Fixed a bug where Physical Cluster Replication (PCR) reader catalogs could have orphaned rows insystem.namespaceafter an object is renamed.#142873",
            "Fixed a bug that could causenil pointer dereferenceerrors when executing statements with user-defined functions (UDFs). The error could also occur when executing statements with some built-in functions, likeobj_description.#141652",
            "Fixed a bug inv24.1.14,v24.3.7,v24.3.8, andv25.1that could cause a nil-pointer error when a column's default expression contained a volatile expression (likenextval) as a UDF argument.#143635",
            "Fixed a bug that could preventSHOW CREATE TABLEfrom working if a database was offline (e.g., due to aRESTOREon that database).#141509",
            "Fixed an issue where dropping a database with triggers could fail due to an undropped backreference to a trigger function.#142726",
            "Fixed a bug where the declarative schema changer allowedCREATE SEQUENCEoperations to proceed even while aDROP SCHEMAorDROP DATABASEwas in progress. Such operations now retry if the parent object has a schema change in progress, preventing new child objects from being created under deleted parent objects.#142763",
            "Fixed a potential deadlock that could occur during client certificate updates while metrics were being collected. This issue affected the reliability of certificate expiration reporting.#143593",
            "Fixed a bug where the fraction completed and internal checkpoints during an index backfill operation would stop getting written if any of the periodic fraction/checkpoint write operations failed. Progress is now logged in addition to being written to the job record. This bug affected schema change operations such as creating an index or adding a non-nullable column to a table.#141787",
            "Fixed a crash due touse of enum metadata before hydrationwhen using logical data replication (LDR) with user-defined types.#143389",
            "When configuring thesql.ttl.default_delete_rate_limitcluster setting, a notice is now displayed informing the user that the TTL rate limit is per leaseholder per table with alink to the docs.#142833",
            "Improved S3 credential caching for AWS Security Token Service (STS) credentials.#142437"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.8",
        "date": "March 12, 2025",
        "changes": [
            "Improved S3 credential caching for STS credentials to avoid exceeding the Amazon metadata service rate limit and encountering errors related to AssumeRole API calls when accessing large numbers of files in larger clusters.#142679"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.7",
        "date": "March 6, 2025",
        "changes": [
            "Added support for a new index hint,AVOID_FULL_SCAN, which will prevent the optimizer from planning a full scan for the specified table if any other plan is possible. The hint can be used in the same way as other existing index hints. For example,SELECT * FROM table_name@{AVOID_FULL_SCAN};. This hint is similar toNO_FULL_SCAN, but will not error if a full scan cannot be avoided. Note that a full scan of a partial index would not normally be considered a \"full scan\" for the purposes of theAVOID_FULL_SCANandNO_FULL_SCANhints, but if the user has explicitly forced the partial index viaFORCE_INDEX=index_name, it is considered a full scan.#140255#140998",
            "Added theoptimizer_prefer_bounded_cardinalitysession setting, which instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default.#140255#140998",
            "Added theoptimizer_check_input_min_row_countsession setting to control the minimum row count estimate for buffer scans of foreign key and uniqueness checks. It defaults to0.#141375",
            "Since v23.2, table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#139897#140998",
            "Fixed a bug that could cause unexpected errors with SQLVALUESclauses that contain function calls with multiple overloads. This bug existed only in pre-release versions of v25.1.#140646",
            "Added theoptimizer_min_row_countsession setting. This setting sets a lower bound on row count estimates for relational expressions during query planning. A value of0(default) indicates no lower bound. If set to a value greater than0, a row count of zero can still be estimated for expressions with a cardinality of zero, e.g., for a contradictory filter. Setting this to a value greater than0, such as1, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate.#140255#140998",
            "Reduced noise in dynamically provisioned logging sinks by logging flush errors at most once per minute.#139643",
            "Thecockroach node decommissionCLI command now waits until the target node is drained before marking it as fully decommissioned. Previously, it would start the drain but not wait, leaving the target node briefly in a state where it would be unable to communicate with the cluster but would still accept client requests (which would then hang or hit unexpected errors).#139556",
            "Improved the performance of thecockroachd debug zipcommand when retrieving data fromcrdb_internal.transaction_contention_events, reducing the likelihood ofmemory budget exceededorquery execution canceled due to statement timeouterrors.#139754",
            "Previously, in changefeeds using CDC queries and the Parquet format, the output would include duplicate columns when it contained a user-defined primary key. Now, the columns are de-duplicated columns in the output when writing to Parquet.#140153",
            "Fixed a bug where dropping a table with a trigger using the legacy schema changer could leave an orphaned reference in the descriptor. This occurred when two tables were dependent on each other via a trigger, and the table containing the trigger was dropped.#141179",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp must be after replica GC threshold\"error.#140284",
            "The Data Distribution and Zone Configs report on the DB Console Advanced Debug page will no longer crash if there areNULLvalues for theraw_sql_configcolumn in thecrdb_internal.zonestable.#140661",
            "Fixed possible index corruption caused by triggers that could occur when the following conditions were satisfied:A query calls a user-defined function (UDF) or stored procedure, and also performs a mutation on a table.The UDF/stored procedure contains a statement that either fires anAFTERtrigger, or fires a cascade that itself fires a trigger.The trigger modifies the same row as the outer statement.Either the outer or inner mutation is something other than anINSERTwithout anON CONFLICTclause.#138361",
            "A query calls a user-defined function (UDF) or stored procedure, and also performs a mutation on a table.",
            "The UDF/stored procedure contains a statement that either fires anAFTERtrigger, or fires a cascade that itself fires a trigger.",
            "The trigger modifies the same row as the outer statement.",
            "Either the outer or inner mutation is something other than anINSERTwithout anON CONFLICTclause.#138361",
            "Fixed a bug where activating statement diagnostics sometimes appeared unresponsive, with no state or status update. The status now always indicates whether diagnostics are active or a statement bundle is available for download.#139585",
            "Fixed a memory leak that could previously occur when evaluating some memory-intensive queries via the vectorized engine in CockroachDB. The leak had been present since v20.2.#139095",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp must be after replica GC threshold\"error.#140084",
            "Fixed a bug in thekafka_sink_configoption for changefeeds where users were previously unable to set negative GZIP compression levels. Users can now configure theCompressionLevelfield in the range of[-2, 9]where-2enables Huffman encoding and-1sets the default compression.#141037",
            "Fixed a bug that would cause an internal error when the result of aRECORD-returning user-defined function (UDF) was wrapped by another expression (such asCOALESCE) within aVALUESclause.#140646",
            "Fixed a rare bug in which a query could fail with the errorcould not find computed column expression for column in tablewhile dropping a virtual computed column from a table. This bug was introduced in v23.2.4.#139833"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.6",
        "date": "February 19, 2025",
        "changes": [
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error.#141655"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.5",
        "date": "February 6, 2025",
        "changes": [
            "The protected timestamp records of running changefeeds are now updated when the set of targets changes, such as when system tables are added to the protected tables list.#138654",
            "Inv24.3.4, a bug was fixed that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error. This fix isnotpresent in v24.3.5, but has been released inv24.3.6.#140175",
            "Since v23.2 table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#140265",
            "Added support for a new index hint,AVOID_FULL_SCAN, which will prevent the optimizer from planning a full scan for the specified table if any other plan is possible. The hint can be used in the same way as other existing index hints. For example,SELECT * FROM table_name@{AVOID_FULL_SCAN};. This hint is similar toNO_FULL_SCAN, but will not error if a full scan cannot be avoided. Note that normally a full scan of a partial index would not be considered a \"full scan\" for the purposes of theNO_FULL_SCANandAVOID_FULL_SCANhints, but if the user has explicitly forced the partial index viaFORCE_INDEX=index_name, CockroachDB does consider it a full scan.#140270",
            "Added theoptimizer_prefer_bounded_cardinalitysession setting, which instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default.#140270",
            "Added theoptimizer_min_row_countsession setting, which sets a lower bound on row count estimates for relational expressions during query planning. A value of zero, which is the default, indicates no lower bound. Note that if this is set to a value greater than zero, a row count of zero can still be estimated for expressions with a cardinality of zero, e.g., for a contradictory filter. Setting this to a value higher than0, such as1, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate.#140270",
            "Schema object identifiers (e.g., database names, schema names, table names, and function names) are no longer redacted when logging statements in theEXECorSQL_SCHEMAchannels. If redaction of these names is required, then the new cluster settingsql.log.redact_names.enabledcan be set totrue. The default value of the setting isfalse.#138563",
            "Schema object identifiers (e.g., table names, schema names, function names, and type names) are no longer redacted in theSQL_SCHEMAlog channel.#138563",
            "Added the metricsql.schema_changer.object_count, which counts the number of objects in the cluster.#138837",
            "Thechangefeed.max_behind_nanosmetric now supports scoping with metrics labels.#139234",
            "Added the/debug/pprof/fgprofendpoint to capture off-CPU stack traces. Use of this endpoint will have a noticable impact to performance while the endpoint is being triggered.#138843",
            "CLOSE CURSORstatements are now allowed in read-only transactions, similar to PostgreSQL. The bug had been present since at least v23.1.#137793",
            "ALTER BACKUP SCHEDULEno longer fails on schedules whose collection URI contains a space.#138082",
            "Previously,SHOW CREATE TABLEwas showing incorrect data for inverted indexes. It now shows the correct data that can be input to CockroachDB to recreate the same table.#138083",
            "Fixed a timing issue betweenALTER VIEW .. RENAMEandDROP VIEWthat caused repeated failures in theDROP VIEWjob.#137889",
            "Fixed a bug where querying thepg_catalog.pg_constrainttable while the schema changer was dropping a constraint could result in a query error.#137875",
            "On theDatabasespage, users should no longer see console errors when visiting theDatabasespage directly after node/SQL pod startup.#138377",
            "In theDatabases>Tablespage, theCREATEstatement will now show up as expected for tables with custom schema names.#138378",
            "Queries that perform a cast from the string representation of an array containingGEOMETRYorGEOGRAPHYtypes to a SQLARRAYtype will now succeed.#138695",
            "Previously, cluster backups taken in a multi-region cluster that had configured the system database with a region configuration could not be restored into a non-multi-region cluster. This is now fixed.#138787",
            "Fixed a bug that disregarded tuple labels in some cases. This could cause unexpected behavior, such as when converting a tuple to JSON withto_jsonb. See #136167 for more details. The incorrect removal of tuple labels bug was introduced in v22.1.0, and changes in v24.3.0 made unexpected behavior due to the bug more likely.#138840",
            "Previously, CockroachDB could encounter an internal errorcomparison of two different versions of enumin some cases when a user-defined type was modified within a transaction and the following statements read the column of that user-defined type. The bug was introduced in v24.2 and is now fixed.#138052",
            "Secondary tenants will no longer fatal when issuing HTTP requests during tenant startup.#138755",
            "Fixed a bug where columns created withGENERATED ... AS IDENTITYwith theSERIALtype could incorrectly fail internal validations.#139101",
            "When the session variableallow_role_memberships_to_change_during_transactionis set, it is now possible to create and drop users quickly even when there are contending transactions on thesystem.usersandsystem.role_optionssystem tables.#139032",
            "Fixed a bug where the errorbatch timestamp ... must be after replica GC thresholdcould occur during a schema change backfill operation, and cause the schema change job to retry infinitely. Now this error is treated as permanent, and will cause the job to enter thefailedstate.#139250",
            "Fixed a bug that prevented theCREATEstatement for a routine from being shown in a statement bundle. This happened when the routine was created on a schema other thanpublic. The bug had existed since v23.1.#136124"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.4",
        "date": "January 31, 2025",
        "changes": [
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error.#140175"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.3",
        "date": "January 9, 2025",
        "changes": [
            "To improve the granularity of changefeed pipeline metrics, the changefeed metricschangefeed.admit_latencyandchangefeed.commit_latencyhave histogram buckets from5msto60m(previously500msto5m). The following changefeed metrics have histogram buckets from5msto10m(previously500msto5m):changefeed.parallel_io_queue_nanoschangefeed.parallel_io_result_queue_nanoschangefeed.sink_batch_hist_nanoschangefeed.flush_hist_nanoschangefeed.kafka_throttling_hist_nanos#136604",
            "changefeed.parallel_io_queue_nanos",
            "changefeed.parallel_io_result_queue_nanos",
            "changefeed.sink_batch_hist_nanos",
            "changefeed.flush_hist_nanos",
            "changefeed.kafka_throttling_hist_nanos#136604",
            "Added support for multiple seed brokers in the new Kafka sink.#136727",
            "Added a new metricdistsender.rangefeed.catchup_ranges_waiting_client_sidethat counts how many rangefeeds are waiting on the client-side limiter to start performing catchup scans.#136838",
            "Added support for a newAWS_USE_PATH_STYLEparameter in S3 URI parsing.#136934",
            "Added support forSHOW TRIGGERS, which displays the names of all triggers on a table, and whether each trigger is enabled. The user must have any privilege on the table, or be its owner.#135862",
            "Added support forSHOW CREATE TRIGGER, which displays the CREATE statement for a trigger. The user must have any privilege on the table, or be its owner.#135862",
            "The names ofBEFOREtriggers fired by a mutation are now included in theEXPLAINoutput, with the trigger-function invocations also visible in the output of verboseEXPLAIN.#135864",
            "AFTERtriggers are now included in the output ofEXPLAINandEXPLAIN ANALYZE.#135864",
            "Added thelegacy_varchar_typingsession setting, which reverts the changes of#133037that causes the change in typing behavior described in#137837. Specifically, it makes type-checking and overload resolution ignore the newly added \"unpreferred\" overloads. This setting defaults toon.#137919",
            "Removed thesql.auth.resolve_membership_single_scan.enabledcluster setting. This was added out of precaution in case it was necessary to revert back to the old behavior for looking up role memberships, but this escape hatch has never been needed in practice since this was added in v23.1.#136162",
            "Telemetry delivery is now considered successful even in cases of a network timeout. This will prevent throttling in cases outside an operator's control.#136480",
            "When a schema change job is completed, rolls back, or encounters a failure, the time taken since the job began is now logged in a structured log in theSQL_SCHEMAlog channel.#136929",
            "Added a new configurable parameterkv.transaction.max_intents_and_locksthat will prevent transactions from creating too many intents.#137687",
            "Added the metrictxn.count_limit_rejected, which tracks the KV transactions that have been aborted because they exceeded the max number of writes and locking reads allowed.#137687",
            "Added the metrictxn.count_limit_on_response, which tracks the number of KV transactions that have exceeded the count limit on a response.#137687",
            "The link on the Plan Details page to the legacy Table page has been removed.#136504",
            "Previously, CockroachDB would encounter an internal error when evaluatingFETCH ABSOLUTE 0statements, and this is now fixed. The bug has been present since v22.1.#134995",
            "Fixed an issue where corrupted table statistics could cause thecockroachprocess to crash.#136042",
            "A table that is participating in a logical replication stream can no longer be dropped. Previously this was allowed, which would cause all the replicated rows to end up in the dead-letter queue.#136255",
            "ALTER COLUMN SET NOT NULLwas not enforced consistently when the table was created in the same transaction.#136323",
            "Fixed a bug whereCREATE RELATION / TYPEcould leave dangling namespace entries if the schema was concurrently being dropped.#136378",
            "security.certificate.*metrics will now be updated if a node loads new certificates while running.#136226",
            "Theidle_in_session_timeoutsetting now excludes the time spent waiting for schema changer jobs to complete, preventing unintended session termination during schema change operations.#136490",
            "Fixed a bug that causes the optimizer to use stale table statistics after altering anENUMtype used in the table.#136630",
            "Changes the table, index contents of the hot ranges page in DB console.#134988",
            "Table statistics collection in CockroachDB could previously run intono bytes in account to releaseerrors in some edge cases (when the SQL memory budget, configured via--max-sql-memoryflag, was close to being exhausted). The bug has been present since v21.2 and is now fixed.#136166",
            "CockroachDB now better respectsstatement_timeoutlimit on queries involving the top K sort and merge join operations.#136653",
            "Fixed an issue where license enforcement was not consistently disabled for single-node clusters started withcockroach start-single-node. The fix ensures proper behavior on cluster restarts.#137012",
            "Fixed a bug that caused queries against tables with user-defined types to sometimes fail with errors after restoring those tables.#137353",
            "Fixed a bug that causes an incorrect filesystem to be logged as part of the store information.#137115",
            "Fixed a bug affecting uniqueness enforcement in regional by row tables when using read-committed isolation. The bug, introduced in v24.3.0, could cause internal errors or incorrect uniqueness enforcement in tables that had both non-unique and unique indexes when the region column was not part of the uniqueness constraints.#137366",
            "Fixed a bug that has existed since v24.1 that would cause a set-returning UDF withOUTparameters to return a single row.#137376",
            "Fixed an issue where adding an existing column with theIF NOT EXISTSoption could exit too early, skipping necessary handling of the abstract syntax tree (AST). This could lead to failure of theALTERstatement.#137675",
            "An issue where a schema change could incorrectly cause a changefeed to fail with an assertion error likereceived boundary timestamp ... of type ... before reaching existing boundary of type ...has now been fixed.#137706",
            "Internal scans are now exempt from thesql.defaults.disallow_full_table_scans.enabledsetting, allowing index creation even when the cluster setting is active.#137725",
            "Thepg_catalog.pg_typetable no longer containsNULLvalues for the columnstypinput,typoutput,typreceive, andtypsend.NULLvalues were erroneously added for these columns for thetriggertype in v24.3.0. This could cause unexpected errors with some client libraries.#137941",
            "Improved the internal caching logic for role membership information. This reduces the latency impact of commands such asDROP ROLE,CREATE ROLE, andGRANT role TO user, which cause the role membership cache to be invalidated.#136162"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.24",
        "date": "December 12, 2025",
        "changes": [
            "A mechanism that prevents unsafe replication changes from causing loss of quorum now functions correctly. An internal function has been fixed to properly return errors, enhancing the reliability of replication safeguards.#156520"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.23",
        "date": "November 14, 2025",
        "changes": [
            "Added thesql.statements.bytes_read.countmetric that counts the number of bytes scanned by SQL statements.#156598",
            "Added thesql.statements.index_rows_written.countmetric that counts the number of primary and secondary index rows modified by SQL statements.#156598",
            "Added thesql.statements.index_bytes_written.countmetric that counts the number of primary and secondary index bytes modified by SQL statements.#156598",
            "Added thesql.statements.rows_read.countmetric that counts the number of index rows read by SQL statements.#156598",
            "Fixed a bug where the job responsible for compacting stats for the SQL activity state could enter an unschedulable state.#155971",
            "Fixed a bug where changefeeds using CDC queries could sometimes unexpectedly fail after a schema change with a descriptor retrieval error.#156549"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.22",
        "date": "October 30, 2025",
        "changes": [
            "Fixed a bug in thecockroach node draincommand where draining a node using virtual clusters (such as clusters running Physical Cluster Replication (PCR)) could return before the drain was complete, possibly resulting in shutting down the node while it still had active SQL clients and range leases.#156311"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.21",
        "date": "October 17, 2025",
        "changes": [
            "Fixed a bug where anINSERTstatement could fail with a type checking error while adding aBIT(n)column.#153604",
            "Fixed a bug that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when the session settingexpect_and_ignore_not_visible_columns_in_copywas enabled. This bug was introduced withexpect_and_ignore_not_visible_columns_in_copyin v22.1.0.#154284",
            "Fixed a bug where the presence of duplicate temporary tables in a backup caused the restore to fail with an error containing the textrestoring table desc and namespace entries: table already exists.#154399"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.20",
        "date": "September 22, 2025",
        "changes": [
            "Whensql_safe_updatesis enabled, theALTER TABLE ... LOCALITYstatement will be blocked when trying to convert an existing table toREGIONAL BY ROW, unless a region column has been added to the table. This protects against undesired behavior that causedUPDATEorDELETEstatements to fail against the table while the locality change was in progress.#152602",
            "Fixed a bug where invalid default expressions could cause backfilling schema changes to retry forever.#147015",
            "Fixed a bug that could cause excessive memory allocations when compacting timeseries keys.#151813",
            "Fixed a bug where updating column default expressions would incorrectly remove sequence ownerships for the affected column.#152313",
            "Fixed a bug that allowed foreign-key violations to result from some combinations of concurrentREAD COMMITTEDandSERIALIZABLEtransactions. If bothSERIALIZABLEand weaker-isolation transactions will concurrently modify rows involved in foreign-key relationships, theSERIALIZABLEtransactions must have the following session variables set in order to prevent any possible foreign-key violations:SET enable_implicit_fk_locking_for_serializable = on;SET enable_shared_locking_for_serializable = on;SET enable_durable_locking_for_serializable = on;#152376",
            "SET enable_implicit_fk_locking_for_serializable = on;",
            "SET enable_shared_locking_for_serializable = on;",
            "SET enable_durable_locking_for_serializable = on;#152376",
            "Added an automatic repair for dangling or invalid entries in thesystem.commentstable.#152468",
            "Fixed a bug where views could not reference thecrdb_regioncolumn from their underlying tables in expressions.#152742",
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152630",
            "Tunes S3 client retry behavior to be more reliable in the presence of correlated errors.#151875"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.2",
        "date": "December 26, 2024",
        "changes": [
            "Added thelegacy_varchar_typingsession setting. When set toon, type-checking comparisons involvingVARCHARcolumns behave as they did in all previous versions. When set tooff, type-checking of these comparisons is more strict and queries that previously succeeded may now error with the messageunsupported comparison operator. These errors can be fixed by adding explicit type casts. Thelegacy_varchar_typingsession setting is on by default.#137943"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.19",
        "date": "August 22, 2025",
        "changes": [
            "Backporting detailed error logging logic gated behind a cluster setting. The cluster setting enables detailed error logging for messages exceeding Kafka v2 size limit.#150182",
            "Changefeeds emitting to Kafka sinks that were created in CockroachDB v24.2.1+, or v23.2.10+ and v24.1.4+ with thechangefeed.new_kafka_sink.enabledcluster setting enabled now include the message key, size, and MVCC timestamp in \"message too large\" error logs.#150182",
            "Introduced a cluster setting,sql.stats.error_on_concurrent_create_stats.enabled, which modifies how CockroachDB reacts to concurrent auto stats jobs. The default,true, maintains the previous behavior. Settingsql.stats.error_on_concurrent_create_stats.enabledtofalsewill cause the concurrent auto stats job to be skipped with just a log entry and no increased error counters.#149841",
            "Updated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#151489",
            "Fixed an issue where themvcc_timestampfield was incorrectly returning zero values when used with CDC queries. The timestamp is now emitted correctly.#147112",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150336",
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151081",
            "Fixed a memory accounting issue in the client certificate cache that caused multiple allocations to be reported for the same certificate. The cache now accurately tracks memory usage and includes a safeguard to prevent it from negatively affecting SQL operations.#151141",
            "Fixed a bug wheredebug.zipfiles collected from clusters withdisallow_full_table_scansenabled were missing system table data.#151223",
            "Upgrade Go to consume security fixes#150989",
            "Restore will now re-attemptAdminSplitKV requests instead of immediately failing and pausing the job.#149619"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.18",
        "date": "August 8, 2025",
        "changes": [
            "Fixed a memory accounting issue in the client certificate cache that caused multiple allocations to be reported for the same certificate. The cache now accurately tracks memory usage and includes a safeguard to prevent it from negatively affecting SQL operations.#151564"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.17",
        "date": "August 1, 2025",
        "changes": [
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151094"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.16",
        "date": "July 28, 2025",
        "changes": [
            "Added a session variableinitial_retry_backoff_for_read_committedthat controls the initial backoff duration when retrying an individual statement in an explicitREAD COMMITTEDtransaction. A duration of0disables exponential backoff. If a statement in an explicitREAD COMMITTEDtransaction is failing with the40001errorERROR: restart transaction: read committed retry limit exceeded; set by max_retries_for_read_committed=..., then you should setinitial_retry_backoff_for_read_committedto a duration proportional to the typical execution time of the statement (in addition to also increasingmax_retries_for_read_committed).#148228",
            "Added the metricssql.txn.auto_retry.countandsql.statements.auto_retry.count, which count the number of automatic retries of SQL transactions and statements, respectively, within the database. These metrics differ from the relatedtxn.restarts.*metrics, which count retryable errors emitted by the KV layer that must be retried. The newsql.txn.auto_retry.countandsql.statements.auto_retry.countmetrics count auto-retry actions taken by the SQL layer in response to some of those retryable errors.#148228",
            "Introduced a cluster setting,sql.stats.error_on_concurrent_create_stats.enabled, which modifies how CockroachDB reacts to concurrent auto stats jobs. The default,true, maintains the previous behavior. Settingsql.stats.error_on_concurrent_create_stats.enabledtofalsewill cause the concurrent auto stats job to be skipped with just a log entry and no increased error counters.#149850",
            "Fixed a data race in thecloudstoragesink.#147161",
            "Fixed an error incrdb_internal.table_spansthat could occur when a table's schema had been dropped.#148048",
            "Fixed a bug wherelibpqclients using the async API could hang with large result sets (Python: psycopg; Ruby: ActiveRecord, ruby-pg).#148470",
            "TheRESET ALLstatement no longer affects the following session variables:is_superuserrolesession_authorizationtransaction_isolationtransaction_prioritytransaction_statustransaction_read_onlyThis better matches PostgreSQL behavior forRESET ALL. In addition, theDISCARD ALLstatement no longer errors whendefault_transaction_use_follower_readsis enabled.#149431",
            "is_superuser",
            "session_authorization",
            "transaction_isolation",
            "transaction_priority",
            "transaction_status",
            "transaction_read_only",
            "Fixed a bug that would allow a race condition in foreign key cascades underREAD COMMITTEDandREPEATABLE READisolation levels.#150342"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.15",
        "date": "June 25, 2025",
        "changes": [
            "Added the metricssql.txn.auto_retry.countandsql.statements.auto_retry.count, which count the number of automatic retries of SQL transactions and statements, respectively, within the database. These metrics differ from the relatedtxn.restarts.*metrics, which count retryable errors emitted by the KV layer that must be retried. The newsql.txn.auto_retry.countandsql.statements.auto_retry.countmetrics count auto-retry actions taken by the SQL layer in response to some of those retryable errors.#148229",
            "Added a session variableinitial_retry_backoff_for_read_committedthat controls the initial backoff duration when retrying an individual statement in an explicitREAD COMMITTEDtransaction. A duration of0disables exponential backoff. If a statement in an explicitREAD COMMITTEDtransaction is failing with the40001errorERROR: restart transaction: read committed retry limit exceeded; set by max_retries_for_read_committed=..., then you should setinitial_retry_backoff_for_read_committedto a duration proportional to the typical execution time of the statement (in addition to also increasingmax_retries_for_read_committed).#148229",
            "Fixed a bug that could cause anAFTERtrigger to fail withclient already committed or rolled back the transactionif the query also contained foreign-key cascades. The bug had existed sinceAFTERtriggers were introduced in v24.3.#146974",
            "Fixed a bug that could potentially cause a changefeed to complete erroneously when one of its watched tables encounters a schema change.#147031",
            "Fixed a bug that caused the SQL Activity > Statement Fingerprint page to fail to load details for statements run with application names containing a#character.#147221",
            "Fixed a bug that could cause thecockroachprocess tosegfaultwhen collecting runtime execution traces (typically collected via theAdvanced Debugpage in the Console).#147337",
            "Fixed a bug that caused the optimizer to ignore index hints when optimizing some forms of prepared statements. This could result in one of two unexpected behaviors: a query errors with the messageindex cannot be used for this querywhen the index can actually be used; or a query uses an index that does not adhere to the hint. The hints relevant to this bug are regular index hints, e.g.,SELECT * FROM tab@index,FORCE_INVERTED_INDEX, andFORCE_ZIGZAG.#147415",
            "Fixed the database filter in the DB Console's Hot Ranges page, which was broken in v24.3.3, and updated the locality filter to remove duplicate entries.#147444",
            "Fixed a bug that could cause stable expressions to be folded in cached query plans. The bug could cause stable expressions likecurrent_settingto return the wrong result if used in a prepared statement. The bug was introduced in v23.2.22, v24.1.14, v24.3.9, v25.1.2, and the v25.2 alpha.#147458",
            "Fixed a bug where prepared statements on schema changes could fail with runtime errors.#147669",
            "Fixed a bug whereALTER TABLEwas modifying identity attributes on columns not backed by a sequence.#147768",
            "Fixed an issue with logical data replication (LDR) where the presence of a unique index could have caused spurious dead-letter queue (DLQ) entries if the unique index had a smaller index ID than the primary key index.#147354",
            "TTL jobs now respond to cluster topology changes by restarting and rebalancing across available nodes.#147211"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.14",
        "date": "May 28, 2025",
        "changes": [
            "Changed the default value of the cluster settingadmission.l0_file_count_overload_thresholdto4000.#145919",
            "SQL queries run on the source cluster by logical data replication (LDR) and physical cluster replication (PCR) will account to internal metrics likesql.statements.active.internalinstead of the metrics likesql.statements.activethat are used to monitor application workload.#145114",
            "Schema insights that recommend replacing an index were previously a two-statement command consisting of aCREATE INDEXand aDROP INDEXstatement. When these two DDL statements were run as a single batched command, it was possible for one statement to succeed and one to fail. This is because DDL statements do not have the same atomicity guarantees as other SQL statements in CockroachDB. Index-replacement insights are now a singleCREATE INDEXstatement followed by a comment with additional DDL statements to be run manually: anALTER INDEX ... NOT VISIBLEstatement, which makes the old index invisible to the optimizer, followed by aDROP INDEXstatement that should only be run after making the old index invisible and verifying that workload performance is satisfactory.#145988",
            "Fixed a bug where using valueschangefeed.aggregator.flush_jitterandmin_checkpoint_frequencysuch thatchangefeed.aggregator.flush_jitter * min_checkpoint_frequency < 1would cause a panic. Jitter will now be disabled in this case.#144425",
            "Fixed a bug in the DB Console where theDrop unused indextag appeared multiple times for an index on theIndexestab of the table details page.#144652",
            "Fixed the following bugs in theSchedulespage of the DB Console:Fixed a bug where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.Fixed a bug where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144805",
            "Fixed a bug where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.",
            "Fixed a bug where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144805",
            "Fixed a bug in theSQL Activity Statementspage where filtering byStatement Typereturned no results. The filter now works as expected.#144854",
            "Improved the performance ofSHOW CREATE TABLEon multi-region databases with large numbers of objects.#145073",
            "Fixed a bug where runningDROP INDEXon a hash-sharded index did not properly detect dependencies from functions and procedures on the shard column. This caused theDROP INDEXstatement to fail with an internal validation error. Now the statement returns a correct error message, and usingDROP INDEX ... CASCADEworks as expected by dropping the dependent functions and procedures.#145392",
            "Fixed a bug where a node that was drained as part of decommissioning may have interrupted SQL connections that were still active during drain (and for which drain would have been expected to wait).#145447",
            "Fixed a bug that could lead to schema changes hanging after a cluster recovered from availability issues.#145543",
            "Previously, on a table with multiple column families, CockroachDB could encounter aNon-nullable column \":\" with no valueerror in rare cases during table statistics collection. The bug was present since v19.2 and is now fixed.#145574",
            "Fixed a bug that could cause a row-level TTL job to fail with the error \"comparison of two different versions of enum\" if anENUMtype referenced by the table experienced a schema change.#145915",
            "Fixed a bug where the physical cluster replication (PCR) reader catalog job could hit validation errors when schema objects had dependencies between them (for example, when a sequence's default expression was being removed).#145997",
            "Fixed a bug where orphaned leases were not properly cleaned up.#146096",
            "Fixed an internal assertion failure that could occur during operations likeALTER TYPEorALTER DATABASE ... ADD REGIONwhen temporary tables were present.#146198",
            "Fixed a bug that could cause queries that perform work in parallel to ignore the requested quality-of-service level. Affected operations include lookup joins, DistSQL execution, and foreign-key checks.#146222",
            "Fixed a bug that preventedTRUNCATEfrom succeeding if any indexes on the table had back-reference dependencies, such as from a view or function referencing the index.#146324",
            "Fixed a bug where an invalid comment in thesystem.commenttable for a schema object could make it inaccessible.#146416",
            "Fixed a bug in the rangefeed restarts metric that was introduced in v23.2.#133978",
            "Fixed a rare corruption bug that impacts import and materialized views.#144661"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.13",
        "date": "May 15, 2025",
        "changes": [
            "The default value of theadmission.l0_file_count_overload_thresholdcluster setting is now4000. This change improves stability under high write load and during Write-Ahead Log (WAL) failover by addressing token exhaustion.#146597"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.12",
        "date": "April 30, 2025",
        "changes": [
            "CockroachDB v24.3.12 and subsequent v24.3 releases are eligible forlong term support (LTS).",
            "Added theWITH IGNORE_FOREIGN_KEYSoption toSHOW CREATE TABLEwhich omits foreign key constraints from the output schema. This option is also allowed inSHOW CREATE VIEW, but has no effect. It cannot be combined with theWITH REDACToption.#142162",
            "EXPLAIN ANALYZEstatements now display the number of transaction retries and time spent retrying, if non-zero, in the plan output.#142929",
            "A newexecution timestatistic is now reported onEXPLAIN ANALYZEoutput for most operators. Previously, this statistic was only available on the DistSQL diagrams inEXPLAIN ANALYZE (DISTSQL)output.#143897",
            "Added the cluster settingserver.child_metrics.include_aggregate.enabled(default:true) that controls the behavior of Prometheus child metrics reporting (/_status/vars). When set totrue, child metrics include an aggregate time series, maintaining the existing behavior. When set tofalse, it stops reporting the aggregate time series, preventing double counting when querying metrics.#142745",
            "Thesys.cpu.host.combined.percent-normalizedmetric has been updated to include additional counters for more accurate host CPU measurement and to reduce underreporting. It now accounts for time spent processing hardware (irq) and software (softirq) interrupts, as well asnicetime, which represents low-priority user-mode activity.#142905",
            "Theserver.client_cert_expiration_cache.capacitycluster setting has been removed. Thesecurity.certificate.expiration.clientandsecurity.certificate.ttl.clientmetrics now report the lowest value observed for a user in the last 24 hours.#143591",
            "SQL queries run on the source cluster by logical data replication (LDR) and physical cluster replication (PCR) will account to internal metrics likesql.statements.active.internalinstead of the metrics likesql.statements.activethat are used to monitor application workload.#145115",
            "Fixed a bug in client certificate expiration metrics,security.certificate.expiration.clientandsecurity.certificate.ttl.client.#142843",
            "Fast failback could succeed even if the standby cluster protected timestamp had been removed, causing the reverse physical cluster replication (PCR) stream to enter a crashing loop. This patch ensures the failback command fast fails.#143078",
            "Fixed a bug that caused changefeeds to fail on startup when scanning a single key.#143149",
            "MVCC garbage collection is now fully subject to IO admission control. Previously, it was possible for MVCC GC to cause store overload (such as LSM inversion) when a large amount of data would become eligible for garbage collection. Should any issues arise from subjecting MVCC GC to admission control, thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting can be set tofalseto restore the previous behavior.#143276",
            "Fixed a bug where calling a stored procedure could drop the procedure if it hadOUTparameters that were not used by the calling routine. This bug had existed since PL/pgSQLCALLstatements were introduced in v24.1.#143289",
            "Fixed a bug where CockroachDB would encounter an internal error when decoding the gists of plans withCALLstatements. The bug had been present since v23.2.#143314",
            "The reader virtual cluster now starts if the user begins a physical cluster replication (PCR) stream from a cursor viaALTER VIRTUAL CLUSTER virtual_cluster START REPLICATION OF virtual_cluster ON pgurl_physical_cluster WITH READ VIRTUAL CLUSTER.#143369",
            "Fixed a crash due to \"use of enum metadata before hydration\" when using logical data replication (LDR) with user-defined types (UDTs).#143376",
            "Fixed a potential deadlock that could occur during client certificate updates while metrics were being collected. This issue affected the reliability of certificate expiration reporting.#143591",
            "Fixed a bug in v24.1.14, v24.3.7, v24.3.8, and v25.1 that could cause a nil-pointer error when a column's default expression contained a volatile expression (likenextval) as a UDF argument.#143636",
            "Previously, the fieldsmaximum memory usageandmax sql temp disk usagein theEXPLAIN ANALYZEoutput could be under-reported for distributed plans when memory-intensive operations were fully performed on the remote nodes. This is now fixed. The bug existed in v22.1 and later.#143793",
            "TheALTER VIRTUAL CLUSTER SET REPLICATION READ VIRTUAL CLUSTERsyntax is now supported for adding a reader virtual cluster for an existing PCR standby.#143905",
            "Previously, whenever CockroachDB collected a statement bundle when plan-gist-based matching was used,plan.txtwould be incomplete. This is now fixed. The bug had been present since the introduction of plan-gist-based matching in v23.1, and was partially addressed in v24.2.#143935",
            "Fixed a bug where CockroachDB could encounter acannot specify timestamp older than ...error during table statistics collection in some cases (e.g., when the cluster is overloaded). The bug was present since v19.1.#144017",
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144030",
            "Fixed a rare corruption bug that impactsIMPORTand materialized views.#144688"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.11",
        "date": "April 28, 2025",
        "changes": [
            "Fixed a rare corruption bug that impacts import and materialized views.#144661"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.10",
        "date": "April 9, 2025",
        "changes": [
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144060"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.1",
        "date": "December 12, 2024",
        "changes": [
            "When triggers fire one another cyclically, the newrecursion_depth_limitsetting now limits the depth of the recursion. By default, the limit is1000nested trigger executions.#135046",
            "The metrics scrape HTTP endpoint at/ _status/varswill now truncate HELP text at the first sentence, reducing the metadata for metrics with large descriptions. Customers can still access these descriptions via our docs.#135021",
            "The row-level TTL job now periodically updates the progress meter in the jobs introspection interfaces, includingSHOW JOBSand the Jobs page in the DB console.#135171",
            "Telemetry delivery is now considered successful even in cases where we experience a network timeout. This will prevent throttling in cases outside an operator's control.#136481",
            "When activating statement diagnostics in the DB Console, users now have the option to produce a redacted bundle as output. This bundle will omit sensitive data.#134993",
            "Protected timestamp records for changefeeds now include thesystem.userstable. This ensures that user information remains available when running CDC queries against historical data.#134238",
            "Fixed a bug that could causeDELETEtriggers not to fire on cascading delete, and which could causeINSERTtriggers to match incorrectly in the same scenario.#134896",
            "Reduced the duration of partitions in the gossip network when a node crashes in order to eliminate false positives in theranges.unavailablemetric.#134480",
            "When a non-admin user runsDROP ROLE IF EXISTSon a user that does not exist, an error is no longer returned.#134970",
            "Fixed a bug that could cause incorrect query results when the optimizer planned a lookup join on an index containing a column of typeCHAR(N),VARCHAR(N),BIT(N),VARBIT(N), orDECIMAL(M, N), and the query held that column constant to a single value (e.g. with an equality filter).#135037",
            "Fixed an unhandled error that would occur ifDROP SCHEMAwas executed on thepublicschema of thesystemdatabase, or on an internal schema likepg_catalogorinformation_schema.#135181",
            "A bug has been fixed that caused incorrect evaluation of some binary expressions involvingCHAR(N)values and untyped string literals with trailing whitespace characters. For example, the expression'f'::CHAR = 'f 'now correctly evaluates totrue.#134710",
            "PreventALTER DATABASEoperations that modify the zone config from hanging if an invalid zone config already exists.#135216",
            "CREATE SCHEMAnow returns the correct error if a schema name is missing.#135928",
            "percentile_contandpercentile_discaggregate functions now supportfloat4data type inputs. Previously, these functions would return an error when used withfloat4values.#135764",
            "security.certificate.*metrics now update correctly when certificates are reloaded during node runtime. Previously, these metrics would not reflect changes to certificates after node startup.#136227",
            "SQL roles created from LDAP groups that contain periods (.) or hyphens (-) in their Common Names (CN) no longer result in authorization failures.#134942",
            "LDAP authorization now supports partial group mapping, allowing users to authenticate even when some LDAP groups do not have corresponding CockroachDB roles. Previously, authentication would fail if any LDAP group lacked a matching database role.#135587",
            "Regional by row tables with uniqueness constraints where the region is not part of those uniqueness constraints and which also contain non-unique indices will now have those constraints properly enforced when modified atREAD COMMITTEDisolation. This bug was introduced in v24.3.0.#137367",
            "The_status/nodes_uiAPI no longer returns unnecessary metrics in its response. This decreases the payload size of the API and improves the load time of various DB Console pages and components.#135209",
            "PL/pgSQL loops now execute up to 3-4x faster through improved optimization, particularly when they contain subqueries. This enhancement improves performance for routines with many iterations or nested operations.#135648"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-rc.1",
        "date": "November 18, 2024",
        "changes": [
            "All cluster settings that accept strings are now fully redacted when transmitted as part of CockroachDB's diagnostics telemetry. This payload includes a record of modified cluster settings and their values when they are not strings. Customers who previously applied the mitigations in Technical Advisory 133479 can safely set the value of cluster settingserver.redact_sensitive_settings.enabledto false and turn on diagnostic reporting via thediagnostics.reporting.enabledcluster setting without leaking sensitive cluster settings values.#134018",
            "Row-levelAFTERtriggers can now be executed in response to mutations on a table. Row-levelAFTERtriggers fire after checks and cascades have completed for the query.#133320",
            "Cascades can now execute row-levelBEFOREtriggers. By default, attempting to modify or eliminate the cascadingUPDATEorDELETEoperation results in aTriggered Data Change Violationerror. To bypass this error, you can set theunsafe_allow_triggers_modifying_cascadesquery option totrue. This could result in constraint violations.#134444",
            "String constants can now be compared with collated strings.#134086",
            "Thekvadmission.low_pri_read_elastic_control.enabledcluster setting has been removed, because all bulk requests are now subject to elastic admission control admission by default.#134486",
            "The following metrics have been added for Logic Data Replication (LDR):logical_replication.catchup_ranges: the number of source side ranges conducting catchup scans.logical_replication.scanning_ranges: the number source side ranges conducting initial scans.In the DB Console, these metrics may not be accurate if multiple LDR jobs are running. The metrics are accurate when exported from the Prometheus endpoint.#134674",
            "logical_replication.catchup_ranges: the number of source side ranges conducting catchup scans.",
            "logical_replication.scanning_ranges: the number source side ranges conducting initial scans.",
            "In the DB Console, these metrics may not be accurate if multiple LDR jobs are running. The metrics are accurate when exported from the Prometheus endpoint.#134674",
            "The backup and restore syntax update ofcockroach workloadwhich was introduced in#134610#has been reverted.#134645",
            "After finalizing an upgrade to v24.3, an updated version of theDatabasespage will be available.#134244",
            "Users with theCONNECTprivilege can now access theDatabasespage.#134542",
            "Fixed a bug where an LDAP connection would be closed by the server and would not be retried by CockroachDB.#134277",
            "Fixed a bug that prevented LDAP authorization from successfully assigning CockroachDB roles to users when the source group name contained periods or hyphens.#134944",
            "Fixed a bug introduced in v22.2 that could cause significantly increased query latency while executing queries with index or lookup joins when the ordering needs to be maintained#134367",
            "Fixed a bug whereUPSERTstatements on regional by row tables under non-serializable isolations would not display show uniqueness constraints inEXPLAINoutput. Even when not displayed, the constraints were enforced.#134267",
            "Fixed a bug where uniqueness constraints constraints enforced with tombstone writes were not shown in the output ofEXPLAIN (OPT).#134482",
            "Fixed a bug whereDISCARD ALLstatements were erroneously counted under thesql.ddl.countmetric instead of thesql.misc.countmetric.#134510",
            "Fixed a bug that could cause a backup or restore operation on AWS to fail with a KMS error due to a missingdefaultshared config.#134536",
            "Fixed a bug that could prevent a user from running schema change operations on a restored table that was previously apart of a Logic Data Replication (LDR) stream.#134675",
            "The optimizer now generates more efficient query plans involving inverted indexes for queries with a conjunctive filter on the same JSON or ARRAY column. For example:icon/buttons/copySELECT*FROMtWHEREj->'a'='10'ANDj->'b'='20'#134002",
            "Upgraded to Go 1.22.8#134427"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-beta.3",
        "date": "November 5, 2024",
        "changes": [
            "Client authentication errors using LDAP now log more details to help with troubleshooting authentication and authorization issues.#133812",
            "Physical Cluster Replicationreader catalogs now bypass AOST timestamps using thebypass_pcr_reader_catalog_aostsession variable, which can be used to modify cluster settings within the reader.#133876",
            "Added a timer for innerchangefeed sinkclient flushes.#133288",
            "Rows replicated by Logical Data Replication inimmediatemode are now considered in the decision to recompute SQL table statistics.#133591",
            "The new cluster settingkvadmission.flow_controller.token_reset_epochcan be used to refill replicationadmission controlv2 tokens. This is an advanced setting. Use it only after consultation with your account team.#133294",
            "The new cluster settinggoschedstats.always_use_short_sample_period.enabled, when set totrue, helps to prevent unnecessary queueing due to CPU [admission control](/docs/v24.3/admission-control.htmls.#133585",
            "InDatabasepages, theRefreshtooltip now includes details about the progress of cache updates and when the job started.#133351",
            "Fixed a bug wherechangefeed sink) timers were not correctly registered with the metric system.#133288",
            "Fixed a bug that could cause new connections to fail with the following error after upgrading:ERROR: invalid value for parameter \"vectorize\": \"unknown(1)\" SQLSTATE: 22023 HINT: Available values: off,on,experimental_always. To encounter this bug, the cluster must have:Run on version v21.1 at some point in the pastRunSET CLUSTER SETTING sql.defaults.vectorize = 'on';while running v21.1.Notsetsql.defaults.vectorizeafter upgrading past v21.1 4.Subsequently upgraded to v24.2.upgraded all the way to v24.2.To detect this bug, run the following query:icon/buttons/copySELECT*FROMsystem.settingsWHEREname='sql.defaults.vectorizeIf the command returns1instead ofon, run the following statement before upgrading.icon/buttons/copyRESETCLUSTERSETTINGsql.defaults.vectorize;1is now allowed as a value for this setting, and is equivalent toon.#133371",
            "Run on version v21.1 at some point in the past",
            "RunSET CLUSTER SETTING sql.defaults.vectorize = 'on';while running v21.1.",
            "Notsetsql.defaults.vectorizeafter upgrading past v21.1 4.",
            "Subsequently upgraded to v24.2.upgraded all the way to v24.2.",
            "Fixed a bug in v22.2.13+, v23.1.9+, and v23.2 that could cause the internal errorinterface conversion: coldata.Column isin an edge case.#133762",
            "Fixed a bug introduced in v20.1.0 that could cause erroneousNOT NULLconstraint violation errors to be logged duringUPSERTandINSERTstatements with theON CONFLICT ...DO UPDATEclause that update an existing row and a subset of columns that did not include aNOT NULLcolumn of the table.#133820",
            "Fixed a that could cache and reuse a non-reusable query plan, such as a plan for a DDL orSHOWstatement, whenplan_cache_modewas set toautoorforce_generic_plan, which are not the default options.#133073",
            "Fixed an unhandled error that could occur while running the commandREVOKE ... ON SEQUENCE FROM ... {user}on an object that is not a sequence.#133710",
            "Fixed a panic that could occur while running aCREATE TABLE ASstatement that included asequencewith an invalid function overload.#133870"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-beta.2",
        "date": "October 28, 2024",
        "changes": [
            "If a table is the destination of a logical data replication stream, then only schema change statements that are deemed safe are allowed on the table. Safe statements are those that do not result in a rebuild of the primaryindexand do not create an index on a virtualcomputed column.#133266",
            "The two new metricssql.crud_query.countandsql.crud_query.started.countmeasure the number ofINSERT/UPDATE/DELETE/SELECTqueries executed and started respectively.#133198",
            "When creating a logical data replication stream, anyuser-defined typesin the source and destination are now checked for equivalency. This allows for creating a stream that handles user-defined types without needing to use theWITH SKIP SCHEMA CHECKoption as long as the stream usesmode = immediate.#133274",
            "Logical data replication streams that reference tables withuser-defined typescan now be created with themode = immediateoption.#133295",
            "TheSQL Statementsgraph on theOverviewandSQLdashboard pages in DB Console has been renamedSQL Queries Per Secondand now showsTotal Queriesas a general Queries Per Second (QPS) metric.#133198",
            "Due to the inaccuracy of theRange Countcolumn on theDatabasespageand the cost incurred to fetch the correct range count for every database in a cluster, this data will no longer be visible. This data is still available via aSHOW RANGESquery.#133267",
            "Users with theadminrolecan now runALTER DEFAULT PRIVILEGES FOR target_role ...on anytarget_role. Previously, this could result in a privilege error, which is incorrect asadmins are allowed to perform any operation.#133072",
            "REASSIGN OWNED BY current_owner_role ...will now transfer ownership of thepublicschema. Previously, it would always skip over thepublicschema even if it was owned by thecurrent_owner_role.#133072"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-beta.1",
        "date": "October 24, 2024",
        "changes": [
            "The cluster settingdiagnostics.reporting.enabledis now ignored if the cluster has aEnterprise Trial or Enterprise Free license, or if the reporting job is unable to load any license at all.#132257",
            "This change ensures authorization with LDAP only works when theldapgrouplistfilteroption is present in theHBA configuration, otherwise authentication will proceed with the provided LDAP auth method options in the HBA configuration. This change is to ensure external authorization with LDAP is opt-in rather than enabled by default.#132235",
            "Added achangefeed sinkerror metricchangefeed.sink_errors, and expanded reporting of the internal retries metricchangefeed.internal_retry_message_countto all sinks that perform internal retries.#132092",
            "ImplementedDROP TRIGGERstatements. TheCASCADEoption for dropping atriggeris not supported.#128540",
            "Added support forCREATE TRIGGER. TheOR REPLACEsyntax is not supported. Also,triggerscannot be executed, so creation is a no-op.#128540",
            "REGIONAL BY ROWandPARTITION ALL BYtables can now be inserted into undernon-SERIALIZABLEisolation levelsas long as there is noON CONFLICTclause in the statement. Also,REGIONAL BY ROWandPARTITION ALL BYtables can now be updated under non-SERIALIZABLEisolation levels.#129837",
            "Attempting to addforeign keysreferencing a table withrow-level TTLenabled will generate a notice informing the user about potential impact on the row-level TTL deletion job. Similarly, a notice is generated while attempting to enable row-level TTL on a table that has inbound foreign key references.#127935",
            "It is now possible to assign to an element of a composite typed variable inPL/pgSQL. For example, given a variablefoowith two integer elementsxandy, the following assignment statement is allowed:foo.x := 100;.#132628",
            "Backupandrestorenow work for tables with triggers. When theskip_missing_udfsoptionis applied, triggers with missing trigger functions are removed from the table.#128555",
            "UPSERT and INSERT ... ON CONFLICTstatements are now supported onREGIONAL BY ROWtables underREAD COMMITTEDisolation.#132768",
            "Added support for row-levelBEFOREtriggers. A row-level trigger executes the trigger function for each row that is being mutated.BEFOREtriggers fire before the mutation operation.#132511",
            "Added support forPL/pgSQLintegerFORloops, which iterate over a range of integer values.#130211",
            "Admission Controlnow has an integration for pacing snapshot ingest traffic based on disk bandwidth.kvadmission.store.snapshot_ingest_bandwidth_control.enabledis used to turn on this integration. It requires provisioned bandwidth to be set for the store (or cluster through thecluster setting) for it to take effect.#131243",
            "Added validation to check whetheraudit loggingandbuffering configurationsare both present in thefile log sink. Audit logging and buffering configuration should not both exist in the file log sink.#132742",
            "Updated thefile log sinkvalidation message. This would give clear indication to the user about the expected valid configuration.#132899",
            "The value of the automaticstatisticscollection cluster settingsql.stats.automatic_collection.enabledis now in the top right corner of theDatabasesoverview page.#132269",
            "In the newDatabasesandTablespages, when cached data is being refreshed, the refresh button will be disabled and its tooltip text will display,Data is currently refreshing.#132462",
            "Addressed a rare bug that could preventbackupstaken during aDROP COLUMNoperation with asequenceowner fromrestoringwith the error:rewriting descriptor ids: missing rewrite for <id> in SequenceOwner....#132202",
            "Fixed a bug existing since before v23.1 that could lead to incorrect results in rare cases. The bug requires ajoinbetween two tables with an equality between columns with equivalent, but not identicaltypes(e.g.,OIDandREGCLASS). In addition, the join must lookup into anindexthat includes acomputed columnthat references one of the equivalent columns.#126345",
            "Fixed a bug existing since before v23.1 that could lead to incorrect results in rare cases. The bug requires a lookupjoininto a table with a computedindexcolumn, where thecomputed columnexpression is composite sensitive. A composite sensitive expression can compare differently if supplied non-identical but equivalent input values (e.g.,2.0::DECIMALversus2.00::DECIMAL).#126345",
            "Fixed a bug that caused quotes around the name of a routine to be dropped when it was called within anotherroutine. This could prevent the correct routine from being resolved if the nested routine name was case-sensitive. The bug has existed since v24.1 when nested routines were introduced.#131643",
            "Fixed a bug where theSQL shellwould print out the previous error message when executing thequitcommand.#130736",
            "Fixed a bug where aspan statisticsrequest on a mixed-version cluster resulted in a null pointer exception.#132349",
            "Fixed an issue wherechangefeedswould fail to updateprotected timestamp recordsin the face ofretryable errors.#132712",
            "Thefranz-golibrary has been updated to fix a potential deadlock onchangefeedrestarts.#132761",
            "Fixed a bug that in rare cases could cause incorrect evaluation ofscalar expressionsinvolvingNULLvalues.#132261",
            "Fixed a bug in the queryoptimizerthat in rare cases could cause CockroachDB nodes to crash. The bug could occur when a query contains a filter in the formcol IN (elem0, elem1, ..., elemN)only whenNis very large, (e.g., 1.6+ million), and whencolexists in ahash-sharded index, or exists a table with an indexed,computed columndependent oncol.#132701",
            "Theproretsetcolumn of thepg_catalog.pg_proctable is now properly set totruefor set-returning built-in functions.#132853",
            "Fixed an error that could be caused by using anAS OF SYSTEM TIMEexpression that references a user-defined (or unknown) type name. These kinds of expressions are invalid, but previously the error was not handled properly. Now, a correct error message is returned.#132348",
            "Upgraded to Go v1.23.2.#132111"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-alpha.2",
        "date": "October 14, 2024",
        "changes": [
            "The parameters for anHBA config entryfor LDAP are now validated when the entry is created or amended, in addition to the validation that happens during an authentication attempt.#132086",
            "Added automatic cleanup and validation fordefault privilegesthat reference dropped roles after a major-version upgrade to v24.3.#131782",
            "Changed the licensecockroachis distributed under to the new CockroachDB Software License (CSL).#131799#131794#131793",
            "You can nowauthenticate to the DB console APIby supplying a Java Web Token (JWT) as a Bearer token in the Authorization header.#130779",
            "To view comments on a type, you can use the newSHOW TYPES WITH COMMENTcommand. Comments can be added usingCOMMENT ON.#131183",
            "You can create or alter auser-defined function (UDF)orstored procedure (SP)with[EXTERNAL] SECURITY DEFINERinstead of the default[EXTERNAL] SECURITY INVOKER. WithSECURITY DEFINER, the privileges of the owner are checked when the UDF or SP is executed, rather than the privileges of the executor. TheEXTERNALkeyword is optional and exists for SQL language conformity.#129720",
            "The following newmetricsshow details aboutreplicationflow control send queue when thecluster settingkvadmission.flow_control.enabledis set totrueand the cluster settingkvadmission.flow_control.modeis set toapply_to_all.kvflowcontrol.tokens.send.regular.deducted.prevent_send_queuekvflowcontrol.tokens.send.elastic.deducted.prevent_send_queuekvflowcontrol.tokens.send.elastic.deducted.force_flush_send_queuekvflowcontrol.range_controller.countkvflowcontrol.send_queue.byteskvflowcontrol.send_queue.countkvflowcontrol.send_queue.prevent.countkvflowcontrol.send_queue.scheduled.deducted_byteskvflowcontrol.send_queue.scheduled.force_flush#131857",
            "kvflowcontrol.tokens.send.regular.deducted.prevent_send_queue",
            "kvflowcontrol.tokens.send.elastic.deducted.prevent_send_queue",
            "kvflowcontrol.tokens.send.elastic.deducted.force_flush_send_queue",
            "kvflowcontrol.range_controller.count",
            "kvflowcontrol.send_queue.bytes",
            "kvflowcontrol.send_queue.count",
            "kvflowcontrol.send_queue.prevent.count",
            "kvflowcontrol.send_queue.scheduled.deducted_bytes",
            "kvflowcontrol.send_queue.scheduled.force_flush",
            "The followingmetricshave been renamed:Previous nameNew name-kvflowcontrol.tokens.eval.regular.disconnectedkvflowcontrol.tokens.eval.regular.returned.disconnectkvflowcontrol.tokens.eval.elastic.disconnectedkvflowcontrol.tokens.eval.elastic.returned.disconnectkvflowcontrol.tokens.send.regular.disconnectedkvflowcontrol.tokens.send.regular.returned.disconnectkvflowcontrol.tokens.send.elastic.disconnectedkvflowcontrol.tokens.send.elastic.returned.disconnect#131857",
            "The_status/ranges/endpoint on DB ConsoleAdvanced debug pagesis now enabled for non-system virtual clusters, where it returns the ranges only for the tenant you are logged into. For the system virtual cluster, the_status/ranges/endpoint continues to return ranges for the specified node across all virtual clusters.#131100",
            "Improved performance in theDatabases,Tables View, andTable Detailssections of theDatabases page#131769",
            "Fixed a bug where JSON values returned bycockroachcommands using the--format=sqlflag were not correctly escaped if they contained double quotes within a string.#131881",
            "Fixed an error that could happen if anaggregate functionwas used as the value in aSETcommand.#131891",
            "Fixed a rare bug introduced in v22.2 in which an update of aprimary keycolumn could fail to update the primary index if it is also the only column in a separate column family.#131869",
            "Fixed a rare bug where dropping a column ofFLOAT4,FLOAT8,DECIMAL,JSON,ARRAY, or collateSTRINGtype stored in a singlecolumn familycould prevent subsequent reading of the table if the column family was not the first column family.#131967",
            "Fixed anunimplementedinternal error that could occur when ordering by aVECTORcolumn.#131703",
            "Efficiency has been improved when writing string-like values over the PostgreSQL wire protocol.#131964",
            "Error handling during periodic table history polling has been improved when theschema_lockedtable parameteris not used.#131951"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0-alpha.1",
        "date": "October 9, 2024",
        "changes": [
            "URLs in theCREATE CHANGEFEEDandCREATE SCHEDULE FOR CHANGEFEEDSQL statements are now sanitized of any secrets before being written to unredactedlogs.#126970",
            "The LDAPcluster settingsserver.ldap_authentication.client.tls_certificateandserver.ldap_authentication.client.tls_keydid not have callbacks installed to reload the settings value for LDAP authManager. This change fixes this by adding the necessary callbacks.#131151",
            "Cluster settingsforhost-based authenticationconfiguration (server.host_based_authentication.configuration) and identity map configuration (server.identity_map.configuration) need to be redacted as they can be configured to contain LDAP bind usernames, passwords, and mapping of external identities to SQL users that are sensitive. These cluster settings can be configured for redaction via theserver.redact_sensitive_settings.enabledcluster setting.#131150",
            "Added support for configuring authorization using LDAP. During login, the list of groups that a user belongs to are fetched from the LDAP server. These groups are mapped toSQL rolesby extracting the common name (CN) from the group. After authenticating the user, the login flow grants these roles to the user, and revokes any other roles that are not returned by the LDAP server. The groups given by the LDAP server are treated as the sole source of truth for role memberships, so any roles that were manually granted to the user will not remain in place.#131043",
            "Previously, thehost-based authentication(HBA) configuration cluster settingserver.host_based_authentication.configurationwas unable to handle double quotes in authentication method option values. For example, for the following entry:host all all all ldap ldapserver=ldap.example.com ldapport=636 ldapbasedn=\"ou=users,dc=example,dc=com\" ldapbinddn=\"cn=readonly,dc=example,dc=com\" ldapbindpasswd=readonly_password ldapsearchattribute=uid ldapsearchfilter=\"(memberof=cn=cockroachdb_users,ou=groups,dc=example,dc=com)\"The HBA parser would fail after incorrectly determiningldapbinddn=\"cn=readonly,dc=example,dc=com\"as 2 separate options (ldapbinddn=and cn=readonly,dc=example,dc=com). Now, the 2 tokens are set as key and value respectively for the same HBA configuration option.#131480",
            "CockroachDB will now avoidloggingunnecessary stack traces while executingscheduled jobs.#129846",
            "Upgrading to 24.3 is blocked if nolicenseis installed, or if a trial/free license is installed with telemetry disabled.#130576",
            "Attempting to install a second Enterprise trial license on the same cluster will now fail.#131422",
            "Changed the licensecockroachis distributed under to the new CockroachDB Software License (CSL).#131690#131686#131688#131687#131717#131689#131693#131691#131777#131778#131661",
            "Added aCompressionLevelfield to the changefeedkafka_sink_configoption.Changefeedswill use this compression level when emitting events to aKafka sink. The possible values depend on a compression codec. TheCompressionLevelfield optimizes for faster or stronger level ofcompression.#125456",
            "The updated version of theCockroachDB changefeed Kafka sink implementationnow supports specifying compression levels.#127827",
            "Introduced the cluster settingserver.jwt_authentication.client.timeoutto capture the HTTP client timeout for external calls made duringJWT authentication.#127145",
            "The JWT authenticationcluster settingshave been madepublic.#128170",
            "Updated certain error messages to refer to thestabledocs tree rather than an explicit version.#128842",
            "Disambiguatedmetricsand logs for the two buffers used by the KV feed. The affected metrics now have a suffix indicating which buffer they correspond to:changefeed.buffer_entries.*,changefeed.buffer_entries_mem.*,changefeed.buffer_pushback_nanos.*. The previous versions are still supported for backward compatibility, though using the new format is recommended.#128813",
            "Added support for authorization to a CockroachDB cluster via LDAP, retrieving AD groups membership information for LDAP user. The newHBA configurationcluster setting optionldapgrouplistfilterperforms filtered search query on LDAP for matching groups. An example HBA configuration entry to support LDAP authZ configuration:icon/buttons/copy#TYPEDATABASEUSERADDRESSMETHODOPTIONS#AllowalluserstoconnecttousingLDAPauthenticationwithsearchandbindhostallallallldapldapserver=ldap.example.comldapport=636\"ldapbasedn=ou=users,dc=example,dc=com\"\"ldapbinddn=cn=readonly,dc=example,dc=com\"ldapbindpasswd=readonly_passwordldapsearchattribute=uid\"ldapsearchfilter=(memberof=cn=cockroachdb_users,ou=groups,dc=example,dc=com)\"\"ldapgrouplistfilter=(objectClass=groupOfNames)\"#Fallbacktopasswordauthenticationfortherootuserhostallroot0.0.0.0/0passwordFor example, to use for an Azure AD server:icon/buttons/copySETclustersettingserver.host_based_authentication.configuration='host all all all ldap ldapserver=azure.dev ldapport=636 \"ldapbasedn=OU=AADDC Users,DC=azure,DC=dev\" \"ldapbinddn=CN=Some User,OU=AADDC Users,DC=azure,DC=dev\" ldapbindpasswd=my_pwd ldapsearchattribute=sAMAccountName \"ldapsearchfilter=(memberOf=CN=azure-dev-domain-sync-users,OU=AADDC Users,DC=crlcloud,DC=dev)\" \"ldapgrouplistfilter=(objectCategory=CN=Group,CN=Schema,CN=Configuration,DC=crlcloud,DC=dev)\" host all root 0.0.0.0/0 password';Post configuration, the CockroachDB cluster should be able to authorize users via LDAP server if:Users LDAP authentication attempt is successful, and it has the user's DN for the LDAP server.ldapgrouplistfilteris properly configured, and it successfully syncs groups of the user.#128498",
            "Users LDAP authentication attempt is successful, and it has the user's DN for the LDAP server.",
            "ldapgrouplistfilteris properly configured, and it successfully syncs groups of the user.#128498",
            "Added changefeed support for themvcc_timestampoption when the changefeed is emitting inavroformat. If both options are specified, the Avro schema includes anmvcc_timestampmetadata field and emits the row'sMVCC timestampwith the row data.#129840",
            "Updated the cluster settingchangefeed.sink_io_workerswith all thesinksthat support the setting.#129946",
            "Added a LDAP authentication method to complement password-based login for theDB Consoleif HBA configuration has an entry for LDAP for the user attempting login, along with other matching criteria (like the requests originating IP address) for authentication to the DB Console.#130418",
            "Added timers around key parts of thechangefeedpipeline to help debug feeds experiencing issues. Thechangefeed.stage.<stage>.latencymetrics now emit latency histograms for each stage. The metric respects thechangefeedscopelabelfor debugging specific feeds.#128794",
            "Forenterprise changefeeds,eventschangefeed_failedandcreate_changefeednow include aJobIdfield.#131396",
            "The newmetricseconds_until_license_expiryallows you to monitor the status of a cluster's Enterprise license.#129052.",
            "Added thechangefeed.total_rangesmetric, whichmonitorsthe number ofrangesthat are watched bychangefeed aggregators. It shares the same polling interval aschangefeed.lagging_ranges, which is controlled by the existinglagging_ranges_polling_intervaloption.#130897",
            "Added a session setting,optimizer_use_merged_partial_statisticswhich defaults tofalse. When set totrue, it enables usage of existing partialstatisticsmerged with full statistics whenoptimizinga query.#126948",
            "Theenable_create_stats_using_extremessession setting is nowtrueby default. Partial statistics at extremes can be collected using theCREATE STATISTICS <stat_name> ON <column_name> FROM <table_name> USING EXTREMESsyntax.#127850",
            "AddedSHOW SCHEMAS WITH COMMENTandSHOW SCHEMAS FROM database_name WITH COMMENTfunctionality similar toSHOW TABLESandSHOW DATABASES.#127816",
            "Thedeadlock_timeoutsession variableis now supported. The configuration can be used to specify the time to wait on a lock before pushing the lock holder for deadlock detection. It can be set at session granularity.#128506",
            "Partial statistics at extremes can now be collected on all valid columns of a table using theCREATE STATISTICS <stat_name>FROM <table_name> USING EXTREMESsyntax, without anON <col_name>clause. Valid columns are all single column prefixes of a forwardindexexcluding partial, sharded, and implicitly partitioned indexes.#127836",
            "Partialstatisticscan now be automatically collected at the extremes of indexes when a certain fraction and minimum number of rows are stale (by default 5% and 100 respectively). These can be configured with newtable storage parametersandcluster settings, and the feature is disabled by default. The new cluster settings and table parameters are:sql.stats.automatic_partial_collection.enabled/sql_stats_automatic_partial_collection_enabled, defaults tofalse.sql.stats.automatic_partial_collection.min_stale_rows/sql_stats_automatic_partial_collection_min_stale_rows, defaults to100.sql.stats.automatic_partial_collection.fraction_stale_rows/sql_stats_automatic_partial_collection_fraction_stale_rows, Defaults to0.05.#93067",
            "sql.stats.automatic_partial_collection.enabled/sql_stats_automatic_partial_collection_enabled, defaults tofalse.",
            "sql.stats.automatic_partial_collection.min_stale_rows/sql_stats_automatic_partial_collection_min_stale_rows, defaults to100.",
            "sql.stats.automatic_partial_collection.fraction_stale_rows/sql_stats_automatic_partial_collection_fraction_stale_rows, Defaults to0.05.#93067",
            "The session variableenforce_home_region_follower_reads_enabledis now deprecated, and will be removed in a future release. The related session variableenforce_home_regionisnotdeprecated.#129024",
            "Added a newcluster settingto control whether most common values are collected as part ofhistogram collectionfor use by theoptimizer. The setting is calledsql.stats.histogram_buckets.include_most_common_values.enabled. When enabled, the histogram collection logic will ensure that the most common sampled values are represented as histogram bucket upper bounds. Since histograms in CockroachDB track the number of elements equal to the upper bound in addition to the number of elements less, this allows the optimizer to identify the most common values in the histogram and better estimate the rows processed by a query plan. To set the number of most common values to include in a histogram, a second settingsql.stats.histogram_buckets.max_fraction_most_common_valueswas added. Currently, the default is0.1, or10%of the number of buckets. With a 200 bucket histogram, by default, at most 20 buckets may be adjusted to include a most common value as the upper bound.#129378",
            "Added a new column tocrdb_internal.table_spansto indicate whether a table isdropped. Rows for dropped tables will be removed once they aregarbage collected.#128788",
            "Added thecluster settingsql.txn.repeatable_read_isolation.enabled, which defaults tofalse. When set totrue, the following statements will configure transactions to run underREPEATABLE READisolation, rather than being automatically interpreted asSERIALIZABLE:BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READSET TRANSACTION ISOLATION LEVEL REPEATABLE READSET default_transaction_isolation = 'repeatable read'SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL REPEATABLE READThis setting was added sinceREPEATABLE READtransactionsis apreviewfeature, so usage of it is opt-in for v24.3. In a future CockroachDB major version, this setting will change to default totrue.#130089",
            "BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "SET TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "SET default_transaction_isolation = 'repeatable read'",
            "SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "Previously,SHOW CHANGEFEED JOBSshowed the changefeed jobs for the last 14 days by default. Now, it uses the same age filter forSHOW JOBS, which shows jobs from the last 12 hours by default.#127584",
            "Set the default for session variablelarge_full_scan_rowsto0. This means that by default,disallow_full_table_scanswill disallowallfull table scans, even full scans on very small tables. Iflarge_full_scan_rowsis set > 0,disallow_full_table_scanswill allow full scans estimated to read fewer thanlarge_full_scan_rows.#131040",
            "It is now possible to createPL/pgSQLtrigger functions, which can be executed by a trigger in response to table mutation events. Note that this patch does not add support for triggers, only trigger functions.#126734",
            "Cluster settingsenterprise.licenseanddiagnostics.reporting.enablednow have additional validation.#131097",
            "TheSHOW SESSIONScommand was changed to include anauthentication_methodcolumn in the result. This column will show the method used to authenticate the session, for example,password,cert,LDAP, etc.#131625",
            "EventsDiskSlownessDetectedandDiskSlownessClearedare now logged when disk slowness is detected and cleared on a store.#127025",
            "Severalcluster settingsallow you to configure rate-limiting traffic to cloud storage over various protocols. These settings begin withcloudstorage.#127207",
            "The newcluster settingkv.range.range_size_hard_capallows you to limit how large arangecan grow beforebackpressureis applied. This can help to mitigate against a situation where a range cannot be split, such as when a range is comprised of a single key due to an issue with the schema or workload pattern or a bug in client application code. The default is 8 GiB, which is 16 times the default max range size. If you have changed the max range size, you may need to adjust this cluster setting or reduce the range size.#129450",
            "The followingkvflowcontrolmetricshave been renamed. After a cluster is finalized on v24.3, old and new metrics will be populated. The previous metrics underkvasdmission.flow_controllerwill be removed.Old metric namesNew metric nameskvadmission.flow_controller.regular_tokens_availablekvflowcontrol.tokens.eval.regular.availablekvadmission.flow_controller.elastic_tokens_availablekvflowcontrol.tokens.eval.elastic.availablekvadmission.flow_controller.regular_tokens_deductedkvflowcontrol.tokens.eval.regular.deductedkvadmission.flow_controller.elastic_tokens_deductedkvflowcontrol.tokens.eval.elastic.deductedkvadmission.flow_controller.regular_tokens_returnedkvflowcontrol.tokens.eval.regular.returnedkvadmission.flow_controller.elastic_tokens_returnedkvflowcontrol.tokens.eval.elastic.returnedkvadmission.flow_controller.regular_tokens_unaccountedkvflowcontrol.tokens.eval.regular.unaccountedkvadmission.flow_controller.elastic_tokens_unaccountedkvflowcontrol.tokens.eval.elastic.unaccountedkvadmission.flow_controller.regular_stream_countkvflowcontrol.streams.eval.regular.total_countkvadmission.flow_controller.elastic_stream_countkvflowcontrol.streams.eval.elastic.total_countkvadmission.flow_controller.regular_requests_waitingkvflowcontrol.eval_wait.regular.requests.waitingkvadmission.flow_controller.elastic_requests_waitingkvflowcontrol.eval_wait.elastic.requests.waitingkvadmission.flow_controller.regular_requests_admittedkvflowcontrol.eval_wait.regular.requests.admittedkvadmission.flow_controller.elastic_requests_admittedkvflowcontrol.eval_wait.elastic.requests.admittedkvadmission.flow_controller.regular_requests_erroredkvflowcontrol.eval_wait.regular.requests.erroredkvadmission.flow_controller.elastic_requests_erroredkvflowcontrol.eval_wait.elastic.requests.erroredkvadmission.flow_controller.regular_requests_bypassedkvflowcontrol.eval_wait.regular.requests.bypassedkvadmission.flow_controller.elastic_requests_bypassedkvflowcontrol.eval_wait.elastic.requests.bypassedkvadmission.flow_controller.regular_wait_durationkvflowcontrol.eval_wait.regular.durationkvadmission.flow_controller.elastic_wait_durationkvflowcontrol.eval_wait.elastic.duration#130167",
            "The newranges.decommissioningmetricshows the number of ranges with a replica on adecommissioningnode.#130117",
            "Newcluster settingshave been added which control the refresh behavior for the cached data in theDatabasespage of theDB Console:obs.tablemetadatacache.data_valid_duration: the duration for which the data insystem.table_metadatais considered valid before a cache reset will occur. Default: 20 minutes.obs.tablemetadatacache.automatic_updates.enabled: whether to automatically update the cache according the validity interval. Default:false.#130198",
            "obs.tablemetadatacache.data_valid_duration: the duration for which the data insystem.table_metadatais considered valid before a cache reset will occur. Default: 20 minutes.",
            "obs.tablemetadatacache.automatic_updates.enabled: whether to automatically update the cache according the validity interval. Default:false.",
            "New gaugemetricssecurity.certificate.expiration.{cert-type}andsecurity.certificate.ttl.{cert-type}show the expiration and TTL for a certificate.#130110",
            "To set thelogging formatforstderr, you can now set theformatfield to any valid format, rather than onlycrdb-v2-tty.#131529",
            "The following newmetricsshow connection latency for each SQL authentication method:Authentication methodMetricCertificateauth_cert_conn_latencyJava Web Token (JWT)auth_jwt_conn_latencyKerberos GSSauth_gss_conn_latencyLDAPauth_ldap_conn_latencyPasswordauth_password_conn_latencySCRAM SHA-256auth_scram_conn_latency#131578",
            "Verbose logging of slowPebblereads can no longer be enabled via the shorthand flag--vmodule=pebble_logger_and_tracer=2, wherepebble_logger_and_tracercontains the CockroachDB implementation of the logger needed by Pebble. Instead, you must list the Pebble files that contain the log statements. For example--vmodule=reader=2,table=2.#127066",
            "The lowestadmission controlpriority for the storage layer has been renamed fromttl-low-pritobulk-low-pri.#129564",
            "New clusters will now have azone configurationdefined for thetimeseriesrange, which specifiesgc.ttlsecondsand inherits all other attributes from the zone config of thedefaultrange. This zone config will also be added to a cluster that isupgradedto v24.3 if it does not already have a zone config defined.#128032",
            "cockroach debug tsdumpnow includes all the available resolutions in the time range supplied by the user.#127186",
            "Added the flag--tenant-name-scopeto thecert create-clientcommand. This allows users to generate tenant-scopedclient certificatesusing tenant names in addition to tenant IDs.#129216",
            "If arangeis larger than twice the max range size, it will now display in theProblem Rangespagein the DB Console.#129001",
            "Updated some metric charts on theOverviewandReplicationdashboards to omit verbose details in the legends for easier browsing.#129149",
            "Updated the icon for notification alerts to use the new CockroachDB logo.#130333",
            "Thetxn.restarts.writetoooldmultimetric was rolled into thetxn.restarts.writetoooldmetric in the v24.1.0-alpha.1 release.txn.restarts.writetoooldmultihas now been removed altogether.#131642",
            "The grants table in theDB Detailspage will now show the database level grants. For example, when clicking a database in the databases list. Previously, it showed grants per table in the database.#131250",
            "Added new database pages that are available from the side navigationDatabaseslink.#131594",
            "TheDB Consolewill reflect any throttling behavior from the cluster due to an expired license or missing telemetry data. Enterprise licenses are not affected.#131326",
            "Users can hover over the node/region cell in multi-region deployments to view a list of nodes the database or table is on.#130704",
            "TheDatabasespagesin the DB console have been updated to read cached metadata about database and table storage statistics. The cache update time is now displayed in the top right-hand corner of the database and tables list pages. Users may trigger a cache refresh with therefreshicon next to the last updated time. The cache will also update automatically when users visit aDatabasespage and the cache is older than or equal to 20 minutes.#131463",
            "Fixed a bug where CockroachDB could incorrectly evaluate anIS NOT NULLfilterif it was applied to non-NULLtuples that hadNULLelements (like(1, NULL)or(NULL, NULL)). The bug was present since v20.2.#126901",
            "Fixed a bug related to displaying the names of composite types in theSHOW CREATE TABLEScommand. The names are now shown as two-part names, which disambiguates the output and makes it more portable to other databases.#127158",
            "TheCONCAT()built-in functionnow accepts arguments of any data type.#127098",
            "Fixed a bug that prevented mergedstatisticsfrom being created after injecting statistics or recreatingstatement bundles. This would occur when the injected statistics or statement bundle contained related full and partial statistics.#127252",
            "Fixed a bug where CockroachDB could encounter spurious(error encountered after some results were delivered)ERROR: context cancelederrors in rare cases when evaluating some queries. The bug was present since v22.2. The conditions that triggered the bug were queries that:Had to be executed locally.Had aLIMIT.Have at least twoUNIONclauses.Have some lookup or indexjoinsin theUNIONbranches.#127076",
            "Had to be executed locally.",
            "Had aLIMIT.",
            "Have at least twoUNIONclauses.",
            "Have some lookup or indexjoinsin theUNIONbranches.#127076",
            "Updated the restorejobdescription fromRESTORE ... FROMtoRESTORE FROM {backup} IN {collectionURI}to reflect the newRESTOREsyntax.#127970",
            "Fixed a bug that could cause aCASEstatement with multiplesubqueriesto produces the side effects of one of the subqueries even if that subquery shouldn't have been evaluated.#120327",
            "Changed theschema changers merge process so that it can detectcontention errorsand automatically retry with a smaller batch size. This makes the merge process more likely to succeed without needing to manually tune settings.#128201",
            "SHOW CREATE ALL TYPESnow shows corresponding type comments in its output.#128084",
            "Enforce thestatement_timeoutsession settingwhen waiting forjobsafter aschema changein animplicit transaction.#128474",
            "Fixed a bug where certain dropdowns in theDB Consoleappeared to be empty (with no options to select from) for users of the Safari browser.#128996",
            "Fixed a bug that would cause thehlc_to_timestampfunctionto return an incorrecttimestampfor some inputdecimals.#129153",
            "Fixed a memory leak wherestatement insightobjects could leak if the session was closed without thetransactionfinishing.#128400",
            "Fixed a bug in the public previewWAL failoverfeature that could prevent a node from starting if it crashed during a failover.#129331",
            "Fixed a bug where'infinity'::TIMESTAMPreturned a different result than PostgreSQL.#127141",
            "Fixed a spurious error log from thereplication queueinvolving the text\" needs lease, not adding\".#129351",
            "Using more than oneDECLAREstatement in the definition of auser-defined functionnow correctly declares additional variables.#129951",
            "Fixed a bug in which someSELECT FOR UPDATEorSELECT FOR SHAREqueries usingNOWAITcould still block on locked rows when using theoptimizer_use_lock_op_for_serializablesession settingunderserializableisolation. This bug was introduced withoptimizer_use_lock_op_for_serializablein v23.2.0.#130103",
            "Fixed a bug in theupgradepre-condition for repairing descriptor corruption that could lead to finalization being stuck.#130064",
            "Fixed a bug that caused the optimizer to plan unnecessary post-query uniqueness checks duringINSERT,UPSERT, andUPDATEstatements on tables with partial, unique,hash-sharded indexes. These unnecessary checks added overhead to execution of these statements, and caused the statements to error when executed underREAD COMMITTEDisolation.#130366",
            "Fixed a bug that caused incorrect evaluation ofCASE,COALESCE, andIFexpressions with branches producing fixed-width string-like types, such asCHAR. In addition, theBPCHARtype no longer incorrectly imposes a length limit of1.#129007",
            "Fixed a bug wherezone configurationchanges issued by thedeclarative schema changerwere not blocked if a table had theschema_lockedstorage parameterset.#130670",
            "Fixed a bug that could prevent aCHANGEFEEDfrom being able to resume after being paused for a prolonged period of time.#130622",
            "Fixed a bug where if a client connection was attempting aschema changewhile the sameschema objectswere being dropped, it was possible for the connection to be incorrectly dropped.#130928",
            "Fixed a bug introduced in v23.1 that could cause incorrect results when:The query contained acorrelated subquery.The correlated subquery had aGROUP BYorDISTINCToperator with an outer-column reference in its input.The correlated subquery was in the input of aSELECTorJOINoperator.TheSELECTorJOINhad a filter that set the outer-column reference from (2) equal to a non-outer column in the input of the grouping operator.The grouping column set did not include the replacement column, and functionally determined the replacement column.#130925",
            "The query contained acorrelated subquery.",
            "The correlated subquery had aGROUP BYorDISTINCToperator with an outer-column reference in its input.",
            "The correlated subquery was in the input of aSELECTorJOINoperator.",
            "TheSELECTorJOINhad a filter that set the outer-column reference from (2) equal to a non-outer column in the input of the grouping operator.",
            "The grouping column set did not include the replacement column, and functionally determined the replacement column.#130925",
            "Fixed a bug which could cause errors with the message\"internal error: Non-nullable column ...\"when executing statements underREAD COMMITTEDisolation that involved tables withNOT NULLvirtual columns.#130725",
            "Fixed a bug that could cause a very rare internal error\"lists in SetPrivate are not all the same length\"when executing queries.#130981",
            "Fixed a bug that could cause incorrect evaluation ofscalar expressionsinvolvingNULLvalues in rare cases.#128123",
            "SHOW CREATE ALL SCHEMASnow shows corresponding schema comments in its output.#130164",
            "Fixed a bug, introduced in v23.2.0, where creating a newincremental schedule(usingALTER BACKUP SCHEDULE) on afull backup schedulecreated on an older version would fail.#131231",
            "Fixed a bug that could cause an internal error if a table with an implicit (rowid)primary keywas locked from within asubquerylikeSELECT * FROM (SELECT * FROM foo WHERE x = 2) FOR UPDATE;. The error could occur either underREAD COMMITTEDisolation, or with theoptimizer_use_lock_op_for_serializablesession settingenabled.#129768",
            "Fixed a bug wherejobscreated in a session with non-zero sessiontimezone offsetscould hang before starting, or report incorrect creation times when viewed inSHOW JOBSand theDB Console.#123632",
            "Fixed a bug which could result inchangefeeds using CDC queriesfailing due to a system table beinggarbage collected.#131027",
            "ALTER COLUMN TYPEnow errors out when there is apartial indexthat is dependent on the column being altered.#131590",
            "Fixed a bug that prevented buffered file sinks from being included when iterating over all file sinks. This led to problems such as thedebug zipcommand not being able to fetch logs for a cluster where buffering was enabled.#130158",
            "Fixed a bug where backup schedules could advance a protected timestamp too early, which caused incremental backups to fail.#131358",
            "Raft logsync callback handling is now parallelized, which can improve write-heavy workload performance on large, single-store nodes.#126523",
            "Planning timefor complex queries has been reduced.#128049",
            "Reduced thewrite-amplificationimpact ofrebalancesby splitting snapshot SSTable files into smaller ones before ingesting them intoPebble.#127997",
            "Improved the performance ofjob-systemrelated queries.#123848",
            "Thequery optimizernow plans limited,partial-index scansin more cases.#129901",
            "The initialization of the execution engine for a query is now more efficient when thequery plancontainsaggregate functions.#130834",
            "Enabled multi-levelcompactionsthat moderately reducewrite amplificationwithin thestorage engine.#131378",
            "Increased the per-vCPU concurrency limits for KV operations. Specifically, increased thekv.dist_sender.concurrency_limitcluster settingto 384/vCPU (up from 64/vCPU) andkv.streamer.concurrency_limitto 96/vCPU (up from 8/vCPU).#131226",
            "Theoptimizernow plans more efficientlookup joinsin some cases.#131383",
            "Changed the AWS SDK version used for interactions with external storage from v1 to v2.#129938",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.3",
        "patch_version": "24.3.0",
        "date": "November 18, 2024",
        "changes": [
            "Feature categoriesCockroachDB LicensingCockroachDB CloudChange Data CaptureDisaster RecoverySQLSecurityObservability",
            "CockroachDB Licensing",
            "CockroachDB Cloud",
            "Change Data Capture",
            "Disaster Recovery",
            "Observability",
            "Additional informationBackward-incompatible changesKey cluster setting changesDeprecationsKnown limitationsAdditional resources",
            "Backward-incompatible changes",
            "Key cluster setting changes",
            "Deprecations",
            "Known limitations",
            "Additional resources",
            "Enterprise: This paid license allows usage of all CockroachDB features in accordance with the terms specified in theCockroachDB Software License.",
            "Enterprise Free: Same functionality as Enterprise, but free of charge for businesses with less than $10M in annual revenue. Clusters will be throttled after 7 days without sending telemetry. License must be renewed annually.",
            "Enterprise Trial: A 30 day self-service trial license. Telemetry is required during the trial. Clusters will be throttled after 7 days without sending telemetry. Telemetry can be disabled once the cluster is upgraded to a paid Enterprise license.",
            "Added on-hover cursor support that will display the closest time-series value and highlight the node in the legend to allow users to quickly pinpoint outliers.",
            "Improved legend visibillity and made legends scrollable to improve usability and reduce vertical scrolling.",
            "Foreground (regular) CPU work",
            "Store (IO) work",
            "Background (elastic) CPU work",
            "Replication admission control (store overload on replicas)",
            "Upgrading to v24.3 is blocked if nolicenseis installed, or if a trial/free license is installed with telemetry disabled.#130576",
            "A cluster must have anEnterprise licenseor atrial licenseset before an upgrade to v24.3 can be finalized.",
            "New clusters that are initialized for the first time on v24.3, and clusters that are upgraded to v24.3 will now have azone configdefined for thetimeseriesrange if it does not already exist, which specifies the value forgc.ttlseconds, but inherits all other attributes from the zone config for thedefaultrange.",
            "Settings added",
            "Settings with changed defaults",
            "Settings with changed visibility",
            "Additional setting changes",
            "goschedstats.always_use_short_sample_period.enabled: when set totrue, helps to prevent unnecessary queueing due to CPUadmission controlby forcing1mssampling of runnable queue lengths. The default value isfalse.#133585",
            "kv.range.range_size_hard_cap: allows you to limit how large arangecan grow beforebackpressureis applied. This can help to mitigate against a situation where a range cannot be split, such as when a range is comprised of a single key due to an issue with the schema or workload pattern, or a bug in client application code. The default is8 GiB, 16 times the default maximum range size. If you have changed the maximum range size, you may need to adjust this cluster setting or reduce the range size.#129450",
            "kvadmission.flow_controller.token_reset_epoch: can be used to refill replicationadmission controlv2 tokens. This setting is marked asreserved, as it is not supported for tuning, by default. Use it only after consultation with your account team.#133294",
            "kvadmission.store.snapshot_ingest_bandwidth_control.enabled: enables a newAdmission Controlintegration for pacing snapshot ingest traffic based on disk bandwidth. It requires provisioned bandwidth to be set for the store, or the cluster through the settingkvadmission.store.provisioned_bandwidth, for it to take effect.#131243",
            "Settings have been added which control the refresh behavior for the cached data in the Databases page of theDB Console:obs.tablemetadatacache.data_valid_duration: the duration for which the data insystem.table_metadatais considered valid before a cache reset will occur. Default: 20 minutes.obs.tablemetadatacache.automatic_updates.enabled: whether to automatically update the cache according the validity interval. Default:false.#130198",
            "obs.tablemetadatacache.data_valid_duration: the duration for which the data insystem.table_metadatais considered valid before a cache reset will occur. Default: 20 minutes.",
            "obs.tablemetadatacache.automatic_updates.enabled: whether to automatically update the cache according the validity interval. Default:false.",
            "server.jwt_authentication.client.timeout: the HTTP client timeout for external calls made duringJWT authentication.#127145",
            "Partialstatisticscan now be automatically collected at the extremes of indexes when a certain fraction and minimum number of rows are stale (by default 5% and 100%, respectively). These can be configured with newtable storage parametersandcluster settings:sql.stats.automatic_partial_collection.enabled(table parametersql_stats_automatic_partial_collection_enabled) - both default tofalse.sql.stats.automatic_partial_collection.min_stale_rows(table parametersql_stats_automatic_partial_collection_min_stale_rows) - both default to100.sql.stats.automatic_partial_collection.fraction_stale_rows(table parametersql_stats_automatic_partial_collection_fraction_stale_rows) - both default to0.05.#93067",
            "sql.stats.automatic_partial_collection.enabled(table parametersql_stats_automatic_partial_collection_enabled) - both default tofalse.",
            "sql.stats.automatic_partial_collection.min_stale_rows(table parametersql_stats_automatic_partial_collection_min_stale_rows) - both default to100.",
            "sql.stats.automatic_partial_collection.fraction_stale_rows(table parametersql_stats_automatic_partial_collection_fraction_stale_rows) - both default to0.05.",
            "sql.stats.histogram_buckets.include_most_common_values.enabled: controls whether common values are included inhistogram collectionfor use by theoptimizer. When enabled, histogram buckets will represent the most common sampled values as upper bounds.#129378",
            "sql.stats.histogram_buckets.max_fraction_most_common_values: controls the fraction of buckets that can be adjusted to include common values. Defaults to0.1.#129378",
            "sql.txn.repeatable_read_isolation.enabled: defaults tofalse. When set totrue, the following statements configure transactions to run underREPEATABLE READisolation, rather than being automatically interpreted asSERIALIZABLE:BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READSET TRANSACTION ISOLATION LEVEL REPEATABLE READSET default_transaction_isolation = 'repeatable read'SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "SET TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "SET default_transaction_isolation = 'repeatable read'",
            "SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL REPEATABLE READ",
            "The default forsql.defaults.large_full_scan_rowsis now0. If a user is using session var values inherited from these settings, whensql.defaults.disallow_full_table_scans.enabledis set totrue: all full table scans are now disallowed by default, even full scans on very small tables, but ifsql.defaults.large_full_scan_rowsis set to a number greater than0, full scans are allowed if they are estimated to read fewer than that number of rows.Note:Allsql.defaultssettings are maintained for backward compatibility. We recommend usingALTER ROLE, instead, to set the corresponding session vars for users (in this case,large_full_scan_rowsanddisallow_full_table_scans). For more information, see the note on theCluster Settings table.",
            "Note:Allsql.defaultssettings are maintained for backward compatibility. We recommend usingALTER ROLE, instead, to set the corresponding session vars for users (in this case,large_full_scan_rowsanddisallow_full_table_scans). For more information, see the note on theCluster Settings table.",
            "Increased the per-vCPU concurrency limits for KV operations:The default forkv.dist_sender.concurrency_limit(reserved) has changed from64per vCPU to384per vCPU. (In v24.3, it is possible to estimate the current concurrency level using the new metricdistsender.batches.async.in_progress.)The default forkv.streamer.concurrency_limit(reserved) has changed from8per vCPU to96per vCPU.These arereservedsettings, not intended for tuning by customers.When runningSHOW CLUSTER SETTING, the displayed setting values will depend on the node's number of vCPUs.Contact Support if the number ofdistsender.batches.async.throttledrequests is persistently greater than zero.#131226",
            "The default forkv.dist_sender.concurrency_limit(reserved) has changed from64per vCPU to384per vCPU. (In v24.3, it is possible to estimate the current concurrency level using the new metricdistsender.batches.async.in_progress.)",
            "The default forkv.streamer.concurrency_limit(reserved) has changed from8per vCPU to96per vCPU.",
            "These arereservedsettings, not intended for tuning by customers.",
            "When runningSHOW CLUSTER SETTING, the displayed setting values will depend on the node's number of vCPUs.",
            "Contact Support if the number ofdistsender.batches.async.throttledrequests is persistently greater than zero.",
            "The default forserver.oidc_authentication.client.timeout, which sets the client timeout for external calls made during OIDC authentication, has changed from30sto15s.",
            "Cluster settings for configuringrate limiting for traffic to cloud storageare now public.These settings have the prefixcloudstoragefollowed by:a provider or protocol (azure,gs,s3,http,nodelocal,userfile, ornullsink)readorwritenode_burst_limitornode_rate_limitFor example,cloudstorage.s3.write.node_burst_limit.#127207",
            "These settings have the prefixcloudstoragefollowed by:a provider or protocol (azure,gs,s3,http,nodelocal,userfile, ornullsink)readorwritenode_burst_limitornode_rate_limit",
            "a provider or protocol (azure,gs,s3,http,nodelocal,userfile, ornullsink)",
            "readorwrite",
            "node_burst_limitornode_rate_limit",
            "For example,cloudstorage.s3.write.node_burst_limit.#127207",
            "JWT authentication have been madepublic.#128170server.jwt_authentication.audienceserver.jwt_authentication.claimserver.jwt_authentication.enabledserver.jwt_authentication.issuers.custom_caserver.jwt_authentication.jwksserver.jwt_authentication.jwks_auto_fetch.enabled",
            "server.jwt_authentication.audience",
            "server.jwt_authentication.claim",
            "server.jwt_authentication.enabled",
            "server.jwt_authentication.issuers.custom_ca",
            "server.jwt_authentication.jwks",
            "server.jwt_authentication.jwks_auto_fetch.enabled",
            "Settings with the prefixserver.ldap_authenticationhave been madepublicwith the Preview release of LDAP support:server.ldap_authentication.client.tls_certificateserver.ldap_authentication.client.tls_keyserver.ldap_authentication.domain.custom_ca",
            "server.ldap_authentication.client.tls_certificate",
            "server.ldap_authentication.client.tls_key",
            "server.ldap_authentication.domain.custom_ca",
            "The settingserver.host_based_authentication.configurationnow supports LDAP configuration, and its value is now redacted for non-admin users when theserver.redact_sensitive_settings.enabledis set totrue.#131150",
            "The settingsenterprise.licenseanddiagnostics.reporting.enablednow have additional validation. To disable diagnostics reporting, the cluster must also have a license that is not anEnterprise Trial or Enterprise Free license. Additionally, to set one of these licenses, the cluster must already be submitting diagnostics information.#131097#132257",
            "sql.defaults.vectorizenow supports the value1(in addition to0and2) to indicateon, to address a bug that could cause new connections to fail after an upgrade with a message referencing aninvalid value for parameter \"vectorize\": \"unknown(1)\".#133371",
            "The description of the settingchangefeed.sink_io_workershas been updated to reflect all of thesinksthat support the setting: the batching versions of webhook, pubsub, and kafka sinks that are enabled bychangefeed.new_<sink type>_sink_enabled.#129946",
            "The session variableenforce_home_region_follower_reads_enabledis now deprecated, and will be removed in a future release. The related session variableenforce_home_regionisnotdeprecated.#129024"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.9",
        "date": "December 26, 2024",
        "changes": [
            "Added thelegacy_varchar_typingsession setting. When set toon, type-checking comparisons involvingVARCHARcolumns behave as they did in all previous versions. When set tooff, type-checking of these comparisons is more strict and queries that previously succeeded may now error with the messageunsupported comparison operator. These errors can be fixed by adding explicit type casts. Thelegacy_varchar_typingsession setting is on by default.#137946"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.8",
        "date": "December 12, 2024",
        "changes": [
            "All cluster settings that accept strings are now fully redacted when transmitted as part of our diagnostics telemetry. The transmitted payload includes a record of modified cluster settings and their values when they are not strings. If you previously applied the mitigations inTechnical Advisory 133479, you can safely set the value of cluster settingserver.redact_sensitive_settings.enabledto false and turn on diagnostic reporting via thediagnostics.reporting.enabledcluster setting without leaking sensitive cluster settings values.#134016",
            "COCKROACH_SKIP_ENABLING_DIAGNOSTIC_REPORTINGis no longer mentioned in thecockroach democommand.#134087",
            "Addedsystem.usersto the list of system tables that changefeeds protect with protected timestamps (PTS). This table is required for change data capture queries.#134836",
            "Added changefeed support for themvcc_timestampoption with theavroformat. If both options are specified, theavroschema includes anmvcc_timestampmetadata field and emits the row's MVCC timestamp with the row data.#136482",
            "To prevent unnecessary queuing in admission control CPU queues, thegoschedstats.always_use_short_sample_period.enabledsetting should be set totruefor any production cluster.#133583",
            "A new cluster settingui.database_locality_metadata.enabled, when set totrue, disables loading database and table region information in the DB Console Database and Table pages. This information can cause significant CPU load on large clusters with many ranges. The Database and Table pages in v24.3 onwards do not have this problem. If you require this data, use theSHOW RANGES FROM {DATABASE|TABLE}SQL statement to compute this information on-demand.#134094",
            "The row-level TTL job now will periodically log progress by showing the number of table spans that have been processed so far.#135179",
            "Fixed a bug where CockroachDB could encounter an internal errorinterface conversion: coldata.Column isin an edge case. The bug was present in v22.2.13+, v23.1.9+, and v23.2+.#133760",
            "Fixed an unhandled error that could occur when usingREVOKE ... ON SEQUENCE ... FROM useron an object that is not a sequence.#133708",
            "Fixed a bug that caused incorrectNOT NULLconstraint violation errors onUPSERTandINSERT ... ON CONFLICT ... DO UPDATEstatements when those statements updated an existing row and a subset of columns that did not include aNOT NULLcolumn of the table. This bug had been present since at least v20.1.0.#133822",
            "Addressed a panic that could occur insideCREATE TABLE ASif sequence builtin expressions had invalid function overloads.#133868",
            "String constants can now be compared against collated strings.#134105",
            "Previously, when executing queries with index / lookup joins where ordering needed to be maintained, CockroachDB's behavior could lead to increased query latency, potentially by several orders of magnitude. This bug was introduced in v22.2, and is now fixed.#134365",
            "Fixed a bug whereDISCARD ALLstatements were counted under thesql.ddl.countmetric. Now these statements will be counted under thesql.misc.countmetric.#134508",
            "Fixed a bug whereDROP CASCADEwould occasionally panic with anun-dropped backrefmessage on partitioned tables.#134522",
            "Reduced the duration of partitions in the gossip network when a node crashes. This eliminates false positives in theranges.unavailablemetric.#134601",
            "As a non-admin user who runsDROP ROLE IF EXISTSon a user that does not exist, you no longer get an error message.#134968",
            "Fixed a bug that caused quotes around the name of a routine to be dropped when the routine was called within another routine. This could prevent the correct routine name from being resolved if the nested routine name was case-sensitive. The bug has existed since v24.1, when nested routines were introduced.#134001",
            "Fixed a bug that could cause incorrect query results when the optimizer planned a lookup join on an index containing a column of typeCHAR(N),VARCHAR(N),BIT(N),VARBIT(N), orDECIMAL(M, N), and the query held that column constant to a single value (for example, with an equality filter).#135111",
            "Fixed an unhandled error that would occur ifDROP SCHEMAwas executed on thepublicschema of thesystemdatabase, or on an internal schema, such aspg_catalogorinformation_schema.#135195",
            "Fixed a bug that caused incorrect evaluation of some binary expressions involvingCHAR(N)values and untyped string literals with trailing whitespace characters. For example, the expression'f'::CHAR = 'f 'now correctly evaluates totrue.#135690",
            "CREATE SCHEMAnow returns the correct error if a the schema name is missing.#135926",
            "Unnecessary block loads of SSTable files are now avoided in some rare cases after a replica rebalance.#134541"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.7",
        "date": "November 18, 2024",
        "changes": [
            "You can now authenticate to the DB Console by passing a JWT as the bearer token.#133536",
            "Changed the licensecockroachis distributed under to the new CockroachDB Software License.#131706#131939#131950#131982#132004#132005#132007#132009#132008#132010#132017#132057#132802#132750",
            "Attempting to install a second Enterprise Trial license on the same cluster will now fail.#131972",
            "The cluster settingdiagnostics.reporting.enabledis now ignored if the cluster has an Enterprise Trial or Enterprise Free license or if the license cannot be loaded.#132463",
            "The new metricschangefeed.sink_errorsandchangefeed.internal_retry_message_countallow you to observe the rate of errors and internal retries for a sink, respectively.#132352",
            "Added a timer for inner sink client flushes.#133196",
            "Some charts on theOverviewandReplicationmetrics dashboard pages have more terse legends to facilitate easier browsing.#129358",
            "The DB Console now shows a warning if the cluster is throttled or will be throttled soon due to an expired Enterprise Free or Enterprise Trial license or missing telemetry data. Clusters with an Enterprise license are not throttled.#132091",
            "TheRange Countcolumn on theDatabasespage is no longer shown due to performance issues. This data is still available via theSHOW RANGEScommand.#133269",
            "Fixed a bug where timers were not correctly registered with the metric system.#133196",
            "Fixed a bug where the command-line interface would not correctly escape JSON values that had double quotes inside a string when using the--format=sqlflag.#131930",
            "Fixed an error that could occur if aSETcommand used an aggregate function as the value.#131959",
            "Added automated clean-up and validation for dropped roles inside of default privileges.#132135",
            "Fixed a bug that could causeRESTOREto hang after encountering transient errors from the storage layer.#132259",
            "Fixed a rare bug that could prevent a backup from being restored and could cause the errorrewriting descriptor ids: missing rewrite for <id> in SequenceOwner.... This bug could occur only if aDROP COLUMNoperation dropped a sequence while the backup was running.#132325",
            "Fixed a bug that caused incorrect evaluation of aCASE,COALESCE, orIFexpression with a branch that produced fixed-width string-like types, such asCHAR.#130890",
            "Fixed a bug that could cause theBPCHARtype to incorrectly impose a length limit of 1.#130890",
            "Fixed a bug introduced before v23.1 that could cause incorrect results when a join evaluates columns with equivalent but non-identical types, such asOIDandREGCLASS, for equality. The issue arises when the join performs an index lookup on an index that includes a computed column referencing one of the equivalent columns.#132509",
            "Fixed a bug introduced before v23.1 that could cause a composite sensitive expression to compare differently if comparing equivalent but non-identical input values, such as2.0::DECIMALand2.00::DECIMAL. The issue arises when the join performs an index lookup on a table with a computed index column where the computed column expression is composite sensitive.#132509",
            "Fixed a bug where a span statistics request on a mixed-version cluster could result in a null pointer exception.#132681",
            "Updated thefranz-golibrary to fix a potential deadlock when a changefeed restarts.#132785",
            "Fixed a bug where a changefeed could fail to update protected timestamp records after a retryable error.#132775",
            "Fixed a bug where a changefeed that used change data capture queries could fail after a system table was garbage collected.#131648",
            "Fixed a rare bug introduced in v22.2 where an update of a primary key column could fail to update the primary index if it is also the only column in a separate column family.#132122",
            "Fixed a bug where theproretsetcolumn of thepg_catalog.pg_proctable was incorrectly set tofalsefor builtin functions that return a set.#132875",
            "Fixed a bug that could cause incorrect evaluation of scalar expressions withNULLvalues.#132947",
            "Fixed a rare bug in the query optimizer that could cause a node to crash if a query contained a filter in the formcol IN (elem0, elem1, ..., elemN)whenNis very large, in the order of millions, and whencolexists in a hash-sharded index or when a table with an indexed computed column depends oncol.#133065",
            "Fixed a bug where anALTER DEFAULT PRIVILEGES FOR target_role ...command could result in an erroneous privilege error when run by a user with theadminrole.#133070",
            "Fixed a bug where aREASSIGN OWNED BYcommand would fail to transfer ownership of the public schema, even when the schema was owned by the target role.#133070",
            "Fixed a panic when resolving the types of anAS OF SYSTEM TIMEexpression.#132454",
            "Reduced the write-amplification impact of rebalances by splitting snapshot sorted string table (SST) files into smaller ones before ingesting them into Pebble.#129018",
            "Performance has been improved during periodic polling of table history whenschema_lockedis not used.#132190"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.6",
        "date": "October 17, 2024",
        "changes": [
            "Updated the cluster settingchangefeed.sink_io_workerswith all thechangefeed sinksthat support the setting.#130373",
            "Added two network metrics,changefeed.network.bytes_inandchangefeed.network.bytes_out. These metrics track the number of bytes sent by individualchangefeedsto the following sinks:Kafka sinks. Ifchild metrics are enabled, the metric will have akafkalabel.Webhook sinks. If child metrics are enabled, the metric will have awebhooklabel.Pub/Sub sinks. If child metrics are enabled, the metric will have apubsublabel.SQL sink. If child metrics are enabled, the metric will have asqllabel.#130583",
            "Kafka sinks. Ifchild metrics are enabled, the metric will have akafkalabel.",
            "Webhook sinks. If child metrics are enabled, the metric will have awebhooklabel.",
            "Pub/Sub sinks. If child metrics are enabled, the metric will have apubsublabel.",
            "SQL sink. If child metrics are enabled, the metric will have asqllabel.#130583",
            "Added achangefeed.total_rangesmetric that can be used to monitor the number of ranges that are watched bychangefeedaggregators. It shares the same polling interval aschangefeed.lagging_ranges, which is controlled by the existinglagging_ranges_polling_intervaloption.#130983",
            "Disambiguatedmetricsand logs for the two buffers used by the KV feed. The following metrics now have a suffix indicating which buffer they correspond to:changefeed.buffer_entries.*,changefeed.buffer_entries_mem.*,changefeed.buffer_pushback_nanos.*. The old versions are kept for backward compatibility, though using the new format is recommended.#131418",
            "Added timers around key parts of thechangefeedpipeline to help debug feeds experiencing issues. Thechangefeed.stage.{stage}.latencymetrics now emit latency histograms for each stage. The metric respects the changefeedscopelabel for debugging specific feeds.#131429",
            "Beginning with v24.1.6, CockroachDB v24.1 is inLong term support (LTS).",
            "Added aranges.decommissioningmetricrepresenting the number of ranges that have a replica on adecommissioning node.#130248",
            "You can now configure the log format for thestderrlog sinkby setting thestderr.formatfield in theYAML configuration.#131534",
            "TheDB Consolewill now show a notification alerting customers without an Enterprise license toupcoming license changeswith a link to more information.#130426",
            "Fixed a bug in whichSHOW CLUSTER SETTING FOR VIRTUAL CLUSTERwould erroneously returnNULLfor some settings.#128783",
            "Addressed a bug in theupgradepre-condition for repairing descriptor corruption, which could lead to upgrade finalization being stuck.#130518",
            "Fixed a potential memory leak inchangefeedsusing acloud storage sink. The memory leak could occur if bothchangefeed.fast_gzip.enabledandchangefeed.cloudstorage.async_flush.enabledweretrue, and the changefeed received an error while attempting to write to the cloud storage sink.#130601",
            "Fixed a bug in which someSELECT FOR UPDATEorSELECT FOR SHAREqueries usingNOWAITcould still block on locked rows when using theoptimizer_use_lock_op_for_serializablesession settingunderSERIALIZABLEisolation. This bug was introduced withoptimizer_use_lock_op_for_serializablein v23.2.0.#130429",
            "Fixed a bug that caused theoptimizerto plan unnecessary post-query uniqueness checks duringINSERT,UPSERT, andUPDATEstatements on tables withpartial,unique,hash-sharded indexes. These unnecessary checks added overhead to execution of these statements, and caused the statements to error when executed underREAD COMMITTEDisolation.#130569",
            "Previously, if a connection was attempting aschema changewhile the same schema objects were being dropped, it was possible for the connection to be incorrectly dropped. This is now fixed.#130961",
            "Fixed a bug that could result in the inability to garbage collect anMVCCrange tombstone within aglobal table.#130950",
            "Fixed a bug that could cause errors with the messageinternal error: Non-nullable column ...when executing statements underREAD COMMITTEDisolation that involved tables withNOT NULLvirtual columns.#131064",
            "Fixed a bug that could cause incorrect results for queries containing a correlated subquery with aGROUP BYorDISTINCT ONoperator referencing an outer column. This issue would occur if the correlated subquery was in the input of aSELECTorJOINoperator that had a filter equating the outer-column reference to a non-outer column in the grouping operator's input, while the grouping column set did not include the replacement column but functionally determined it. This bug was introduced in v23.1.#130989",
            "The AWS endpoint and cloud custom HTTP client configuration are now considered whenimplicit authenticationis used for cloud storage. Previously, these were only considered when using explicit credentials.#131202",
            "Fixed a bug where jobs created in sessions with non-zero session timezone offsets could hang before starting or report incorrect creation times when viewed inSHOW JOBSand the DB Console.#131406",
            "Fixed a bug that could prevent achangefeedfrom being able to resume after being paused for a prolonged period of time.#130920",
            "Fixed a bug where backup schedules could advance a protected timestamp too early, which caused incremental backups to fail.#131390",
            "Thequery optimizernow plans limited,partial indexscans in more cases when the new session settingoptimizer_push_limit_into_project_filtered_scanis set toon.#130336"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.5",
        "date": "September 25, 2024",
        "changes": [
            "Upgraded thegrpcversion to v1.56.3.#130046",
            "Introduced the newcluster settingchangefeed.protect_timestamp.lag, which controls when achangefeed'sprotected timestamp is updated. Theprotected timestampwill only be updated if the setchangefeed.protect_timestamp.lagvalue has passed between the last protected timestamp and thechangefeed high watermark.#129686",
            "SHOW CHANGEFEED JOB,SHOW CHANGEFEED JOBS, andSHOW JOBSno longer expose user-sensitive information likeclient_key.#122636",
            "Added two network metrics,changefeed.network.bytes_inandchangefeed.network.bytes_out. These metrics track the number of bytes sent by individualchangefeedsto the following sinks:Kafka sinks. Ifchild metricsare enabled, the metric will have akafkalabel.Webhook sinks. Ifchild metricsare enabled, the metric will have awebhooklabel.Pub/Sub sinks. Ifchild metricsare enabled, the metric will have apubsublabel.SQL sink. Ifchild metricsare enabled, the metric will have asqllabel.#130584",
            "Kafka sinks. Ifchild metricsare enabled, the metric will have akafkalabel.",
            "Webhook sinks. Ifchild metricsare enabled, the metric will have awebhooklabel.",
            "Pub/Sub sinks. Ifchild metricsare enabled, the metric will have apubsublabel.",
            "SQL sink. Ifchild metricsare enabled, the metric will have asqllabel.#130584",
            "The session settingplan_cache_mode=force_generic_plancan now be used to forceprepared statementsto use query plans that areoptimizedonce, and reused in future executions without re-optimization, as long as it does not become stale due toschema changesor a collection of newtable statistics. The setting takes effect duringEXECUTEcommands.EXPLAIN ANALYZEincludes aplan typefield. If a generic query plan is optimized for the current execution, theplan typewill begeneric, re-optimized. If a generic query plan is reused for the current execution without performing optimization, theplan typewill begeneric, reused. Otherwise, theplan typewill becustom.#128085",
            "The session settingplan_cache_mode=autocan now be used to instruct the system to automatically determine whether to usecustomorgenericquery plans for the execution of aprepared statement. Custom query plans are optimized on every execution, while generic plans areoptimizedonce and reused on future executions as-is. Generic query plans are beneficial in cases where query optimization contributes significant overhead to the total cost of executing a query.#128085",
            "There are now structuredlogging eventsthat report connection breakage during node shutdown. Previously, the logs existed, but were unstructured. The logs appear in theOPSlogging channel. There are two new events:Thenode_shutdown_connection_timeoutevent is logged after the timeout defined by theserver.shutdown.connections.timeoutcluster setting transpires, if there are still open SQL connections.Thenode_shutdown_transaction_timeoutevent is logged after the timeout defined by theserver.shutdown.transactions.timeoutcluster setting transpires, if there are still open transactions on those SQL connections.#128711",
            "Thenode_shutdown_connection_timeoutevent is logged after the timeout defined by theserver.shutdown.connections.timeoutcluster setting transpires, if there are still open SQL connections.",
            "Thenode_shutdown_transaction_timeoutevent is logged after the timeout defined by theserver.shutdown.transactions.timeoutcluster setting transpires, if there are still open transactions on those SQL connections.#128711",
            "Added a new configuration parameterserver.cidr_mapping_url, which maps IPv4 CIDR blocks to arbitrary tag names.#130051",
            "Modified the metricssql.bytesinandsql.bytesoutto work as aggregate metrics ifchild metricsare enabled.#130051",
            "Added three new network-tracking metrics.rpc.connection.connectedis the number of rRPC TCP level connections established to remote nodes.rpc.client.bytes.egressis the number of TCP bytes sent via gRPC on connections CockroachDB initiates.rpc.client.bytes.ingressis the number of TCP bytes received via gRPC on connections CockroachDB initiated.#130050",
            "This commit adds two metrics:changefeed.network.bytes_inandchangefeed.network.bytes_out. These metrics track the number of bytes sent by the individualchangefeedsto differentsinks.#130584",
            "The user experience formetricscharges in theDB Consolenow has hover behavior that focuses on individual lines and shows values under the mouse pointer.#128867",
            "Users with theVIEWACTIVITYprivilege can download statement bundles from theDB Console.#129503",
            "Users with theVIEWACTIVITYprivilege can now request, view, and cancel statement bundles in theDB Console.#129805",
            "TheDB Consolewill show a notification alerting customers without an Enterprise license toupcoming license changeswith a link to more information.#130510",
            "Previously,declarativeand legacyschema changeswere incorrectly allowed to be run concurrently, which could lead to failing or hung schema change jobs.#128805",
            "Fixed a bug that caused errors likeERROR: column 'crdb_internal_idx_expr' does not existwhen accessing a table with anexpression indexwhere the expression evaluates to anENUMtype, for example,CREATE INDEX ON t ((col::an_enum)).#129093",
            "Fixed a bug whereNaNorInfcould not be used as the default value for a parameter inCREATE FUNCTIONstatements.#129086",
            "Fixed a bug in whichSELECT ... FOR UPDATEandSELECT ... FOR SHAREqueries usingSKIP LOCKEDand aLIMITand/or anOFFSETcould return incorrect results underREAD COMMITTEDisolation. This bug was present when support forSKIP LOCKEDunderREAD COMMITTEDisolation was introduced in v24.1.0.#128101",
            "Fixed a bug in which someSELECT ... FOR UPDATEorSELECT ... FOR SHAREqueries usingSKIP LOCKEDcould still block on locked rows when usingoptimizer_use_lock_op_for_serializableunderSERIALIZABLEisolation. This bug was present whenoptimizer_use_lock_op_for_serializablewas introduced in v24.1.0.#128101",
            "Function input parameters foruser-defined functionscan no longer be of theVOIDtype, which matches the behavior of PostgreSQL.#129280",
            "Fixed a bug in the public preview ofWrite Ahead Log (WAL) Failoverthat could prevent a node from starting if it crashed during a failover.#129367",
            "Starting nodescould fail with:could not insert session ...: unexpected value, if an ambiguous result error was encountered when inserting into thesqllivenesstable.#129234",
            "Internally issued queries that are not initiated within aSQL sessionno longer respect astatement timeout. This includes: backgroundjobs, queries issued by theDB Consolethat perform introspection, and theCloud SQL shell.#129515",
            "Fixed a rare bug inSHOW CLUSTER SETTINGthat could cause it to fail with an error liketimed out: value differs between local setting and KV.#129756",
            "Fixed a bug where theschema_lockedtable parameterdid not prevent a table from being referenced by aforeign key.#129754",
            "Fixed a bug where therequire_explicit_primary_keyssession variablewould aggressively prevent allCREATE TABLEstatements from working.#129907",
            "Fixed a slow-building memory leak when usingKerberos authentication.#130318",
            "Fixed a potential memory leak inchangefeedsusing acloud storage sink. The memory leak could occur if both the cluster settingschangefeed.fast_gzip.enabledandchangefeed.cloudstorage.async_flush.enabledare set totrueand the changefeed received an error while attempting to write to the cloud storage sink.#130626",
            "Fixed a bug that prevented buffered file sinks from being included when iterating over all file sinks. This led to problems such as thedebug zipcommand not being able to fetch logs for a cluster where buffering was enabled.#130158"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.4",
        "date": "August 29, 2024",
        "changes": [
            "URLs in the following SQL statements are now sanitized of any secrets before being written tounredacted logs.#127506ALTER BACKUP SCHEDULEALTER BACKUPALTER CHANGEFEED SET sinkBACKUPCOPYCREATE CHANGEFEEDCREATE EXTERNAL CONNECTIONCREATE SCHEDULE FOR BACKUPCREATE SCHEDULE FOR CHANGEFEEDEXPORTIMPORT INTORESTORESHOW BACKUPSSHOW BACKUP",
            "ALTER BACKUP SCHEDULE",
            "ALTER BACKUP",
            "ALTER CHANGEFEED SET sink",
            "CREATE CHANGEFEED",
            "CREATE EXTERNAL CONNECTION",
            "CREATE SCHEDULE FOR BACKUP",
            "CREATE SCHEDULE FOR CHANGEFEED",
            "IMPORT INTO",
            "SHOW BACKUPS",
            "SHOW BACKUP",
            "Added a new Kafkachangefeed sinkthat uses thefranz-golibraryand CockroachDB'sbatching_sinkimplementation. The new Kafka sink can be enabled with thechangefeed.new_kafka_sink_enabledcluster setting, which is disabled by default.#128018",
            "The new Kafka sink, enabled withchangefeed.new_kafka_sink_enabled, as well as the Google Cloud Pub/Sub sink, now display notices indicating the topics that a changefeed will emit to.#128333",
            "Added a newsql.auth.grant_option_for_owner.enabledcluster settingto prevent theGRANT OPTIONfrom being given to the owner of an object by default. The cluster setting defaults totrue, retaining the existing behavior; when it is set tofalse, theGRANT OPTIONis not implicitly given to an object's owner. The owner will still have all privileges on an object except the ability to grant privileges to other users.#126959",
            "A--locality-fileflag is now available on thecockroach startandcockroach start-single-nodecommands. This allows specifying nodelocality(typically aregionvalue) as a file, rather than by using the--localityflag.#127475",
            "TheDatabasesandTablespagesin the DB Console now show a loading state while loading information for databases and tables, including size and range counts.#127748",
            "On theDatabasespagein the DB Console, table names will no longer appear with quotes around the schema and table name.#127766",
            "Fixed a bug introduced in v23.2.0 in which CockroachDB would hit an internal error when evaluatingINSERTsintoREGIONAL BY ROWtables where the source was aVALUESclause with a single row and at least one Boolean expression.#127277",
            "Fixed a bug in which theDISCARDstatement was disallowed when thesession settingdefault_transaction_read_onlywas set toon.#127363",
            "In theDB Console event log,ALTER ROLEevents now display correctly even when norole optionsare included in theALTER ROLEstatement.#126568",
            "Fixed a formatting issue with thesql_sequence_cached_nodevalue of theserial_normalizationsession setting. This could lead to an error connecting to CockroachDB if this value was set as the default forserial_normalizationvia the cluster settingsql.defaults.serial_normalization.#127673",
            "Fixed a bug wheredroppingENUMvaluesthat were referenced byindex expressionscould fail with an error.#127454",
            "Fixed a bug that caused a memory leak when executing SQL statements withcomments, for example,SELECT /* comment */ 1;. Memory owned by a SQL session would continue to grow as these types of statements were executed. The memory would only be released when closing theSQL session. This bug had been present since v23.1.#127759",
            "Fixed a bug whereschema changescould hang if the lease rangefeed stopped receiving updates.#127487",
            "Fixed small memory leaks that would occur duringchangefeedcreation.#128018",
            "Fixed a memory leak that could occur when specifying a non-existentvirtual clustername in the connection string.#128106",
            "Fixed a bug whereCREATE INDEX IF NOT EXISTSwould not correctly short-circuit if the given index already existed.#128311",
            "Fixed a bug in syntax validation, in which theDESCENDINGclause was not allowed for non-terminal columns of aninverted index. Only the last column of an inverted index should be prevented from beingDESCENDING. This is now properly checked.#128311",
            "Fixed a bug where anindexcould store a column in the primary index if that column had a mixed-case name.#128311",
            "Setting or dropping a default value on acomputed columnis now blocked, even forNULLdefaults. Previously, setting or dropping a default value on a computed column was a no-op.#128466",
            "Fixed a bug that could cause spurious user permission errors when multiple databases shared a common schema with a routine referencing a table. The bug had existed since v22.2 whenuser-defined functions (UDFs)were introduced.#126412",
            "Fixed a bug wheredebug zipwould return an error while fetching unstructured/malformed logs.#128605",
            "Fixed a bug where a hash-shardedconstraintcould not be created if it referred to columns that had a backslash in the name.#128521",
            "Fixed a bug in which the output ofEXPLAIN (OPT, REDACT)for variousCREATEstatements was not redacted. This bug had existed sinceEXPLAIN (REDACT)was introduced in v23.1 and affects the following statements:EXPLAIN (OPT, REDACT) CREATE TABLEEXPLAIN (OPT, REDACT) CREATE VIEWEXPLAIN (OPT, REDACT) CREATE FUNCTION#128489",
            "EXPLAIN (OPT, REDACT) CREATE TABLE",
            "EXPLAIN (OPT, REDACT) CREATE VIEW",
            "EXPLAIN (OPT, REDACT) CREATE FUNCTION#128489"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.3",
        "date": "August 1, 2024",
        "changes": [
            "EXPLAIN ANALYZEstatements are now supported when executed via Cloud ConsoleSQL shell.#125563",
            "Added thesql.auth.grant_option_inheritance.enabledcluster setting. The default value istrue, which maintains consistency with CockroachDB's previous behavior: users granted a privilege withWITH GRANT OPTIONcan in turn grant that privilege to others. Whensql.auth.grant_option_inheritance.enabledis set tofalse, theGRANT OPTIONis not inherited through role membership, thereby preventing descendant roles from granting the privilege to others. However, the privilege itself continues to be inherited through role membership.#126300",
            "crdb_internal.cluster_execution_insights.txtandcrdb_internal.cluster_txn_execution_insights.txthave been removed from thedebug zip. These files contained cluster-wide insights for statements and transactions. Users can still rely on theper-node executioninsights incrdb_internal.node_execution_insights.txtandcrdb_internal.node_txn_execution_insights.txt.#125807",
            "For theTELEMETRY logging channel, TCLsampled_queryevents will now be sampled at the rate specified by the settingsql.telemetry.query_sampling.max_event_frequency, which is already used to limit the rate of sampling DML statements.#126729",
            "Fixed a bug where collection ofdebug informationfor very long-runningjobscould use excessive space in thejob_infosystem table and cause some interactions with the jobs system to become slow.#126122",
            "Fixed a bug where a change to auser-defined type (UDT)could cause queries against tables using that type to fail with an error:histogram.go:694: span must be fully contained in the bucket. The change to the user-defined type could come directly from anALTER TYPEstatement, or indirectly from anALTER DATABASE ADD REGIONorDROP REGIONstatement (which implicitly change thecrdb_internal_regiontype). This bug has existed since UDTs were introduced in v20.2.#125800",
            "Fixed a bug in which constantLIKEpatterns containing certain sequences of backslashes did not become constrained scans. This bug has been present since v21.1.13 when support for building constrained scans fromLIKEpatterns containing backslashes was added.#125539",
            "Fixed the statistics estimation code in theoptimizerso it does not use the empty histograms produced ifhistogram collectionhas been disabled during stats collection due to excessive memory utilization. Now the optimizer will rely on distinct counts instead of the empty histograms and should produce better plans as a result. This bug has existed since CockroachDB v22.1.#126153",
            "Fixed a bug whereCREATE TABLEstatements withindex expressionscould hit undefined column errors ontransaction retries.#125967",
            "Fixed a bug where CockroachDB would hit an internal error when evaluatingINSERTsintoREGIONAL BY ROWtables where the source is aVALUESclausewith a single row and at least one boolean expression. The bug was introduced in v23.2.0.#125505",
            "Fixed a bug incockroach debug tsdumpwhere the command fails when a custom SQL port is used and the--format=rawflag is provided.#125980",
            "Fixed a bug where auser-defined function (UDF)that shared a name with abuilt-in functionwould not be resolved, even if the UDF had higher precedence according to thesearch_pathvariable.#126296",
            "Fixed a bug that causedbackground jobsto incorrectly respect a statement timeout.#126820",
            "Fixed a bug whereALTER DATABASE ... DROP REGIONcould fail if any tables under the given database haveindexes on expressions.#126599",
            "Fixed a PostgreSQL incompatibility bug when inputtingpublicas user name forbuilt-in functionssuch ashas_database_privilegeandhas_schema_privilege.#126851",
            "Fixed a bug whenrestoringa database with acomposite type.#126428",
            "Fixed a bug where theDatabasespage crashed if the range information was not available.#127092",
            "Fixed a bug where CockroachDB could incorrectly evaluate anIS NOT NULLfilter if it was applied to non-NULLtuples that hadNULLelements, such as(1, NULL)or(NULL, NULL). This bug has existed since v20.2.#126938",
            "Thesql_sequence_cached_nodevalue of theserial_normalizationsettingwas not correctly formatted. This could lead to errors while connecting to CockroachDB if the default value ofserial_normalizationwas set toserial_normalization. The formatting bug was fixed, which also fixes the errors when connecting.#127675",
            "Starting acockroachprocess will no longer flush bufferedlogsto configuredlogging sinksunless the process is running undersystemd, where cockroach runs with theNOTIFY_SOCKETenvironment variable.#126305",
            "Schema changesthat cause a data backfill, such as adding a non-nullable column or changing the primary key, will now split and scatter the temporary indexes used to perform the change. This reduces the chance of causing awrite hotspotthat can slow down foreground traffic.#126684"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.25",
        "date": "October 17, 2025",
        "changes": [
            "Fixed a bug where anINSERTstatement could fail with a type checking error while adding aBIT(n)column.#153606",
            "Fixed a bug that caused panics when executingCOPYinto a table with hidden columns and expression indexes. The panic only occurred when the session settingexpect_and_ignore_not_visible_columns_in_copywas enabled. This bug was introduced withexpect_and_ignore_not_visible_columns_in_copyin v22.1.0.#154282",
            "Fixed a bug where the presence of duplicate temporary tables in a backup caused the restore to fail with an error containing the textrestoring table desc and namespace entries: table already exists.#154400"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.24",
        "date": "September 22, 2025",
        "changes": [
            "Whensql_safe_updatesis enabled, theALTER TABLE ... LOCALITYstatement will be blocked when trying to convert an existing table toREGIONAL BY ROW, unless a region column has been added to the table. This protects against undesired behavior that causedUPDATEorDELETEstatements to fail against the table while the locality change was in progress.#152603",
            "Updated TTL job replanning to be less sensitive by focusing specifically on detecting when nodes become unavailable rather than reacting to all plan differences. The cluster settingsql.ttl.replan_flow_thresholdmay have been set to0to work around the TTL replanner being too sensitive; this fix will alleviate that and any instance that had setreplan_flow_thresholdto0can be reset back to the default.#151490",
            "Fixed a bug wheredebug.zipfiles collected from clusters withdisallow_full_table_scansenabled were missing system table data.#151222",
            "Fixed a bug where updating column default expressions would incorrectly remove sequence ownerships for the affected column.#152312",
            "Fixed a bug where views could not reference thecrdb_regioncolumn from their underlying tables in expressions.#152744",
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152893"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.23",
        "date": "August 22, 2025",
        "changes": [
            "Backporting detailed error logging logic gated behind a cluster setting. The cluster setting enables detailed error logging for messages exceeding Kafka v2 size limit.#150183",
            "Changefeeds emitting to Kafka sinks that were created in CockroachDB v24.2.1+, or v23.2.10+ and v24.1.4+ with thechangefeed.new_kafka_sink.enabledcluster setting enabled now include the message key, size, and MVCC timestamp in \"message too large\" error logs.#150183",
            "Fixed an issue where themvcc_timestampfield was incorrectly returning zero values when used with CDC queries. The timestamp is now emitted correctly.#147110",
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151083",
            "Upgrade Go to consume security fixes#150990",
            "Restore will now re-attemptAdminSplitKV requests instead of immediately failing and pausing the job.#149618"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.22",
        "date": "August 1, 2025",
        "changes": [
            "Fixed a bug that could cause some errors returned by attempts to upload backup data to external storage providers to be undetected, potentially causing incomplete backups.#151098"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.21",
        "date": "July 28, 2025",
        "changes": [
            "Fixed a data race in thecloudstoragesink.#147160",
            "Fixed a bug wherelibpqclients using the async API could hang with large result sets (Python: psycopg; Ruby: ActiveRecord, ruby-pg).#148472"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.20",
        "date": "June 25, 2025",
        "changes": [
            "Fixed a bug that could potentially cause a changefeed to complete erroneously when one of its watched tables encounters a schema change.#147039",
            "Fixed a bug that caused theSQL Activity>Statement Fingerprintpage to fail to load details for statements run with application names containing a#character.#147220",
            "Fixed a bug that could cause thecockroachprocess tosegfaultwhen collecting runtime execution traces (typically collected via theAdvanced Debugpage in the Console).#147338",
            "Fixed a bug that could cause stable expressions to be folded in cached query plans. The bug could cause stable expressions likecurrent_settingto return the wrong result if used in a prepared statement. The bug was introduced in v23.2.22, v24.1.14, v24.3.9, v25.1.2, and the v25.2 alpha.#147457",
            "Fixed a bug where prepared statements on schema changes could fail with runtime errors.#147668",
            "Fixed a bug whereALTER TABLEwas modifying identity attributes on columns not backed by a sequence.#147771",
            "TTL jobs now respond to cluster topology changes by restarting and rebalancing across available nodes.#147213"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.2",
        "date": "July 2, 2024",
        "changes": [
            "Added error messages for unsupported Apache Pulsarchangefeedsink parameters, e.g.topic_prefix is not yet supported.#124666",
            "Fixed a bug that was present since v22.2 wherechangefeedswith long-runninginitial scansmight incorrectly restore checkpoint job progress and drop events duringchangefeed restartsdue to transient errors or node restarts. The bug was most likely to occur in clusters with the following contributing factors:Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled.The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.There were multiple target tables with significant differences in row counts in one changefeed.The changefeed target tables were large with many ranges.The initial scan took a long time to complete (an hour or longer).#124996",
            "Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled.",
            "The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.",
            "There were multiple target tables with significant differences in row counts in one changefeed.",
            "The changefeed target tables were large with many ranges.",
            "The initial scan took a long time to complete (an hour or longer).#124996",
            "Improveddisk usage metric reportingover volumes that dynamically change their size over the life of thecockroachprocess.#125050",
            "The default values for the followingcluster settingswere updated from100000to7500. These settings control the maximum number offingerprints(distinct combinations of statements andtransactions) CockroachDB can store in memory, with stats being flushed on a10mintervalby default. You can increase these settings if your workload produces more unique fingerprints than this amount within the flush interval, and you notice that SQL stats are missing.cockroachdb/cockroach#125554sql.metrics.max_mem_stmt_fingerprintssql.metrics.max_mem_txn_fingerprints",
            "sql.metrics.max_mem_stmt_fingerprints",
            "sql.metrics.max_mem_txn_fingerprints",
            "The favicon now renders properly forDB Console, along with other image files.#122706",
            "SHOW TYPESnow includesuser-defined composite types. It had omitted those types ever since composite types were added in v23.1.#124817",
            "Fixed a crash introduced in v24.1.0-beta.2 that could occur when planningstatisticscollection on a table with avirtual computed columnusing auser-defined typewhen thecluster settingsql.stats.virtual_computed_columns.enabled(introduced in v24.1.0-alpha.1) was set totrue.#124996",
            "Fixed handling in thedeclarative schema changerwhen columns are included in theSTORING()clause of aCREATE INDEXstatement. CockroachDB now checks if the column is virtual up-front, and properly detects when a column is already handled by an existingINDEXwhen the column name has UTF-8 characters.#125153",
            "Fixed a bug where a change to auser-defined typecould cause queries against tables using that type to fail with an error message like:\"histogram.go:694: span must be fully contained in the bucket\". The change to the user-defined type could come directly from anALTER TYPEstatement, or indirectly from anALTER DATABASE ... ADD REGIONorDROP REGIONstatement (which implicitly changes thecrdb_internal_regiontype). This bug had existed since UDTs were introduced in v20.2.#124810",
            "Fixed a bug wheretelemetry logshad the samestatement fingerprintID for different SQL statements.#125000",
            "Fixed an issue whereadding a columnwith a default value of an emptyarraywould not succeed.#125325",
            "ALTER TABLE ... ADD CONSTRAINT UNIQUEwill now fail with a well-formed error message and code42601if a statement tries to add aunique constrainton an expression.#125417",
            "Fixed a bug where thepublicschemawould be created with the wrong owner. Previously theadminrolewould own thepublicschema. Now, the database owner is also the owner of thepublicschema. The owner can be altered after the schema is created.#125533",
            "Fixed a bug in v24.1, v23.2, and v23.1 where using thechangefeed.aggregator.flush_jittercluster settingwith themin_checkpoint_frequencyoption set to0could cause panics.#125459",
            "The log message\"expiration of liveness record ... is not greater than expiration of the previous lease ... after liveness heartbeat\"is no longer generated.#125449",
            "Fixed a bug introduced in v23.2.0 in which CockroachDB would hit an internal error when evaluatingINSERTsintoREGIONAL BY ROWtables where the source was aVALUESclause with a single row and at least one boolean expression.#126209",
            "Improved the efficiency of error handling in thevectorized execution engineto reduce the CPU overhead of statement timeout handling and reduce the potential for more statement timeouts.#124996",
            "Someprivilegechecks when scanning thecrdb_internal.system_jobsinternal table now happen once before the scan, instead of once for each row. This improves performance for queries that read fromcrdb_internal.system_jobs.#125250",
            "Achangefeedoptimization to reduce duplicates during aggregator restarts has been disabled due to poor performance.#124996"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.19",
        "date": "May 28, 2025",
        "changes": [
            "Changed the default value of the cluster settingadmission.l0_file_count_overload_thresholdto4000.#145920",
            "Schema insights that recommend replacing an index were previously a two-statement command consisting of aCREATE INDEXand aDROP INDEXstatement. When these two DDL statements were run as a single batched command, it was possible for one statement to succeed and one to fail. This is because DDL statements do not have the same atomicity guarantees as other SQL statements in CockroachDB. Index-replacement insights are now a singleCREATE INDEXstatement followed by a comment with additional DDL statements to be run manually: anALTER INDEX ... NOT VISIBLEstatement, which makes the old index invisible to the optimizer, followed by aDROP INDEXstatement that should only be run after making the old index invisible and verifying that workload performance is satisfactory.#145987",
            "Fixed a bug where CockroachDB could encounter acannot specify timestamp older than ...error during table statistics collection in some cases (e.g., when the cluster is overloaded). The bug was present since v19.1.#144519",
            "Fixed a bug in the DB Console where tables with page size dropdowns failed to update when a new page size option was selected. Tables now update correctly.#144768",
            "Fixed the following bugs in theSchedulespage of the DB Console:Fixed a bug where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.Fixed a bug where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144804",
            "Fixed a bug where theSchedulespage displayed only a subset of a cluster's schedules. TheSchedulespage now correctly displays all schedules.",
            "Fixed a bug where manually updating theshoworstatusparameters in the URL (e.g.,http://127.0.0.1:8080/#/schedules?status=ACTIVE&show=50) caused theSchedulespage to fail to load.#144804",
            "Fixed a bug in theSQL Activity Statementspage where filtering byStatement Typereturned no results. The filter now works as expected.#144853",
            "Improved the performance ofSHOW CREATE TABLEon multi-region databases with large numbers of objects.#145077",
            "Fixed a bug that could lead to schema changes hanging after a cluster recovered from availability issues.#145542",
            "Previously, on a table with multiple column families, CockroachDB could encounter aNon-nullable column \":\" with no valueerror in rare cases during table statistics collection. The bug was present since v19.2 and is now fixed.#145577",
            "Fixed a bug where orphaned leases were not properly cleaned up.#146111",
            "Fixed an internal assertion failure that could occur during operations likeALTER TYPEorALTER DATABASE ... ADD REGIONwhen temporary tables were present.#146199",
            "Fixed a bug that could cause queries that perform work in parallel to ignore the requested quality-of-service level. Affected operations include lookup joins, DistSQL execution, and foreign-key checks.#146310",
            "Fixed a bug that preventedTRUNCATEfrom succeeding if any indexes on the table had back-reference dependencies, such as from a view or function referencing the index.#146323\\",
            "Fixed a rare corruption bug that impacts import and materialized views.#144660"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.18",
        "date": "April 30, 2025",
        "changes": [
            "EXPLAIN ANALYZEstatements now display the number of transaction retries and time spent retrying, if non-zero, in the plan output.#142931",
            "Added theWITH IGNORE_FOREIGN_KEYSoption toSHOW CREATE TABLEwhich omits foreign key constraints from the output schema. This option is also allowed inSHOW CREATE VIEW, but has no effect. It cannot be combined with theWITH REDACToption.#142164",
            "Fixed a rare corruption bug that impacts import and materialized views.#144689",
            "Fixed a bug that caused changefeeds to fail on startup when scanning a single key.#143148",
            "Fixed a bug in the client certificate expiration metricssecurity.certificate.expiration.clientandsecurity.certificate.ttl.client.#142915",
            "Fixed a bug in v24.1.14, v24.3.7, v24.3.8, and v25.1 that could cause a nil-pointer error when a column's default expression contained a volatile expression (likenextval) as a UDF argument.#143638",
            "MVCC garbage collection is now fully subject to IO admission control. Previously, it was possible for MVCC GC to cause store overload (such as LSM inversion) when a large amount of data would become eligible for garbage collection. Should any issues arise from subjecting MVCC GC to admission control, thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting can be set tofalseto restore the previous behavior.#143275",
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144035",
            "Fixed a bug where CockroachDB would encounter an internal error when decoding the gists of plans withCALLstatements. The bug had been present since v23.2.#143313",
            "Fixed a bug where calling a stored procedure could drop the procedure if it hadOUTparameters that were not used by the calling routine. This bug had existed since PL/pgSQLCALLstatements were introduced in v24.1.#143288",
            "Previously, the fieldsmaximum memory usageandmax sql temp disk usagein theEXPLAIN ANALYZEoutput could be under-reported for distributed plans when memory-intensive operations were fully performed on the remote nodes. This is now fixed. The bug existed in v22.1 and later.#143792"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.17",
        "date": "April 28, 2025",
        "changes": [
            "Fixed a rare corruption bug that impacts import and materialized views.#144660"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.16",
        "date": "April 9, 2025",
        "changes": [
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144061"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.15",
        "date": "April 3, 2025",
        "changes": [
            "Added thesql.statement_timeout.countmetric to track the number of SQL statements that fail due to exceeding the statement timeout.#142157",
            "Added thesql.transaction_timeout.countmetric to track the number of SQL statements that fail due to exceeding the transaction timeout.#142157",
            "Thenode decommissionCLI command now waits until the target node is fully drained before marking it as decommissioned. Previously, the command would start draining but not wait, leaving the node in an unstable state where it could still accept client requests while being unable to communicate with the cluster, causing those requests to hang or fail with unexpected errors.#142427",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a \"batch timestamp must be after replica GC threshold\" error.#141723",
            "Fixed a bug that could cause gateway nodes to panic when performing anUPSERTon a table with aBOOLprimary key column and a partial index using the primary key column as the predicate expression.#141824",
            "Fixed a bug whereCREATE SEQUENCEwithout concurrent DDL operations could hit a retry error due to incorrect schema modification.#142609",
            "Fixed a bug where CockroachDB could incorrectly evaluate casts to some OID types (e.g.,REGCLASS). This issue had been present since at least v22.1.#141959",
            "Fixed a bug that could causenil pointer dereferenceerrors when executing statements with user-defined functions (UDFs) or certain built-in functions likeobj_description.#141651",
            "Fixed a bug where nodes drained during decommissioning could interrupt active SQL connections unexpectedly, even when drain was expected to wait for them to complete.#142816",
            "Fixed a bug where the fraction completed and internal checkpoints during an index backfill operation would stop being written if any periodic fraction/checkpoint write failed. Progress is now additionally logged to aid debugging. This bug affected schema changes such as creating an index or adding a non-nullable column.#141786",
            "Fixed a bug that could preventSHOW CREATE TABLEfrom working if a database was offline (e.g., due to aRESTORE).#141510",
            "Fixed a bug where tuple labels were sometimes disregarded, causing unexpected behavior, such as when converting a tuple toJSONwithto_jsonb. This bug existed since v22.1.0 and became more likely to cause issues after changes in v24.1.7.#142137",
            "Fixed a bug where the declarative schema changer allowedCREATE SEQUENCEoperations to proceed even while aDROP SCHEMAorDROP DATABASEwas in progress. Such operations now retry if the parent object has a schema change in progress.#142761",
            "Fixed a bug inv24.1.14,v24.3.7,v24.3.8, andv25.1that could cause a nil-pointer error when a column's default expression contained a volatile expression (likenextval) as a UDF argument.#143637",
            "Configuring thesql.ttl.default_delete_rate_limitcluster setting now displays a notice clarifying that the TTL rate limit is per leaseholder per table, with a link to the documentation.#142832"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.14",
        "date": "March 6, 2025",
        "changes": [
            "Since v23.2, table statistics histograms have been collected for non-indexedJSONBcolumns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#140142",
            "Added support for a new index hint,AVOID_FULL_SCAN, which will prevent the optimizer from planning a full scan for the specified table if any other plan is possible. The hint can be used in the same way as other existing index hints. For example,SELECT * FROM table_name@{AVOID_FULL_SCAN};. This hint is similar toNO_FULL_SCAN, but will not error if a full scan cannot be avoided. Note that normally a full scan of a partial index would not be considered a \"full scan\" for the purposes of theNO_FULL_SCANandAVOID_FULL_SCANhints, but if the user has explicitly forced the partial index viaFORCE_INDEX=index_name, we do consider it a full scan.#140259",
            "Added theoptimizer_prefer_bounded_cardinalitysession setting, which instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default.#140259",
            "Added theoptimizer_min_row_countsession setting, which sets a lower bound on row count estimates for relational expressions during query planning. A value of0, which is the default, indicates no lower bound. Note that if this is set to a value greater than 0, a row count of zero can still be estimated for expressions with a cardinality of zero, e.g., for a contradictory filter. Setting this to a value higher than0, such as1, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate.#140259",
            "Fixed a bug existing only in pre-release versions of v25.1 which could cause unexpected errors during planning forVALUESexpressions containing function calls with multiple overloads.#140648",
            "Added theoptimizer_check_input_min_row_countsession setting to control the minimum row count estimate for buffer scans of foreign key and uniqueness checks. It defaults to0.#141378",
            "Thechangefeed.max_behind_nanosmetric now supports scoping with metric labels.#139239",
            "Improved the performance of the debug zip query that collectstransaction_contention_eventsdata, reducing the chances of \"memory budget exceeded\" or \"query execution canceled due to statement timeout\" errors.#139752",
            "Fixed a bug that, under rare circumstances, could cause draining a node to fail with the error message \"some sessions did not respond to cancellation within 1s\".#139477",
            "Fixed a bug that prevented theCREATEstatement for a routine from being shown in a statement bundle. This happened when the routine was created on a schema other thanpublic. The bug had existed since v23.1.#136127",
            "Fixed a memory leak that could previously occur when evaluating some memory-intensive queries via the vectorized engine in CockroachDB. The leak had been present since v20.2.#139097",
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a \"batch timestamp must be after replica GC threshold\" error.#140086",
            "Removed duplicate columns in the Parquet output from changefeeds using CDC queries.#140151",
            "Fixed a rare bug in which a query might fail with the error \"could not find computed column expression for column in table\" while dropping a virtual computed column from the table. This bug was introduced in v23.2.4.#139873",
            "Fixed a bug that would cause an internal error when the result of aRECORD-returning user-defined function (UDF) was wrapped by another expression (such asCOALESCE) within aVALUESclause.#140648",
            "TheData Distributionreport on theAdvanced Debugpage will no longer crash if there are null values forraw_sql_configincrdb_internal.zones.#140659",
            "Upgraded the Sarama Kafka client library to pick up a fix for a race condition bug that could occur when Kafka throttling was enabled.#140157"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.13",
        "date": "February 19, 2025",
        "changes": [
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error.#141657"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.12",
        "date": "February 6, 2025",
        "changes": [
            "The protected timestamp records of running changefeeds are now updated when the set of targets changes, such as when system tables are added to the protected tables list.#138668",
            "Inv24.1.11, a bug was fixed that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error. This fix isnotpresent in v24.1.12, but has been released inv24.1.13.#140177",
            "Since v23.2 table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#140268",
            "Added support for a new index hint,AVOID_FULL_SCAN, which will prevent the optimizer from planning a full scan for the specified table if any other plan is possible. The hint can be used in the same way as other existing index hints. For example,SELECT * FROM table_name@{AVOID_FULL_SCAN};. This hint is similar toNO_FULL_SCAN, but will not error if a full scan cannot be avoided. Note that normally a full scan of a partial index would not be considered a \"full scan\" for the purposes of theNO_FULL_SCANandAVOID_FULL_SCANhints, but if the user has explicitly forced the partial index viaFORCE_INDEX=index_name, CockroachDB does consider it a full scan.#140272",
            "Added theoptimizer_prefer_bounded_cardinalitysession setting, which instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default.#140272",
            "Added theoptimizer_min_row_countsession setting, which sets a lower bound on row count estimates for relational expressions during query planning. A value of zero, which is the default, indicates no lower bound. Note that if this is set to a value greater than zero, a row count of zero can still be estimated for expressions with a cardinality of zero, e.g., for a contradictory filter. Setting this to a value higher than0, such as1, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate.#140272",
            "Added new metrics that expose the TTL for various certificates.#138659",
            "Introduced the metricsql.schema_changer.object_countthat keeps track of the count of objects in the cluster.#138839",
            "ALTER BACKUP SCHEDULEno longer fails on schedules with a collection URI that contains a space.#138080",
            "Previously,SHOW CREATE TABLEwas showing incorrect data with regards to inverted indexes. It now shows the correct data that can be repeatedly entered back into CockroachDB to recreate the same table.#138168",
            "Fixed a bug where querying thepg_catalog.pg_constrainttable while the schema changer was dropping a constraint could result in a query error.#138285",
            "Fixed a timing issue betweenALTER VIEW .. RENAMEandDROP VIEWthat caused repeated failures in theDROP VIEWjob.#137887",
            "Queries that perform a cast from the string representation of an array containingGEOMETRYorGEOGRAPHYtypes to a SQL array type will now succeed.#138693",
            "security.certificate.*metrics will now be updated if a node loads new certificates while running.#138659",
            "When the session variableallow_role_memberships_to_change_during_transactionis set, it is now possible to create and drop users quickly even when there are contending transactions on thesystem.usersandsystem.role_optionssystem tables.#139027",
            "Fixed a bug where the errorbatch timestamp ... must be after replica GC thresholdcould occur during a schema change backfill operation, and cause the schema change job to retry infinitely. Now this error is treated as permanent, and will cause the job to enter thefailedstate.#139248",
            "CockroachDB could previously hit a bounded memory leak when collecting table statistics on a table that had both very wide (10KiB or more) and relatively small (under 400B)BYTES-like values within the same row. This has been present since before v19.2. Additionally, in v24.1.0, a bug was introduced that made this leak also apply toSTRING-like values.#139174"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.11",
        "date": "January 31, 2025",
        "changes": [
            "Fixed a bug that could causeSHOW TABLESand other introspection operations to encounter a\"batch timestamp ... must be after replica GC threshold\"error.#140177"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.10",
        "date": "January 9, 2025",
        "changes": [
            "The cluster settingserver.jwt_authentication.issuersnow takes the issuer's configuration value apart from the URI.#138187This can be set to one of the following values:A string that Go can parse as a valid issuer URL, e.g.,'https://accounts.google.com'.A string that can be parsed as valid JSON array of issuer URLs, e.g.,['example.com/adfs','https://accounts.google.com'].A string that can be parsed as valid JSON and deserialized into a map of issuer URLs to corresponding JWKS URIs. In the third case, CockroachDB will override the JWKS URI present in the issuer's well-known endpoint, e.g.,'{ \"issuer_jwks_map\": { \"https://accounts.google.com\": \"https://www.googleapis.com/oauth2/v3/certs\", \"example.com/adfs\": \"https://example.com/adfs/discovery/keys\" }}'. Whenissuer_jwks_mapis set, CockroachDB directly uses the JWKS URI to get the key set. In all other cases whereJWKSAutoFetchEnabledis set, it obtains the JWKS URI first from the issuer's well-known endpoint and then uses this endpoint.",
            "This can be set to one of the following values:A string that Go can parse as a valid issuer URL, e.g.,'https://accounts.google.com'.A string that can be parsed as valid JSON array of issuer URLs, e.g.,['example.com/adfs','https://accounts.google.com'].A string that can be parsed as valid JSON and deserialized into a map of issuer URLs to corresponding JWKS URIs. In the third case, CockroachDB will override the JWKS URI present in the issuer's well-known endpoint, e.g.,'{ \"issuer_jwks_map\": { \"https://accounts.google.com\": \"https://www.googleapis.com/oauth2/v3/certs\", \"example.com/adfs\": \"https://example.com/adfs/discovery/keys\" }}'. Whenissuer_jwks_mapis set, CockroachDB directly uses the JWKS URI to get the key set. In all other cases whereJWKSAutoFetchEnabledis set, it obtains the JWKS URI first from the issuer's well-known endpoint and then uses this endpoint.",
            "A string that Go can parse as a valid issuer URL, e.g.,'https://accounts.google.com'.",
            "A string that can be parsed as valid JSON array of issuer URLs, e.g.,['example.com/adfs','https://accounts.google.com'].",
            "A string that can be parsed as valid JSON and deserialized into a map of issuer URLs to corresponding JWKS URIs. In the third case, CockroachDB will override the JWKS URI present in the issuer's well-known endpoint, e.g.,'{ \"issuer_jwks_map\": { \"https://accounts.google.com\": \"https://www.googleapis.com/oauth2/v3/certs\", \"example.com/adfs\": \"https://example.com/adfs/discovery/keys\" }}'. Whenissuer_jwks_mapis set, CockroachDB directly uses the JWKS URI to get the key set. In all other cases whereJWKSAutoFetchEnabledis set, it obtains the JWKS URI first from the issuer's well-known endpoint and then uses this endpoint.",
            "To improve the granularity of changefeed pipeline metrics, the changefeed metricschangefeed.admit_latencyandchangefeed.commit_latencyhave histogram buckets from5msto60m(previously500msto5m). The following changefeed metrics have histogram buckets from5msto10m(previously500msto5m):changefeed.parallel_io_queue_nanoschangefeed.parallel_io_result_queue_nanoschangefeed.sink_batch_hist_nanoschangefeed.flush_hist_nanoschangefeed.kafka_throttling_hist_nanos#136602",
            "changefeed.parallel_io_queue_nanos",
            "changefeed.parallel_io_result_queue_nanos",
            "changefeed.sink_batch_hist_nanos",
            "changefeed.flush_hist_nanos",
            "changefeed.kafka_throttling_hist_nanos#136602",
            "Added support for multiple seed brokers in the new Kafka sink.#136746",
            "Added a new metric (distsender.rangefeed.catchup_ranges_waiting_client_side) that counts how many rangefeeds are waiting on the client-side limiter to start performing catchup scans.#136836",
            "Added changefeed support for themvcc_timestampoption with theavroformat. If both options are specified, the Avro schema includes anmvcc_timestampmetadata field and emits the row's MVCC timestamp with the row data.#136017#137594",
            "Added a no-opAWS_USE_PATH_STYLEparameter for forward compatibility with v24.3.#137100",
            "Added thelegacy_varchar_typingsession setting, which reverts the changes of#133037that caused the change in typing behavior described in#137837. Specifically, it makes type-checking and overload resolution ignore the newly added \"unpreferred\" overloads. This setting defaults toon.#137921",
            "Removed thesql.auth.resolve_membership_single_scan.enabledcluster setting. This was added out of precaution in case it was necessary to revert back to the old behavior for looking up role memberships, but this escape hatch has never been needed in practice since this was added in v23.1.#136121",
            "Telemetry delivery is now considered successful even in cases where CockroachDB experiences a network timeout. This will prevent throttling in cases outside an operator's control.#136478",
            "When a schema change job is completed, rolls back, or encounters a failure, the time taken since the job began is now logged in a structured log in theSQL_SCHEMAlog channel.#136951",
            "Fixed a bug whereALTER COLUMN SET NOT NULLwas not enforced consistently when the table was created in the same transaction.#136364",
            "Fixed a bug whereCREATE RELATION / TYPEcould leave dangling namespace entries if the schema was concurrently being dropped.#136408",
            "Theidle_in_session_timeoutsetting now excludes the time spent waiting for schema changer jobs to complete, preventing unintended session termination during schema change operations.#136503",
            "Fixed a bug that caused the optimizer to use stale table statistics after altering anENUMtype used in the table.#136831",
            "Table statistics collection in CockroachDB could previously run intono bytes in account to releaseerrors in some edge cases (when the SQL memory budget, configured via--max-sql-memoryflag, was close to being exhausted). The bug had been present since v21.2 and is now fixed.#136164",
            "CockroachDB now better respects thestatement_timeoutlimit on queries involving the top K sort and merge join operations.#136651",
            "Fixed an issue where license enforcement was not consistently disabled for single-node clusters started withcockroach start-single-node. The fix ensures proper behavior on cluster restarts.#137010",
            "Fixed a bug that caused queries against tables with user-defined types to sometimes fail with errors after restoring those tables.#137355",
            "Fixed a bug that caused an incorrect filesystem to be logged as part of the store information.#137112",
            "Fixed a bug that had existed since v24.1 that would cause a set-returning UDF withOUTparameters to return a single row.#137378",
            "Fixed a bug that could cause an internal error if a table with an implicit (rowid) primary key was locked from within a subquery, e.g.:SELECT * FROM (SELECT * FROM foo WHERE x = 2) FOR UPDATE;. The error could occur either underREAD COMMITTEDisolation, or withoptimizer_use_lock_op_for_serializableenabled.#131397",
            "Fixed an issue where adding an existing column with theIF NOT EXISTSoption could exit too early, skipping necessary handling of the abstract syntax tree (AST). This could lead to failure of theALTERstatement.#137677",
            "Fixed an issue where a schema change could incorrectly cause a changefeed to fail with an assertion error likereceived boundary timestamp ... of type ... before reaching existing boundary of type ....#137704",
            "Internal scans are now exempt from thesql.defaults.disallow_full_table_scans.enabledsetting, allowing index creation even when the cluster setting is active.#137722",
            "Using more than oneDECLAREstatement in the definition of a user-defined function (UDF) now correctly declares additional variables.#135739",
            "Fixed an issue where corrupted table statistics could cause thecockroachprocess to crash.#136040",
            "Fixed a bug that could cause the password for therootuser to be deleted while upgrading to v24.1. This bug only affected clusters that were initially created with v22.2 or earlier. The same bug could also cause thedefaultdbandpostgresdatabases to be recreated during the upgrade to v24.1 if they had been previously deleted.#136074",
            "CLOSE CURSORstatements are now allowed in read-only transactions, similar to PostgreSQL. The bug had been present since at least v23.1.#137790",
            "Improved the internal caching logic for role membership information. This reduces the latency impact of commands such asDROP ROLE,CREATE ROLE, andGRANT role TO user, which cause the role membership cache to be invalidated.#136121"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.1",
        "date": "June 14, 2024",
        "changes": [
            "Fixed a bug introduced in v22.2 where achangefeedwith a long-runninginitial scanmight incorrectly restore checkpoint job progress and drop events during achangefeed restartdue to transient errors or node restarts. The bug was most likely to occur in clusters with the following contributing factors:Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled (in clusters running v23.2 and later).The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.There were multiple target tables with significant differences in row counts in one changefeed.The changefeed target tables were large with many ranges.The initial scan took a long time to complete (an hour or longer).#123967",
            "Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled (in clusters running v23.2 and later).",
            "The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.",
            "There were multiple target tables with significant differences in row counts in one changefeed.",
            "The changefeed target tables were large with many ranges.",
            "The initial scan took a long time to complete (an hour or longer).#123967",
            "History retention jobs created upon completion ofcluster replicationno longer erroneously indicate that they failed when they expire.#124055",
            "Theoptimizercan now plan constrained scans over partial indexes in more cases, particularly on partial indexes with predicates referencingvirtual computed columns.#123468",
            "The storage parameterttl_delete_rate_limit, which determines the rate limit for deleting expired rows, is now set to100by default.#124354",
            "CockroachDB no longer limits precision when convertingspatial data typesto JSON.#124536",
            "Theoptimizer_push_offset_into_index_joinsession settinghas been added. When enabled, theoptimizerwill attempt to push offset expressions into index join expressions to produce more efficient query plans. The setting is enabled by default on v24.1 and later, and disabled on v23.2.#124490",
            "The default value of thesql.defaults.results_buffer.sizecluster settinghas been changed from 16KiB to 512KiB. This reduces the chance that clients usingREAD COMMITTEDtransactions will encounter errors that cannot automatically be retried within CockroachDB.#124633",
            "The default values for thecluster settingssql.metrics.max_mem_stmt_fingerprintsandsql.metrics.max_mem_txn_fingerprintshave been changed from100000to5000, thus lowering the default limits for in-memory statement and transaction fingerprints.#123430",
            "The newsql.pgwire.pipeline.countgauge metricshows the number of wire protocol commands that have been received by the server, but have not yet begun processing. This metric will only grow if clients are using the \"pipeline mode\" of the PostgreSQL wire protocol.#124256",
            "Theclient_authentication_okandclient_session_endmessages are now logged to theSESSIONSlog channelunconditionally. Previously, these would be logged only if theserver.auth_log.sql_sessions.enabledcluster settingwas set totrue. All otherSESSIONSlog messages are logged only ifserver.auth_log.sql_sessions.enabledorserver.auth_log.sql_connections.enabledare set totrue. To prevent logging ofclient_authentication_okorclient_session_endmessages, you can optionally disable theSESSIONSlog channel.#124369",
            "Fixed a bug where thereplication lag metricwould falsely report high lag for multi-node clusters and on cutover.#123585",
            "Fixed a bug that causedSQL Activityentries sorted by% of Runtimeto be sorted incorrectly.#123903",
            "The \"Admission Delay Rate\", \"Admission Work Rate\", and \"Requests Waiting For Flow Tokens\" time-series charts have been removed from the DB Console. These charts can be difficult to interpret and provide little value for overload investigations.#124509",
            "TheOverloaddashboardnow includes descriptions for all metrics.#124509",
            "Metrics on theOverloaddashboardhave been reordered to improve their categorization. The metrics are now roughly in the following order: 1. Metrics to help determine which resource is constrained (IO, CPU); 2. Metrics to narrow down whichadmission controlqueues are seeing requests waiting; 3. More advanced metrics about system health (goroutine scheduler, L0 sublevels, etc.).#124509",
            "New metricscr.store.storage.l0-sublevelsandcr.node.go.scheduler_latency-p99.9on theOverloaddashboardprovide better visibility into overloaded resources.#124509",
            "There are now four separate graphs for Admission Queue Delay: 1. Foreground (regular) CPU work; 2. Store (IO) work; 3. Background (elastic) CPU work; 4. Replication Admission Control (store overload on replicas).#124509",
            "Fixed a bug that would occur whenALTER TYPE ... DROP VALUEis followed byDROP SCHEMA CASCADE ...in the same transaction. Previously, theALTER TYPEschema change would get queued up to run at commit time, but by that point, the type may have already been removed, so the commit could fail.#123577",
            "Tables are now automatically repaired when the errorsinvalid inbound foreign key ... origin table ID should be ...orinvalid outbound foreign key ... reference table ID should be ...occur.#123668",
            "Fixed a bug where a failedRESTOREcould not be retried without manual intervention.#123205",
            "Fixed a bug introduced in alpha versions of v23.1 where calling a routine could result in an unexpectedfunction ... does not existerror. The bug is triggered when the routine is called twice using the exact same SQL query, and either: (a) the routine has polymorphic arguments, or: (b) between the two calls, the routine is replaced by a routine with the same name and different parameters.#123516",
            "Fixed a rare bug where a lease transfer could lead to aside-transport update saw closed timestamp regressionpanic. The bug could occur when a node was overloaded andfailing to heartbeat its node liveness record.#123533",
            "Fixed a crash introduced in v24.1.0-beta.2 that could occur when planning statistics collection on a table with avirtual computed columnusing auser-defined typewhen the newly-introducedcluster settingsql.stats.virtual_computed_columns.enabledis set totrue. (The setting was introduced in v24.1.0-alpha.1, and defaults totrue.)#124060",
            "Fixed a bug where anALTER TABLE ... ALTER PRIMARY KEYstatement could hang if the table had any indexes that were referred to byviewsorfunctionsusing theFORCE INDEXclause.#124323",
            "Fixed a bug introduced in v24.1.0 where themax_decimal_digitsargument of thest_geojsonbuiltin functionwas ignored and the default was used instead.#124502",
            "Scattering a range with a replication factor of 1 now no longer erroneously up-replicates the range to two replicas. Leases will also no longer thrash between nodes when perturbed with a replication factor of 1.#124453",
            "Fixed a bug where, if thettl_row_stats_poll_intervalstorage parameter was non-zero for a table withrow-level TTLenabled, the queries issued to update row statistics could block the job from completing. Now, if the job completes, these statistics queries are cancelled. This means that thejobs.row_level_ttl.total_rowsandjobs.row_level_ttl.total_expired_rowsmetrics will report0if the job finishes before the row stats queries complete.#124627",
            "Fixed a bug where aDROP ROLEorDROP USERcommand could leave references behind inside types, which could prevent subsequentSHOW GRANTScommands from working.#124619",
            "Fixed a bug where theresults_buffer_sizesession variablecould not be configured by using the \"options\" query parameter in the connection string, but only as a top-level query parameter. Now,results_buffer_sizecan be configured in either part of the connection string. This variable still cannot be changed with theSETcommand after the session begins.#124775",
            "Fixed a bug introduced in v20.2 where a change to auser-defined typecould cause queries against tables using that type to fail with an error message likehistogram.go:694: span must be fully contained in the bucket. The change to the user-defined type could come directly from anALTER TYPEstatement, or indirectly from anALTER DATABASE ... ADD REGIONorDROP REGIONstatement (which implicitly change thecrdb_internal_regiontype).#124856",
            "Improved the efficiency of error handling in thevectorized execution enginein order to reduce the CPU overhead of statement timeout handling and reduce the potential for more statement timeouts.#123499",
            "Due to its poor performance, achangefeedoptimization that aimed to reduce duplicates during aggregator restarts due to its bad performance has been disabled.#123595"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-rc.2",
        "date": "May 16, 2024",
        "changes": [
            "Fixed a bug that was present since v22.2 wherechangefeedswith long-runninginitial scansmight incorrectly restore checkpoint job progress and drop events duringchangefeed restartsdue to transient errors or node restarts. The bug was most likely to occur in clusters with the following contributing factors:Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled (in clusters running v23.2 and later).The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.There were multiple target tables with significant differences in row counts in one changefeed.The changefeed target tables were large with many ranges.The initial scan took a long time to complete (an hour or longer).#123968",
            "Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled (in clusters running v23.2 and later).",
            "The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.",
            "There were multiple target tables with significant differences in row counts in one changefeed.",
            "The changefeed target tables were large with many ranges.",
            "The initial scan took a long time to complete (an hour or longer).#123968",
            "Fixed a crash introduced in v24.1.0-beta.2 that could occur when planningstatistics collectionon a table with avirtual computed columnusing a user-defined type and thesql.stats.virtual_computed_columns.enabledcluster settingis set totrue.sql.stats.virtual_computed_columns.enabledwas introduced in v24.1.0-alpha.1 astrueby default and introduced in v23.2.5 asfalseby default.#124064"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-rc.1",
        "date": "May 8, 2024",
        "changes": [
            "Added a newsession settingoptimizer_use_improved_multi_column_selectivity_estimate, which if enabled, causes theoptimizerto use an improved selectivity estimate for multi-column predicates. This setting will default totrueon v24.2 and later, andfalseon earlier versions.#123106",
            "Added two newmetrics:range.snapshots.upreplication.rcvd-bytescounts the number ofRaftrecovery snapshot bytes received, andrange.snapshots.upreplication.sent-bytescounts the number of Raft recovery snapshot bytes sent. Also updatedrange.snapshots.recovery.rcvd-bytesandrange.snapshots.recovery.sent-bytesto only include Raft snapshots. A new line was added to theSnapshot Data Receivedgraph.#123055",
            "Added aReplication Laggraph to thePhysical Cluster Replicationdashboard to measure replication lag between primary and standby clusters usingphysical cluster replication.#123285",
            "Fixed a bug that caused theTablesandTable Detailspages in the DB Console to display an incorrect value forTable Stats Last Updated.#122816",
            "Fixed a bug in the DB Console'sCustom Charttool where store-level metrics were displayed only for the first store ID associated with the node. Now data is displayed for all stores present on a node, and a single time series is shown for each store, rather than an aggregated value for all of the node's stores. This allows finer-grained monitoring of store-level metrics.#122705",
            "Fixed a bug introduced in v22.2 that could cause the internal errorattempting to append refresh spans after the tracked timestamp has moved forwardin some edge cases.#123136",
            "Fixed a bug where aTYPEDESC SCHEMA CHANGEjob could retry forever if the descriptor it targeted was already dropped.#123273",
            "Fixed a bug where, if the legacy schema changer was enabled, theCREATE SEQUENCEcommand would incorrectly require the user to have theCREATEprivilegeon the parent database rather than only on the parent schema.#123289",
            "Fixed a bug where ajobwould fail if it reported an out-of-bound progress fraction. The error is now logged and no longer causes the job to fail.#122965",
            "Added a newsession settingoptimizer_use_improved_zigzag_join_costing. When enabled and when thecluster settingenable_zigzag_joinis also enabled, the cost of zigzag joins is updated such that a zigzag join will be chosen over a scan only if it produces fewer rows than a scan.#123106",
            "Improved the selectivity estimation of multi-column filters when the multi-column distinct count is high. This prevents theoptimizerfrom choosing a bad query plan due to over-estimating the selectivity of a multi-column predicate.#123106",
            "Improved the efficiency of error handling in thevectorized execution engine, to reduce the CPU overhead of statement timeout handling and reduce the potential for more statement timeouts.#123501",
            "Disabled a poorly-performingchangefeedoptimization that was intended to reduce duplicates during aggregator restarts.#123597"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-beta.3",
        "date": "April 30, 2024",
        "changes": [
            "Updated theSHOW GRANTSresponses to display theobject_typeandobject_name, which has replaced therelation_namecolumn.#122823",
            "Addedexternal connectiongranted privileges to theSHOW GRANTScommand.#122823",
            "Introduced three newcluster settingsfor controlling table statistics forecasting:sql.stats.forecasts.min_observationsis the minimum number of observed statistics required to produce a forecast.sql.stats.forecasts.min_goodness_of_fitis the minimum R (goodness of fit) measurement required from all predictive models to use a forecast.sql.stats.forecasts.max_decreaseis the most a prediction can decrease, expressed as the minimum ratio of the prediction to the lowest prior observation.#122459",
            "sql.stats.forecasts.min_observationsis the minimum number of observed statistics required to produce a forecast.",
            "sql.stats.forecasts.min_goodness_of_fitis the minimum R (goodness of fit) measurement required from all predictive models to use a forecast.",
            "sql.stats.forecasts.max_decreaseis the most a prediction can decrease, expressed as the minimum ratio of the prediction to the lowest prior observation.#122459",
            "Fixed a bug that could lead to descriptors having privileges to roles that no longer exist. Added an automated clean up fordropped rolesinside descriptors.#122701",
            "Fixed a bug whereclient certificate authenticationcombined withidentity maps(server.identity_map.configuration) did not work since v23.1. For the feature to work correctly, the client must specify a valid db user in theconnection string.#122738",
            "Fixed a bug where therow-based execution enginecould drop aLIMITclause when there was anORDER BYclause, and the ordering was partially provided by an input operator. For example, this bug could occur with an ordering such asORDER BY a, bwhen the scanned index was only ordered on columna. The impact of this bug was that more rows may have been returned than specified by theLIMITclause. This bug is only present when not using thevectorized execution engine. That is, when running withSET vectorize = off;. This bug has existed since CockroachDB v22.1.#122837",
            "Previously, CockroachDB could run into an internal error when evaluatingPL/pgSQLroutines with nested blocks. The bug is only present in 24.1.0-beta versions. This bug is now fixed.#122939",
            "Fixed a bug whereUPDATEandUPSERTqueries with a subquery were sometimes inappropriately using implicitFOR UPDATElocking within the subquery. This bug has existed since implicitFOR UPDATElocking was introduced in v20.1.#121391",
            "Droppingandaddinga column with the same name no longer results in a\"column already exists error\".#122631",
            "Fixed a bug that could cause an internal error of the forminvalid datum type given: ..., expected ...when aRECORD-returninguser-defined function, used as a data source, was supplied a column definition list with mismatched types. This bug has existed since v23.1.#122305",
            "Fixed a bug that could result in an internal error when attempting to create aPL/pgSQLroutine using the (unsupported)%ROWTYPEsyntax for a variable declaration. Now, an expected syntax error is returned instead.#122966",
            "Fixed a bug that could result in an assertion error during evaluation ofPL/pgSQLroutines that invoke procedures while usingDEFAULTarguments. The bug was present in v24.1.0-beta releases and is now fixed.#122943",
            "Previously, privileges granted forexternal connectionswere displaying inSHOW SYSTEM GRANTSwith no associated object name. Now these privileges are no longer displayed. Instead, the statementSHOW GRANTS ON EXTERNAL CONNECTIONshould be used to view external connection privileges with their associated object name.#122857",
            "Statistics forecasts of zero rows can cause suboptimalquery plans. Forecasting will now avoid predicting zero rows for most downward-trending statistics.#122459",
            "Fixed a bug introduced in v23.2 that could cause aPL/pgSQLvariable assignment to not be executed if the variable was never referenced after the assignment.#123045",
            "More efficientquery plansare now generated for queries with text similarity filters, for example,text_col % 'foobar'. These plans are generated if theoptimizer_use_trigram_similarity_optimizationsession settingis enabled. It is disabled by default.#122838",
            "Theoptimizernow costsdistinct-onoperators more accurately. It may produce more efficient query plans in some cases.#122850",
            "Improved the speed for optimization of some statements usingGROUP BYorDISTINCTorON CONFLICTby skipping theoptimizerruleSplitGroupByScanIntoUnionScanswhen it is not needed.#123034"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-beta.2",
        "date": "April 24, 2024",
        "changes": [
            "Added thecluster settingsecurity.client_cert.subject_required.enabledthat enforces a mandatory requirement for the client certificate's role subject to be set. The subject can be defined through either the subject role option or by specifying theroot-cert-distinguished-nameandnode-cert-distinguished-nameproperties. This setting applies to both RPC access and login via authCert.#122368",
            "Fixed a bug where table statistics were sometimes not collected on tables that have virtualcomputed columnsof a user-defined type when thesql.stats.virtual_computed_columns.enabledcluster setting is enabled. The setting was introduced in v23.2.4 and is disabled by default. Only clusters running v23.2.4 with the non-default setting are affected.#122320"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-beta.1",
        "date": "April 17, 2024",
        "changes": [
            "SHOW JOBSno longer displays some internal retry counter columns (last_run,next_run,num_runs) and now only shows thestatement,trace_id, andexecution_errorscolumns when inspecting a specific job ID or IDs.#121286",
            "SHOW JOBSnow shortens long job descriptions to 100 characters to make the table easier to read while the full description and statement can be inspected usingSHOW JOBorSHOW JOBSon specific job IDs.#121286",
            "Extendedpg_dependto include dependencies between UDFs.#121313",
            "Withsql_safe_updatesset totrue,SELECT FOR UPDATEandSELECT FOR SHAREstatements now return an error if they do not contain either aWHEREclause or aLIMITclause. Also,UPDATEandDELETEstatements withoutWHEREclauses but withLIMITclauses now bypasssql_safe_updates, which better matches MySQL behavior.#121466",
            "Added support forPL/pgSQLCALLstatements. It is now possible to call a stored procedure from a PL/pgSQL routine.#121743",
            "DEFAULTexpressions for input parameters ofuser-defined functionsand stored procedures are now supported.#121811",
            "The--enterprise-encryptionflag now accepts the special valuepath=*to apply the specified keys to all stores.#121111",
            "TheCommit Latencychart in theChangefeedsdashboardnow aggregates by max instead of by sum for multi-nodechangefeeds. This more accurately reflects the amount of time for events to be acknowledged by the downstream sink.#120787",
            "Introduced a license expiration message in theDB Consolein the top-right corner of the primary header. This message indicates the remaining days before license expiration for clusters with an Enterprise or trial license.#120830",
            "TheJobstablepage no longer includes two columns related to a deprecated internal implementation detail (last execution time and execution count).#121286",
            "The timeseries graphs shown on theSQL Activitystatement details page in the DB Console will now render properly, after fixing a bug related to setting the time range of the charts.#121461",
            "Index recommendationsin the DB Console will now function properly for indexes on tables or columns whose names contain quotation marks or whitespace. For example:CREATE INDEX ON \"my table\" (\"my col\");.#122120",
            "Sequence options forNO MINVALUEandNO MAXVALUEnow match PostgreSQL behavior. SequenceMINVALUEandMAXVALUEautomatically adjust to new types bounds mirroring behavior of PostgreSQL.#121310",
            "CockroachDB could previously \"leak\" reported memory usage as accounted by the internal memory accounting system, the limit for which is configured with the--max-sql-memoryflag, on long-running sessions that issue many (hundreds of thousands or more) transactions. This, in turn, could result in\"root: memory budget exceeded\"errors for other queries. This bug was present in versions v23.1.17 and v23.2.3 and is now fixed.#121873",
            "CockroachDB could previously incorrectly evaluateINexpressions that hadINT2orINT4type on the left side and values outside of the range of the left side on the right side. The bug has been present since at least v21.1 and is now fixed.#121954",
            "Fixed a slow memory leak in the deprecatedPub/Sub changefeeds, which can accumulate when restarting or canceling many deprecated Pub/Sub changefeeds. The bug had been present since the deprecated Pub/Sub changefeed was introduced in a testing release of v22.1.#121867"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-alpha.5",
        "date": "April 1, 2024",
        "changes": [
            "Changefeedsnow default to evenly distributing their work across all replicas, including followers, regardless of leaseholder placement. On upgrade to v24.1, running changefeed jobs will be restarted automatically as part of the upgrade process and will default to distributing work across replicas. To disable this behavior, set thecluster settingchangefeed.random_replica_selection.enabledtofalse. If disabled, changefeed planning reverts to its previous behavior for distributing work.#120077",
            "Whenphysical cluster replicationis enabled, the output of theSHOW VIRTUAL CLUSTER ... WITH REPLICATION STATUScommand now displays replication lag.#120782",
            "Whenphysical cluster replicationis enabled, the output of theSHOW VIRTUAL CLUSTER WITH REPLICATION STATUS to 1command has changed:The output no longer displaysreplication_job_idorservice_modereturn fields.Thedata_statefield has been renamed tostatus.The fields that are displayed are now ordered as follows:retained_time,replicated_time,replication_lag,cutover_time,status.#120782",
            "The output no longer displaysreplication_job_idorservice_modereturn fields.",
            "Thedata_statefield has been renamed tostatus.",
            "The fields that are displayed are now ordered as follows:retained_time,replicated_time,replication_lag,cutover_time,status.#120782",
            "You can now runphysical cluster replicationfrom anexisting CockroachDB cluster, withoutcluster virtualizationenabled, to a standby cluster with cluster virtualization enabled.#122001",
            "You can now specify a condition for thePL/pgSQL statementsEXITandCONTINUE.#120686",
            "Astored procedurecan now invoke another stored procedure using aCALLstatement.#120674",
            "You can now use aSET TRANSACTIONstatement within aPL/pgSQL stored procedureto configure the transaction isolation level, timestamp, or priority, or to set the transaction to read-only. ASET TRANSACTIONstatement must immediately follow aCOMMITorROLLBACK, with no other statements or block boundaries between them.#120456",
            "The newsession variableoptimizer_use_virtual_computed_column_stats, when enabled, configures thecost-based optimizerto usetable statisticson virtual computed columns.#120668",
            "Anidentity columncan now drop theIDENTITYconstraint and related sequence using the following SQL statement:icon/buttons/copyALTERTABLE{table_name}ALTERCOLUMN{column_name}DROPIDENTITY[IFEXISTS];IF EXISTSis optional, and skips the command if the column is not an identity column.#119263",
            "A shared lock that is acquired explicitly usingSELECT FOR SHAREor implicitly by aread-committed transaction, can now be re-acquired with higher strength by either using aSELECT FOR UPDATEstatement or by writing to the key.#119671",
            "Stored proceduresnow supportOUTandINOUTparameter classes.#120851",
            "ThePL/pgSQLEXITandCONTINUEstatements can now use labels to specify which loop or block is the target.#120733",
            "You can now enable asynchronous buffering offile-grouplog sinksusing thebufferingconfiguration optionseither by default or to an individualfile-group. Thebufferingconfiguration option is incompatible with thebuffered-writesconfiguration option. To try thebufferingoption, you must setbuffered-writes: false. Cockroach Labs recommends settingmax-stalenessto1sandflush-trigger-sizeto256KiB.#120428",
            "A minimumRaft schedulerconcurrency is now enforced per store so that nodes with many stores do not spread workers too thin. This helps to avoid high scheduler latency across replicas on a store when load is imbalanced.#120162",
            "The newmetricskv.split.estimated_statsandkv.split.total_bytes_estimatestrack the number of splits that produceMVCCstatistic estimates and the total bytes of estimates produced.#119894",
            "The newcluster settingstorage.sstable.compression_algorithmconfigures the compression algorithm used when compressing sstable blocks.#120784",
            "The newcluster settingkv.dist_sender.proxy.enabled, which is enabled by default, causes proxy requests to be routed through a follower replica when the leaseholder is unavailable.#117340",
            "The new startup flag--wal-failoverallows you to explicitly set the path for WAL failover of a single-store node.#120783",
            "Cluster virtualization is now enabled using either of the new startup flags--virtualizedor--virtualized-emptyinstead of the--config-profileflag.#120813",
            "The following metrics, which track the SQL statistics subsystem's task to flush in-memory statistics to persisted storage, are now more consistent with other metrics used in the subsystem.sql.stats.flushes.successful: Number of times SQL statistics have been flushed successfully to persistent storage.sql.stats.flushes.failed: Number of attempted SQL statistics flushes that failed with errors.sql.stats.flush.latency: The latency of attempted SQL statistics flushes to persistent storage, including both successes and failures.#120709",
            "sql.stats.flushes.successful: Number of times SQL statistics have been flushed successfully to persistent storage.",
            "sql.stats.flushes.failed: Number of attempted SQL statistics flushes that failed with errors.",
            "sql.stats.flush.latency: The latency of attempted SQL statistics flushes to persistent storage, including both successes and failures.#120709",
            "The following newmetricstrack the number and outcome of proxy requests whenkv.dist_sender.proxy.enabledis set totrue:distsender.rpc.proxy.sentdistsender.rpc.proxy.errdistsender.rpc.proxy.forward.sentdistsender.rpc.proxy.forward.errCockroach Labs recommends monitoring and alerting ondistsender.rpc.proxy.sent, because it indicates a possible network partition.#120239",
            "distsender.rpc.proxy.sent",
            "distsender.rpc.proxy.err",
            "distsender.rpc.proxy.forward.sent",
            "distsender.rpc.proxy.forward.err",
            "Theprovisioned-ratefield of a node's store specification can no longer be used to add constraints for the disk name or bandwidth. By default, bandwidth is constrained according to thecluster settingkv.store.admission.provisioned_bandwidth. To override this setting for a specific node, the storage specification must containprovisioned-rate=bandwidth={bandwidth-bytes/s}.#120895",
            "Removal of thecluster settingkv.rangefeed.scheduler.enabled, which was announced inv24.1.0-alpha.1, has been reverted, and the cluster setting is reinstated.#121164",
            "In generated statement fingerprints in the DB ConsoleStatementspage, lists with only literals or placeholders or similar subexpressions are shortened to their first item followed by \"more\".#120507",
            "Fixed a bug introduced in v23.2 that could cause aPL/pgSQLroutine to return incorrect results when the routine included:At least one parameter.AnIFstatement with one leak-proof branch and one branch with side effects.#120451",
            "At least one parameter.",
            "AnIFstatement with one leak-proof branch and one branch with side effects.#120451",
            "Fixed a rare bug where aBACKUPcommand issued shortly after anALTER TABLE {table_name} SET (exclude_data_from_backup = true)could exclude data from an unrelated table from the backup.#120188",
            "Fixed a behavior where a memory exhaustion error during a schema change was treated as a permanent failure and reverted. Such schema changes are now retried instead of reverted.#120806",
            "Fixed a bug where theattnamefor a dropped column was not correctly padded with 8.characters to be compatible with PostgreSQL.#120861",
            "Splits no longer hold latches for time proportional to the range size while computing MVCC statistics. Instead, MVCC statistics are pre-computed before the critical section of the split. As a side effect, the resulting statistics are no longer 100% accurate because they may correctly distribute writes concurrent with the split. To mitigate against this potential inaccuracy, and to prevent the statistics from drifting after successive splits, the existing stored statistics are re-computed and corrected if needed during the non-critical section of the split.#119894",
            "Thecost-based optimizernow generates more efficient query plans for some queries withOFFSETclauses.#121160",
            "Andrew Delph"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-alpha.4",
        "date": "March 25, 2024",
        "changes": [
            "Whenconfiguring logs,file-permissionsare now applied literally, such thatfile-permissions: 644will result in files with permissions matching644(instead of the previous behavior's640). Previously, CockroachDB'sumask(which is always at least007) was being applied after thefile-permissionsfield was used to create files, meaning the resulting permissions did not match those specified in the log configuration.#120669",
            "The followingmetricswere added for observability of per-store disk events:storage.disk.read.countstorage.disk.read.bytesstorage.disk.read.timestorage.disk.write.countstorage.disk.write.bytesstorage.disk.write.timestorage.disk.io.timestorage.disk.weightedio.timestorage.disk.iopsinprogressThe metrics match the definitions of thesys.host.disk.*system metrics.#119885",
            "storage.disk.read.count",
            "storage.disk.read.bytes",
            "storage.disk.read.time",
            "storage.disk.write.count",
            "storage.disk.write.bytes",
            "storage.disk.write.time",
            "storage.disk.io.time",
            "storage.disk.weightedio.time",
            "storage.disk.iopsinprogress",
            "server.controller.default_target_clustercan now be set to any virtual cluster name by default, including a virtual cluster yet to be created or have service started.#120080",
            "TheREAD COMMITTEDisolation level now requires the cluster to have a valid enterprise license.#120154",
            "The new boolean changefeed optionignore_disable_changefeed_replication, when set totrue, prevents the changefeed from filtering events even if CDC filtering is configured via thedisable_changefeed_replicationsession variable,sql.ttl.changefeed_replication.disabledcluster setting, or thettl_disable_changefeed_replicationtable storage parameter.#120255",
            "Added support for thePL/pgSQLCOMMITandROLLBACKstatements.#119647",
            "Identity columnsnow support enhanced sequence management through theALTER [COLUMN] column_name SET sequence_optionandALTER [COLUMN] column_name RESTART [WITH restart]commands. This update facilitates the fine-tuning of identity column sequences.#119432",
            "It is now possible to use theSTRICToption withSELECT ... INTOandRETURNING ... INTOin order to enforce that a SQL statement within aPL/pgSQLroutine returns exactly one row.#120486",
            "Added asession settingplpgsql_use_strict_into, which causes PL/pgSQLSELECT ... INTOandRETURNING ... INTOto require exactly one row from the SQL statement, similar to Oracle behavior.#120486",
            "Added a newfailure_count INT NOT NULLcolumn tocrdb_internal.node_statement_statistics. It represents the number of recorded statement execution failures for the given statement, as a new component of the overall statistics.#120236",
            "TheFORCE_INVERTED_INDEXhint causes theoptimizerto prefer a query plan scan over any inverted index of the hinted table. An error is emitted if no such query plan can be generated.#120384",
            "TheREPAIRCLUSTERMETADATAprivilege has been aliased toREPAIRCLUSTER. Both names can be used interchangeably.#116844",
            "The newcockroach startoption--wal-failover=among-storesorCOCKROACH_WAL_FAILOVER=among-storesenvironment variable will configure a multi-store CockroachDB node to fail over a store's write-ahead log (WAL) to another store's data directory. Failing over the write-ahead log may allow some operations against a store to continue completing, even if the underlying storage is temporarily unavailable. This feature is inpreview.#120509",
            "The newstorage.wal_failover.unhealthy_op_thresholdcluster settingallows configuring the latency threshold at which a WAL write is considered unhealthy.#120509",
            "Two new metrics track the status of the SQL Activity Update job, which pre-aggregates top K information within the SQL statistics subsytem and writes the results tosystem.statement_activityandsystem.transaction_activity:sql.stats.activity.updates.successful: Number of successful updates made by the SQL activity updater job.sql.stats.activity.update.latency: The latency of updates made by the SQL activity updater job. Includes failed update attempts.#120522",
            "sql.stats.activity.updates.successful: Number of successful updates made by the SQL activity updater job.",
            "sql.stats.activity.update.latency: The latency of updates made by the SQL activity updater job. Includes failed update attempts.#120522",
            "Added a new counter metric,sql.stats.flush.done_signals.ignored, that tracks the number of times the SQL activity update job has ignored the signal that indicates that a flush has completed. This metric may indicate that the SQL activity update job is taking longer than expected to complete.#120522",
            "Added a new counter metric,sql.stats.activity.updates.failed, to measure the number of update attempts made by the SQL activity update job that failed with errors.#120522",
            "Added a new counter metric,sql.stats.flush.fingerprint.count, that tracks the number of unique statement and transaction fingerprints included in the SQL stats flush.#120522",
            "The/_status/storesendpoint now includesnode_id,dir, andwal_failover_pathfields to show the store's node ID, data directory, and path to the configured WAL failover secondary, if configured.#120677",
            "The new--go-gc-percentflag of thecockroach startcommand controls the garbage collection target percentage of the Go runtime, mirroring the existingGOGCenvironment variable. A garbage collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. If left unspecified and if a Go soft memory limit is configured (i.e., not explicitly disabled via--max-go-memoryorGOMEMLIMIT), the garbage collection target percentage defaults to 300%. Setting the flag to a negative value disables the target percentage garbage collection heuristic, and only the soft memory limit heuristic triggers garbage collection. To monitor the impact of this change in the DB Console, look for an increase inMemory usagein theHardware dashboardand an increase inGo total memory usagein theRuntime dashboard. This does not increase the risk of an out-of-memory exception (OOM), because the Go memory limit (controlled by the--max-go-memoryflag or theGOMEMLIMITenvironment variable) prevents Go from consuming too much memory.#119605",
            "TheQueuesdashboardnow includes lease queue metrics.#119386",
            "The DB ConsoleSQL ActivityStatement Fingerprintpage has replaced theFailed?boolean column with aFailure Countcolumn that shows the number of failed executions for the given statement fingerprint.In theSQL Activitytable, the same statement fingeprint no longer appears in separate rows for failed executions and successful executions. Instead, they are combined into a single statement fingerprint.#120236",
            "The DB Console now displays an alert message when a license has expired or will expire in fewer than 15 days.#120490",
            "Fixed a bug withDROP SCHEMA ... CASCADEthat could lead to dangling function references in other schemas accessing any functions.#119932",
            "Fixed a bug where aRESTOREof a backup that itself contained a table created by theRESTOREof a table with an in-progressIMPORT INTOwould fail to restore all rows.#120414",
            "Fixed a bug whereidentity columnswithout any configured sequence options did not display the default values for identity attributes ininformation_schema.#119459",
            "Fixed a bug where aGRANT ... ON ALL TABLESstatement could fail if sequences existed and they did not support a privilege (e.g.,BACKUP).#120685",
            "Fixed a bug where anEXPLAIN (DDL)statement would generate event log entries for schema changes that were not executed.#120563"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-alpha.3",
        "date": "March 18, 2024",
        "changes": [
            "cockroach gen encryption-keynow accepts a--version=2parameter. Version 2 keys activate a new encryption implementation with improved performance. This is expected to become the default in CockroachDB v24.2.#119913",
            "Mutation statements such asUPDATEandDELETEas well as locking statements such asSELECT FOR UPDATEare not allowed in read-only transactions orAS OF SYSTEM TIMEtransactions. This fixes an oversight where CockroachDB was allowing mutation statements and locking statements in implicit single-statement transactions usingAS OF SYSTEM TIME.#120097",
            "Added support forRETURNstatements with no expression for routines withOUTparameters and routines with aVOIDreturn type.#120043",
            "ALTER COLUMNcan now change columns to an identity column by using the syntax in one of the following:icon/buttons/copyALTERTABLEtALTERCOLUMNcADDGENERATEDALWAYSASIDENTITY[(<opt_sequence_option_list>)]ALTERTABLEtALTERCOLUMNcADDGENERATEDBYDEFAULTASIDENTITY[(<opt_sequence_option_list>)]Identity columns can have their identity type altered by using the syntax in one of the following statements:icon/buttons/copyALTERTABLEtALTERCOLUMNcSETGENERATEDALWAYSALTERTABLEtALTERCOLUMNcSETGENERATEDBYDEFAULT#115889",
            "Added support for thePL/pgSQLNULLstatement.#119037",
            "crdb_internal.leasesis now behind theVIEWCLUSTERMETADATAprivilege.#120014",
            "PL/pgSQLblocks can now be nested in a block that has an exception handler.#120045",
            "Resolved an issue where clusters with multiple stores per node may list inaccurate region/node information in theDatabasespage.#119260",
            "VIEWtype tables will no longer display in the DB ConsoleDatabasespages. Previously these would be listed with no information, only displaying errors.#119890",
            "Fixed an intermittent page crash in theSchema Insightstab.#120137",
            "Fixed a bug where theRows writtenvalue was incorrectly showing theRows readvalue on theInsightspage.#120145",
            "Fixed a bug that occurred when usingALTER TABLEto drop and re-add aCHECKconstraintwith the same name.#120008",
            "Fixed a bug in which it was possible toSET transaction_read_only = falseduring anAS OF SYSTEM TIMEtransaction.#120097",
            "Fixed a bug that caused a slow memory leak that could accumulate when opening many new connections. The bug was present in v22.2.9+ and v23.1+ versions.#119799",
            "Andrew Delph"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-alpha.2",
        "date": "March 11, 2024",
        "changes": [
            "DB Consolesessioncookie is now markedHttpOnlyto prevent it from being read by any JavaScript code.#119261",
            "DB Consolecookies are now markedSecurefor the browser when the cluster is running in secure mode.#119261",
            "Gatewayswill now detect faulty or stalledreplicasand use other replicas instead, which can prevent them getting stuck in certain cases (e.g., withdisk stalls). This behavior can be disabled via thecluster settingkv.dist_sender.circuit_breaker.enabled.#118943",
            "Added a newALTER ROLE ... SUBJECToption. This role option can be set to a subject distinguished name inRFC 2253orRFC 4514format. If set, then during client certificate authentication, certs that do not match the configured distinguished name will be rejected.#119135",
            "Changefeedssupport a new schemeazure-event-hub://for Kafka data streaming to Azure event hubs. ThesinkURLmust include mandatory parametersshared_access_key_nameandshared_access_key. By default and as required, the optionstls_enabled=true,sasl_handshake=true,sasl_enabled=true, andsasl_mechanism=PLAINare applied, as they are the only supported options. Other parameters such astopic_nameandtopic_prefixare also supported. An example URI is:azure-event-hub://myeventhubs.servicebus.windows.net:9093?shared_access_key_name=abc&shared_access_key=123.#115806",
            "Added an option for node-levelsequencecaching. All the sessions on the node can share the same cache, which can be concurrently accessed. Theserial_normalizationsession variablecan now be set to the valuesql_sequence_cached_node. If this value is set, thecluster settingsql.defaults.serial_sequences_cache_sizecan be used to control the number of values to cache in a node, with a default of 256. ThePER NODE CACHEsequence option (syntax is[ [ PER NODE ] CACHE # ]) is now fully implemented and will allow nodes to cache sequence numbers. A cache size of 1 means there is no cache, and cache sizes of less than 1 are not valid.#118546",
            "Fixed a bug that prevented the use ofPL/pgSQLroutines with complex variable names that require double quotes. This bug had existed since v23.2.#119034",
            "Fixed a bug that could cause creation of a syntactically invalidPL/pgSQLroutine to return the wrong error. This bug had existed since v23.2.#119034",
            "Fixed a bug that could result in a syntax error if aPL/pgSQLroutine was created with an escaped string constant in the routine body. This bug had existed since v23.2.#119034",
            "Fixed a bug where running achangefeedthat targets a table with a user-defined type column and with theenvelopeoptionset to any value other thanwrappedwould cause a node panic due to a nil dereference.#119639",
            "Fixed a bug where runningRESTOREon certain backups would open a very large number of connections to the backup storage provider.#119840",
            "Previously, a user with theVIEWACTIVITYREDACTEDprivilegecould see constants inside of queries that originated from otherusersin theSHOW SESSIONSoutput. This information is now properly redacted.#119820",
            "Previously, theSHOW QUERIESandSHOW STATEMENTScommands incorrectly required the user to have theVIEWACTIVITYorVIEWACTIVITYREDACTEDprivilege. This is now fixed, as a user should always be able to view their own queries, even without this privilege.#119820"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0-alpha.1",
        "date": "March 7, 2024",
        "changes": [
            "AS OF SYSTEM TIMEqueries can no longer use a timestamp followed by a question mark to signify a future-time value. This was an undocumented syntax.#116830",
            "ALTER CHANGEFEEDno longer removes aCDC querywhen modifying changefeed properties.#116498",
            "changefeed.balance_range_distribution.enableis now deprecated. Instead, use the newcluster settingchangefeed.default_range_distribution_strategy.changefeed.default_range_distribution_strategy='balanced_simple'has the same effect as settingchangefeed.balance_range_distribution.enable=true. It does not requireinitial_scan='only', which was required by the old setting.#115166",
            "CDC queries now correctly handle thechangefeed_creation_timestampfunction.#117520",
            "The new syntaxALTER VIRTUAL CLUSTER virtual-cluster START REPLICATION OF virtual-cluster ON physical-clustercan now be used to reconfigure virtual clusters previously serving as sources forphysical cluster replicationto become standbys to a promoted standby. This reverses the direction of replication while maximizing data reuse.#117656",
            "BACKUPs now load range information that is used to avoid a spike in metadata lookups when backups begin.#116520",
            "Clusters created to runphysical cluster replicationno longer automatically disable thespanconfig.range_coalescing.system.enabledandspanconfig.range_coalescing.application.enabledcluster settings. Users who started using physical cluster replication on v23.1 or v23.2 may wish to manually reset these settings.#119221",
            "Physical cluster replication is now always enabled, and thephysical_replication.enabledcluster setting has been removed.#119149",
            "ALTER BACKUP SCHEDULE ... EXECUTE IMMEDIATELYcan now be used to set the next scheduled execution of the backup schedule to the current time.#112118",
            "Fixed theSQL Activityupdate job to avoid conflicts on update, reduced the amount of data cached to just what the overview page requires, and fixed the correctess of the top queries.#112350",
            "Previously, user-defined composite types were not populated in twopg_catalogtables:pg_class(whose row entries pertain to the type) andpg_attribute(whose row entries pertain to the \"columns\" of the type). This PostgreSQL-incompatible behavior is now fixed by populating the tables with user-defined composite types. In addition, thetyprelidcolumn in thepg_typetable has the properoidfor composite types.#111179",
            "The newly addedbuilt-in functionjsonb_array_to_string_arrayno longer removesNULLobjects. It now includes them in the resulting array.#112975",
            "Changed the display for RU estimates shown inEXPLAIN ANALYZEfrom integer to float. This will prevent small estimates from being rounded to zero, which makes the estimate less confusing for cheap queries.#111986",
            "Theinformation_schema._pg_char_octet_lengthbuilt-in functionis now supported, which improves compatibility with PostgreSQL.#111401",
            "Thepg_encoding_max_lengthbuilt-in functionis now supported, which improves compatibility with PostgreSQL.#111401",
            "Theinformation_schema._pg_datetime_precisionbuilt-in functionis now supported, which improves compatibility with PostgreSQL.#111401",
            "Theinformation_schema._pg_interval_typebuilt-in functionis now supported, which improves compatibility with PostgreSQL.#111401",
            "information_schema.user_defined_typesis now populated with information aboutuser-defined types, andinformation_schema.attributesis now populated with information about the attributes ofcomposite data types.#111401",
            "Thecost-based optimizerwill no longer generate a constrained scan that only uses filters from acheckconstraint. This prevents cases where a constrained scan actually scans the entire table because the constraints aren't selective.#114332",
            "Reads rolled back by savepoints are now refreshable, matching the PostgreSQL behavior and avoiding potential serializability violations.#111424",
            "Implemented the postgisST_TileEnvelopebuilt-in function.#112971",
            "Added support for a third argument in thearray_positionbuilt-in function. If provided, it gives the index from which to begin searching in the array.#112161",
            "Added thebit_countbuilt-in functionforBITandBYTEStypes.#115273",
            "Added apg_backend_pidcolumn tocrdb_internal.node_sessionsandcrdb_internal.cluster_sessions. This value corresponds to the numerical ID returned frompg_backend_pid.#116673",
            "Column type changes now require an explicit cast when automatic casting is not possible. This aligns with PostgreSQL's behavior. Previously, certain type conversions, such asBOOLtoINT, were allowed without an explicit cast.#115442",
            "Added a newsession setting,optimizer_merge_joins_enabledthat, when true, instructs thecost-based optimizerto explore query plans with merge joins. The setting defaults totrue.#116410",
            "CockroachDB now supports parsing queries likeSELECT FROM tthat only produce the row count and do not output any columns.#116835",
            "Added themetaphonebuilt-in function, which converts a string to its Metaphone code.#110950",
            "The newEXPIRATION WINDOWoption forALTER VIRTUAL CLUSTERallows the user to override the default producer job expiration window of 24 hours. For example,ALTER VIRTUAL CLUSTER appTenant SET REPLICATION EXPIRATION WINDOW ='100ms'. The producer job expiration window determines how long the producer job stays alive without a heartbeat from the consumer job.#117776",
            "TheSKIP LOCKEDclause is now allowed withSELECT ... FOR SHARE.#117560",
            "Added configurablecluster settingsfor total TCP keep alive probes (server.sql_tcp_keep_alive.count) and TCP probe intervals (server.sql_tcp_keep_alive.interval) for SQL connections. Removed theCOCKROACH_SQL_TCP_KEEP_ALIVEenvironment variable subsuming it.#115833",
            "Removed thesql.trace.session_eventlog.enabledcluster setting and the associated event log tracing. The information in these traces is still available in theDEVlog channelby enabling--vmodule=conn_executor=2withcockroach start.#117928",
            "Thearray_aggaggregate functioncan now support arrays as the input. Note that CockroachDB does not yet fully support nested arrays, andarray_aggdoes not support nested arrays as inputs.#117838",
            "An execution statistic that measures \"client time\" is now included inplan.txtfiles ofstatement diagnostics bundles. Client time tracks how long the query execution was blocked on the client receiving the PGWire protocol messages. Note that when obtained viaEXPLAIN ANALYZE (DEBUG), client time does not make sense because in this variant the output rows are discarded and not communicated to the client.#117591",
            "Added thetrace_idcolumn to the response of theSHOW SESSIONScommand.#118002",
            "Added support for theENCODINGoption ofCOPY, as long as the encoding of'utf8'is specified.#118010",
            "Added theSHOW VARIABLES FOR ROLEcommand, which allows the database administrator to easily view the default values forsession variablesapplied to a given user.#117875",
            "Thesql.txn.read_committed_isolation.enabledcluster settingis nowtrueby default. This means that any syntax and settings that configure theREAD COMMITTEDisolation level will now cause the transaction to use that isolation level, rather than automatically upgrading the transaction toSERIALIZABLE.#118479",
            "Added a newcluster setting,sql.stats.virtual_computed_columns.enabled, which when set enables collection of table statistics onVIRTUALcomputed columns.#118241",
            "Added theautocommit_before_ddlsession variable. When set totrue, any schema change statement that is sent during an explicit transaction will cause the transaction to commit before executing the schema change.#118440",
            "CREATE SEQUENCEis now enabled by default in the declarative schema changer.#117793",
            "PL/pgSQLnow supports nested blocks, with the following limitations: variable shadowing is disallowed, and exception handlers cannot be used in a routine with nested blocks.#117710",
            "Thecluster settingsql.index_recommendation.drop_unused_durationis now public.#118676",
            "It is now possible to hint to thecost-based optimizerthat it should plan a straight join by using the syntax... INNER STRAIGHT JOIN .... If the hint is provided, the optimizer will now fix the join order as given in the query, even if it estimates that a different plan using join reordering would have a lower cost.#116013",
            "Add columngoroutine_idto the response of theSHOW SESSIONScommand.#118644",
            "Introduced a newsession setting,close_cursors_at_commit, which causes a cursor to remain open even after its calling transaction commits. Note that transaction rollback still closes any cursor created in that transaction.#117910",
            "Added theserver.max_open_transactions_per_gatewaycluster setting. When set to a non-negative value, non-adminusers cannot execute a query if the number of transactions open on the current gateway node is already at the configured limit.#118781",
            "Added thesetseedbuilt-in function. It sets the seed for the random generator used by therandombuilt-in function.#119042",
            "OUTandINOUTparameter classes are now supported inuser-defined functions.#118610",
            "Out-of-process SQL servers will now start exporting a newsql.aggregated_livebytesmetric. This metric gets updated once every 60 seconds by default, and its update interval can be configured via thetenant_global_metrics_exporter_intervalcluster setting.#119140",
            "Added support for index hints withINSERTandUPSERTstatements. This allowsINSERT ... ON CONFLICTandUPSERTqueries to use index hints in the same way they are already supported forUPDATEandDELETEstatements.#119104",
            "Added a newttl_disable_changefeed_replicationtable storage parameter that can be used to disable changefeed replication forrow-level TTLon a per-table basis.#119611",
            "The internal versions that are reported duringcluster upgradeshave been renamed for clarity. For example,23.2-8is now named23.2-upgrading-to-24.1-step-008.#115223",
            "Introduced a new cluster setting,server.jwt_authentication.jwks_auto_fetch.enabled, enabling automatic fetching ofJSON Web Key Sets (JWKS)from an issuer's remote endpoint. This prevents an administrator's need to update the JWKS specified inserver.jwt_authentication.jwks- whether manually or by custom script - when the identity provider's keys rotate. That direct specification of JWKS remains the default, as the new cluster setting defaults tofalse.#117054",
            "Updated the error message logged in the case of stalled disks to use the appropriate term \"disk stall\", matching the term used in metrics and dashboards. This was previously \"file write stall\".#114746",
            "Introduced thechangefeed.emitted_batch_sizeshistogram metric that measures the batch sizes used when emitting data tosinks. This metric supportsmetrics labels.#115537",
            "Introduced metricslog_fluent_sink_conn_attempts,log_fluent_sink_write_attempts, andlog_fluent_sink_write_errorsto enable more precise tracking of connection and write operations whenlogging to Fluentd-compatible network collectors.#116699",
            "Thecluster settingsql.contention.record_serialization_conflicts.enabledis nowonby default. This means any40001errorsthat are returned containing conflicting transaction information will be recorded by the contention registry.#116664",
            "Removed thekv.rangefeed.scheduler.enabledcluster settingbecause therangefeedscheduler is now unconditionally enabled.#114410",
            "Removed thekv.rangefeed.catchup_scan_concurrencycluster setting. Catchup scans are throttled viakv.rangefeed.concurrent_catchup_iteratorson a per-node basis.#114408",
            "Removed thechangefeed.mux_rangefeed.enabledcluster setting because the functionality is enabled by default.#114408",
            "The gossip statusAdvanced Debug pagenow includes information about the server's high water timestamps for every other node it knows about in the gossip cluster.#117011",
            "Removed thecockroach_rangefeed_rpc_initial_window_sizeenvironment variable. The rangefeed connection now uses the same window size as other RPC connections.#117545",
            "Eventsforcluster settingchanges are now emitted to theOPSchannel rather than theDEVchannel.#117923",
            "The new environment variablecockroach_rpc_use_default_connection_classenables operators to switch back to the prior default behavior of sending most network/RPC workloads, except system traffic, through a single RPC/TCP connection, in case the environment does not tolerate multiple TCP connections. v24.1 defaults to using multiple connections, each dedicated to a particular types of traffic, specifically forRaftorrangefeeddata. For more information, see additional release notes that reference this variable name.#117810",
            "In unredacteddebug zips, thecrdb_internal.transaction_contention_eventstable file has two new columns:waiting_stmt_query: the query of the waiting statement.blocking_txn_queries_unordered: the unordered list of the blocking transaction's queries.#118478",
            "waiting_stmt_query: the query of the waiting statement.",
            "blocking_txn_queries_unordered: the unordered list of the blocking transaction's queries.#118478",
            "Transaction replay protection state is now passed between the outgoing and incomingleaseholderfor a range during alease transfer. This avoids cases where lease transfers can cause transactions to throwTransactionAbortedError(ABORT_REASON_NEW_LEASE_PREVENTS_TXN)errors.#118300",
            "CockroachDB will now automatically generateCPU profilesif there is an increase in CPU utilization. This can help inform investigations into possible issues.#118850",
            "Expanded the--include-range-infoflag to include problem ranges. This flag still defaults totrue.#119205",
            "Debug zipsno longer include redundanthex_columns for system tableBYTEScolumns.#112033",
            "Added the--follower-read-percentflag, which determines the percent (0-100) of read operations that are follower reads, to thecockroach workload kv runcommand.#113094",
            "The workloadschemachangenow writes a.otlp.ndjson.gzarchive containing OTLP trace bundles for debugging purposes.#114770",
            "cockroach debug tsdumpcreates atsdump.yamlfile. Thetsdumpraw format automatically creates the YAML file in the default location/tmp/tsdump.yaml. Added a new flag--yamlthat allows users to specify the path to createtsdump.yamlinstead of using the default location. For example,cockroach debug tsdump --host <host>:<port> \\ --format raw --yaml=/some_path/tsdump.yaml > /some_path/tsdump.gob.#114046",
            "Removed thecockroach connectcommand functionality. This wasdeprecatedin CockroachDB v23.2.#113893",
            "Changed the SQL shell help URL to point tocockroach-sql.#118960",
            "Added a newencode-uriutility to make generating connection strings for use withPhysical Cluster Replicationeasier.#119528",
            "Store initialization now logs progress every 10 seconds showing the current and total number ofreplicasinitialized.#115760",
            "Introduced a newLease Preferencesgraph on theReplication dashboard. TheLease Preferencesgraph will indicate when the currentleaseholderis not the first lease preference and where the current leaseholder satisfies no applied lease preference.#116709",
            "Updated theStatement Details pageto always show the entire selected period, instead of just the period that had data.#118680",
            "Error messages displayed upon failure to load DB Console views now include information about the HTTP response status code, if one is present.#118782",
            "TheFull Table/Index Scanschart in theSQL Metrics dashboardnow shows the non-negative derivative of the number of full scans tracked.#118787",
            "TheOverload dashboardnow includes two additional graphs:Elastic CPU Utilization: displays the CPU utilization by elastic work, compared to the limit set for elastic work.Elastic CPU Exhausted Duration Per Second: displays the duration of CPU exhaustion by elastic work, in microseconds.#118763",
            "Elastic CPU Utilization: displays the CPU utilization by elastic work, compared to the limit set for elastic work.",
            "Elastic CPU Exhausted Duration Per Second: displays the duration of CPU exhaustion by elastic work, in microseconds.#118763",
            "Thetxn.restarts.writetoooldmetric in theTransaction Restartsgraph under theSQL Dashboardnow includes all restarts previously categorized astxn.restarts.writetoooldmulti. The former is a now a superset of the latter. Thetxn.restarts.writetoooldmultimetric will be removed in a future release.#119411",
            "Fixed a bug that could cause an internal error during distributed execution for an expression likeCASEthat requires its inputs to be the same type with allNULLinputs.#108892",
            "FixedNULLinput handling for the geospatialbuilt-insst_pointfromgeohashandst_geomfromgeohash.#113781",
            "The geospatialst_makeenvelopebuilt-innow correctly supportsxminoryminto be greater thanxmaxorymax, respectively.#113781",
            "Fixed a bug that could cause v23.1 nodes in clusters that had notfinalized the v23.1 version upgradeto use excessive CPU retrying expected errors related to the incomplete upgrade state.#113864",
            "Debug zipnow does not fail on corrupted log files.#113722",
            "Placeholder arguments can now be used inSET TRANSACTIONstatements.#113689",
            "Previously, when the session variableuse_declarative_schema_changerwas set tooff,ALTER PRIMARY KEYwould delete any comments associated with the old primary index and old primary key constraint. This is inconsistent with the behavior ofuse_declarative_schema_changer=on, which is the default setting, where those comments would be carried over to the new primary index. Furthermore, the old behavior also caused a bug that could prevent commandSHOW CREATE tfrom working.#114354",
            "Previously, when the session variable was set touse_declarative_schema_changer=offand there was an attempt toALTER PRIMARY KEYon a table that has unique secondary indexes on new primary key columns, the unique secondary index would still incorrectly have old primary key columns as itskeySuffixColumnafter theALTER PRIMARY KEY. This was problematic because a subsequent dropping of the old primary key columns would unexpectedly drop those unique secondary indexes as well, even withoutCASCADE.#114622",
            "ALTER BACKUP SCHEDULEcan now be used to setupdates_cluster_last_backup_time_metricwithout providing an explicit value, matching the behavior of the option when specified duringCREATE SCHEDULE FOR BACKUP.#113523",
            "Previously, if a table hadsecondary indexesthat stored certain columns (col) using theSTORINGclause, followed by anALTER PRIMARY KEYtocol, an incorrect secondary index would persist. The secondary index would continue to have theSTORINGclause, despite the column being part of the primary key and the fact that CockroachDB does not permit secondary indexes to store any primary key columns. Now, after theALTER PRIMARY KEY, theSTORINGclause is dropped on those secondary indexes.#115214",
            "Fixed a bug that caused uploads toobject-locked bucketsto fail because of the absence of anMD5hash.#115713",
            "ALTER PRIMARY KEYnow preserves the name of the original primary index when the session variable isuse_declarative_schema_changer=off.#115338",
            "Fixed a bug where theunique-without-index-not-validconstraintadded to a table would cause thecreate_statementfromSHOW CREATE tto not be executable and error withunique constraint cannot be NOT VALID.#115354",
            "Fixed a bug where an emptyfull backupfollowed by non-empty incremental backups taken inside an application tenant might not allow arestoredue to the use of an incorrect SQL codec.#116316",
            "Fixed a bug in therow-level TTLjob that would cause it to skip expired rows if the primary key of the table included columns of the collatedSTRINGorDECIMALtype.#116988",
            "Incorrectly labeledPL/pgSQLblocks now return an expected syntax error.#117608",
            "CREATE EXTERNAL CONNECTION IF NOT EXISTSno longer returns an error if the connection already exists.#117312",
            "CockroachDB now correctly uses the histograms on columns of collatedSTRINGtype. The bug has been present since before v22.1.#117714",
            "Improved an interaction during rangelease transfersthat could causeRETRY_ASYNC_WRITE_FAILUREerrors to be returned to clients.#117840",
            "Backfilling tables forCREATE TABLE ASorCREATE MATERIALIZED VIEWcould get into a retry loop if data was deleted and those jobs took longer than the GC TTL.#117877",
            "Decommissioning replicasthat are part of a mis-replicated range will no longer get stuck on a rebalance operation that was falsely determined to be unsafe.#117900",
            "A memory leak within the insights system was found to occur whensql.metrics.transaction_details.enabledwas disabled, while leavingsql.metrics.statement_details.enabledenabled. This patch fixes the memory leak by preventing the collection of further statement and transaction insights whensql.metrics.transaction_details.enabledis disabled.#117709",
            "Fixed a rare panic that could happen during apg_dumpimport that contains a function that has a subquery in one of its arguments, likeSELECT addgeometrycolumn(...). Now, attempting to import apg_dumpwith such a function results in an expected error.#118569",
            "AUTO CREATE STATSjobs could previously lead to growth in an internal system table resulting in slower job-system related queries.#118589",
            "Fixed an issue in CockroachDB where, if operating on a Linux system outside of a CPU cgroup, the system would repeatedly log the errorunable to get CPU capacityat 10-second intervals.#118657",
            "Fixed a bug where casts offloatstointegerssimply truncated the decimal portion. These casts now match the PostgreSQL behavior of rounding to the nearest integer, and in cases of a value halfway between two integers, rounding to the nearest even number. This aligns with the \"round half to even\" rule or \"bankers' rounding\", offering greater overall precision across a group of such cast operations.#117798",
            "Fixed a bug where statements likeADD COLUMN j INT, ADD UNIQUE WITHOUT INDEX (j), whichadd new columnswith unique constraints without creating associated indexes, would fail with an internal error.#118291",
            "Previously,alteringfrom aREGIONAL BY ROWtable to aREGIONAL BY TABLEtable could cause leaseholders to never move to the database's primary region. This is now fixed.#118001",
            "Users with theVIEWACTIVITYprivilege can now request statement bundles usingcrdb_internal.request_statement_bundleor through the DB ConsoleSQL Activitypage.#118760",
            "Fixed an internal error with a message like:LeafTxn ... incompatible with locking requestthat occurs when performing an update underREAD COMMITTEDisolationwhich cascades to a table with multiple other foreign keys.#118722",
            "Fixed a bug whereALTER PRIMARY KEYcould fail with an errornon-nullable column <x> with no value! Index scanned ..when validating recreatedsecondary indexes.#118843",
            "Fixed a bug where a sequence name allocated bySERIALthat conflicted with an existing type name would cause an error.#118861",
            "Fixed a bug whereCOMMENT ONstatements could fail with an \"unexpected value\" error if multipleCOMMENTstatements were running concurrently.#119007",
            "Previously, in certain cases, using virtual tables such ascrdb_internal.system_jobscould result in the internal errorattempting to append refresh spans after the tracked timestamp has moved forward. This is now fixed. The bug was introduced in CockroachDB v23.1.#119176",
            "Fixed a bug where operations on thecrdb_internal.leasestable could cause a node to become unavailable due to a deadlock in the leasing subsystem.#119305",
            "If an individualreplica's circuit breaker had tripped but the range was otherwise functional, for example, because the replica was partially partitioned away from theleaseholder, it was possible for a gateway to persistently error when contacting this replica instead of retrying against a functional leaseholder elsewhere. Thegatewaywill now retry such errors against other replicas once.#118737",
            "Fixed a bug in changefeedwebhook sinkswhere the HTTP request body may not be initialized on retries, resulting in the errorhttp: ContentLength=... with Body length 0.#119326",
            "Fixed a bug where rangefeed resolved timestamps could get stuck, continually emitting the log messagepushing old intents failed: range barrier failed, range split, typically following arange merge.#119512",
            "Fixed a condition where some files were not closed when inspecting backup metadata during BACKUP and RESTORE. Epic: none.#119625",
            "Fixed a bug where some backup metadata files opened duringRESTOREwere not closed.#119625",
            "Fixed a bug that caused internal errors when executing anEXPORTstatement where the query involved sorting by columns not explicitly included in the output, due to hidden columns in the input expression.#119538",
            "Fixed a bug where a warning about the need to refresh data would remain displayed on the Active Executions view of theStatementsandTransactionspages despite enablingAuto Refresh.#118675",
            "Follower readsfor multi-region tables now default to prioritizing replicas in the samelocality, when available, with node latency as a tie breaker. Previously, latency was the primary criteria. This can improve the performance and predictability of follower reads.#112993",
            "During node startup, stores are now loaded in parallel by default, reducing start times for nodes with many stores.#115285",
            "Improved the efficiency and performance ofencryption at rest.#115454",
            "Rangefeeds, the infrastructure used forchangefeeds, now use a more efficient engine that reduces the number of goroutines and the associated Go scheduler pressure and latency.#114410",
            "Rangefeeds, the infrastructure used forchangefeeds, now use a more efficient multiplexing protocol.#114408",
            "Thecost-based optimizernow generates constrained scans on indexes containing boolean, computed expressions.#114798",
            "A separate RPC connection class is now used for mostRafttraffic. This improves isolation and reduces interference with foreground SQL traffic, which reduces chances of head-of-line blocking caused by unrelated traffic under high-load conditions. The newCOCKROACH_RAFT_USE_DEFAULT_CONNECTION_CLASSenvironment variable can be set to use the default connection class instead (the previous behavior).#117385",
            "Rangefeed traffic (typically forchangefeeds) is now separated into its own RPC connection class. This improves isolation and reduces interference with the foreground SQL traffic, which reduces chances of head-of-line blocking caused by unrelated traffic. The newCOCKROACH_RANGEFEED_USE_DEFAULT_CONNECTION_CLASSenvironment variable can be set to use the default connection class, the previous default choice for rangefeeds.#117730",
            "The initial scan traffic forchangefeeds, which can be significant, now uses a different RPC/TCP connection than the foreground SQL/KV traffic. This reduces interference between workloads, and reduces chances of head-of-line blocking issues.#117810",
            "kafka_sink_confignow supports specifying different client IDs for each changefeed, enabling users to define distinct Kafka quota configurations for each. For example,CREATE CHANGEFEED FOR ... WITH kafka_sink_config='{\"ClientID\": \"clientID1\"}'#118643",
            "Added thechangefeed.kafka_throttling_hist_nanosmetric, enhancing visibility into throttling times when CockroachDB operations exceed Kafka's quota limits.#117693",
            "Thecost-based optimizernow generates more efficient query plans for queries with comparisons oftimestampandintervalcolumns, for example,timestamp_col - '1 day'::INTERVAL > now().#118307",
            "Statements from internal executors (use of SQL queries by the cluster itself) now correctly display when filtering by application name$ internalon the Statements page inSQL Activity. Such statements are hidden when$ internalis not specified.#114498",
            "Andrew Delph (first-time contributor)",
            "ChanYe East (first-time contributor)",
            "Charles (first-time contributor)",
            "Harshit Vishwakarma (first-time contributor)",
            "Jasmine Sun (first-time contributor)",
            "Joshua Hildred (first-time contributor)",
            "Kevin Mingtarja (first-time contributor)",
            "Luis Pessoa (first-time contributor)",
            "Nikolai Vladimirov (first-time contributor)",
            "chavacava (first-time contributor)",
            "da-ket (first-time contributor)",
            "lyang24 (first-time contributor)",
            "zach.graves (first-time contributor)",
            "zyf123123 (first-time contributor)",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "24.1",
        "patch_version": "24.1.0",
        "date": "May 20, 2024",
        "changes": [
            "Feature categoriesPerformanceChange data captureRecoverySecurityMigrationsSQLOperationsObservability",
            "Performance",
            "Change data capture",
            "Observability",
            "Additional informationBackward-incompatible changesDeprecationsFeatures that require upgrade finalizationKnown limitationsAdditional resources",
            "Backward-incompatible changes",
            "Deprecations",
            "Features that require upgrade finalization",
            "Known limitations",
            "Additional resources",
            "You run your own Certificate Authority (CA) infrastructure.",
            "You need to use your existing CA infrastructure to manage SQL user authentication.",
            "You need to use the same CA for multiple CockroachDB clusters.",
            "OUT and INOUTparameters can be specified.",
            "PL/pgSQLEXIT and CONTINUE statementscan be used together with conditions.",
            "UDFs cancall other UDFs.",
            "Stored procedures caninvoke other stored proceduresusing aPL/pgSQL CALL statement.",
            "Transaction control within PL/pgSQL blocksis possible using COMMIT, ROLLBACK, and SET TRANSACTION statements.",
            "AS OF SYSTEM TIMEqueries can no longer use a timestamp followed by a question mark to signify a future-time value. This was an undocumented syntax.#116830",
            "TheREAD COMMITTEDisolation level now requires the cluster to have a validenterprise license. Otherwise, transactions which are configured to run asREAD COMMITTEDwill be upgraded toSERIALIZABLE, as described in the next note.#120154",
            "Thesql.txn.read_committed_isolation.enabledcluster settingis nowtrueby default. As a result for enterprise users,READ COMMITTEDtransactions arenotautomatically upgraded toSERIALIZABLE, and will run asREAD COMMITTEDby default. On v23.2, refer to theUpgrades of SQL Transaction Isolation Levelgraph in the DB Console to check whether any transaction is being upgraded from a weaker isolation level toSERIALIZABLE, and could therefore run differently on v24.1.#118479",
            "Splitsno longer holdlatchesfor time proportional to the range size while computingMVCCstatistics. Instead, MVCC statistics are pre-computed before the critical section of the split. As a side effect, the resulting statistics are no longer 100% accurate because they may correctly distribute writes concurrent with the split. To mitigate against this potential inaccuracy, and to prevent the statistics from drifting after successive splits, the existing stored statistics are re-computed and corrected if needed during the non-critical section of the split.#119894",
            "sql.txn.read_committed_isolation.enabledis nowtrueby default. When set totrue, transactions use theREAD COMMITTEDisolation level if specified byBEGIN/SETcommands.If the cluster setting isfalse, as was the default in v23.2, suchREAD COMMITTEDtransactions will instead run asSERIALIZABLE.To check whether any transactions are being upgraded toSERIALIZABLE, see theUpgrades of SQL Transaction Isolation Levelgraph in the DB Console.\"",
            "If the cluster setting isfalse, as was the default in v23.2, suchREAD COMMITTEDtransactions will instead run asSERIALIZABLE.",
            "To check whether any transactions are being upgraded toSERIALIZABLE, see theUpgrades of SQL Transaction Isolation Levelgraph in the DB Console.\"",
            "Thechangefeed.balance_range_distribution.enabledcluster settingis now deprecated. Instead, use the new cluster settingchangefeed.default_range_distribution_strategy.changefeed.default_range_distribution_strategy='balanced_simple'has the same effect as settingchangefeed.balance_range_distribution.enabled=true. It does not requireinitial_scan='only', which was required by the old setting.#115166",
            "Added thecluster settingsecurity.client_cert.subject_required.enabledwhich enforces a mandatory requirement for the client certificate's role subject to be set. The subject can be defined through either the subject role option or by specifying theroot-cert-distinguished-nameandnode-cert-distinguished-nameproperties. This setting applies to both RPC access and login via authCert.#122368",
            "Thecluster settingsql.contention.record_serialization_conflicts.enabledis nowonby default. As a result, any40001errorthat contains conflicting transaction information will be recorded by the contention registry, improving the ability to troubleshoot. For more information, refer to theInsights pagedocumentation.#116664",
            "The newcluster settingstorage.sstable.compression_algorithmconfigures the compression algorithm used when compressing sstable blocks. Supported values are: \"snappy\" and \"zstd\" [snappy =1, zstd =2]. Changing the default of snappy to zstd can result in substantial performance improvement, however, the effects this change may be highly dependent on the workload and data, so experimentation is recommended before enabling zstd in production environments.",
            "The new settingstorage.wal_failover.unhealthy_op_thresholdallows you to set the latency threshold at which a WAL (Write-Ahead Logging) write is considered unhealthy. When exceeded, the node will attempt to write WAL entries to a secondary store's volume. For more information, refer to#120509",
            "The newserver.max_open_transactions_per_gatewaycluster setting, when set to a non-negative value, allows only admin users to execute a query if the number of open transactions on the current gateway node is already at the configured limit.#118781",
            "The newserver.redact_sensitive_settings.enabledcluster setting(falseby default), when set totrue, redacts the values of the following settings in the output ofSHOWcommands or other introspection interfaces. In the future, newly-added sensitive cluster settings will be redacted as well. Users with theMODIFYCLUSTERSETTINGprivilegecan always view the unredacted settings.#117729",
            "The new boolean changefeed optionignore_disable_changefeed_replication, when set totrue, prevents the changefeed from filtering events even if CDC filtering is configured via thedisable_changefeed_replicationsession variable,sql.ttl.changefeed_replication.disabledcluster setting, or thettl_disable_changefeed_replicationtable storage parameter.#120255",
            "The provisioned-rate field, if specified, should no longer accept a disk-name or an optional bandwidth field. To use the disk bandwidth constraint the store-spec must containprovisioned-rate=bandwidth=<bandwidth-bytes/s>, otherwise the cluster settingkvadmission.store.provisioned_bandwidthwill be used. When set to a non-zero value, this is used as the provisioned bandwidth (in bytes/s), for each store. It can be overridden on a per-store basis using the --store flag. Note that setting the provisioned bandwidth to a positive value may enable disk bandwidth based admission control, sinceadmission.disk_bandwidth_tokens.elastic.enableddefaults totrue.",
            "Removed in v24.1:sql.show_ranges_deprecated_behavior.enabledsql.trace.session_eventlog.enabledchangefeed.balance_range_distribution.enabled",
            "sql.show_ranges_deprecated_behavior.enabled",
            "sql.trace.session_eventlog.enabled",
            "changefeed.balance_range_distribution.enabled",
            "changefeed.balance_range_distribution.enableis now deprecated. Instead, use the newcluster settingchangefeed.default_range_distribution_strategy.changefeed.default_range_distribution_strategy='balanced_simple'has the same effect as settingchangefeed.balance_range_distribution.enable=true. It does not requireinitial_scan='only', which was required by the old setting.#115166",
            "Thecockroach connectcommand has been removed. This command wasdeprecatedin CockroachDB v23.2.#113893"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.9",
        "date": "August 1, 2024",
        "changes": [
            "EXPLAIN ANALYZEstatements are now supported when executed via Cloud ConsoleSQL shell.#125562",
            "Added thesql.auth.grant_option_inheritance.enabledcluster setting. The default value istrue, which maintains consistency with CockroachDB's previous behavior: users granted a privilege withWITH GRANT OPTIONcan in turn grant that privilege to others. Whensql.auth.grant_option_inheritance.enabledis set tofalse, theGRANT OPTIONis not inherited through role membership, thereby preventing descendant roles from granting the privilege to others. However, the privilege itself continues to be inherited through role membership.#126298",
            "crdb_internal.cluster_execution_insights.txtandcrdb_internal.cluster_txn_execution_insights.txthave been removed from thedebug zip. These files contained cluster-wide insights for statements and transactions. Users can still rely on theper-node executioninsights incrdb_internal.node_execution_insights.txtandcrdb_internal.node_txn_execution_insights.txt.#125804",
            "Some debugging-only information about physical plans is no longer collected in thesystem.job_infotable forchangefeeds, because it has the potential to grow very large.#126097",
            "For theTELEMETRY channel, TCLsampled_queryevents will now be sampled at the rate specified by the settingsql.telemetry.query_sampling.max_event_frequency, which is already used to limit the rate of sampling DML statements.#126728",
            "Fixed a bug introduced in v23.2.0 in which CockroachDB would hit an internal error when evaluatingINSERTsintoREGIONAL BY ROWtables where the source was aVALUESclause with a single row and at least one boolean expression.#125504#126839",
            "Fixed a bug where aDROP ROLEorDROP USERcommand could leave references behind inside types, which could prevent subsequentSHOW GRANTScommands from working.#125806",
            "Fixed a bug that could lead to descriptors having privileges to roles that no longer exist. Added an automated clean up fordropped rolesinside descriptors.#125806",
            "Fixed a bug where a change to auser-defined type (UDT)could cause queries against tables using that type to fail with an error message like:histogram.go:694: span must be fully contained in the bucket. The change to the user-defined type could occur either directly from anALTER TYPEstatement or indirectly from anALTER DATABASE ... ADD REGIONorALTER DATABASE ... DROP REGIONstatement, which implicitly modifies thecrdb_internal_regionUDT. This bug had existed since UDTs were introduced in v20.2.#125806",
            "Fixed a bug in which constantLIKEpatterns containing certain sequences of backslashes did not become constrained scans. This bug has been present since v21.1.13 when support for building constrained scans fromLIKEpatterns containing backslashes was added.#125538",
            "Fixed a bug introduced in alpha versions of v23.1 where calling a routine could result in an unexpectedfunction ... does not existerror. The bug is triggered when the routine is called twice using the exact same SQL query, and either: (a) the routine has polymorphic arguments, or: (b) between the two calls, the routine is replaced by a routine with the same name and different parameters.#123518",
            "Fixed the statistics estimation code in theoptimizerso it does not use the empty histograms produced ifhistogram collectionhas been disabled during stats collection due to excessive memory utilization. Now the optimizer will rely on distinct counts instead of the empty histograms and should produce better plans as a result. This bug has existed since v22.1.#126156",
            "Fixed a bug incockroach debug tsdumpwhere the command fails when a custom SQL port is used and the--format=rawflag is provided.#126184",
            "Fixed a bug where auser-defined function (UDF)that shared a name with abuilt-in functionwould not be resolved, even if the UDF had higher precedence according to thesearch_pathvariable.#126295",
            "Fixed a bug that causedbackground jobsto incorrectly respect a statement timeout.#126819",
            "Fixed a bug whereALTER DATABASE ... DROP REGIONcould fail if any tables under the given database haveindexes on expressions.#126598",
            "Fixed a bug whenrestoringa database with acomposite type.#126841",
            "Fixed a bug when inputtingpublicrole as user name forbuilt-in compatibility functions, such ashas_database_privilegeandhas_schema_privilege.#126852",
            "Fixed a bug where theDatabase pagecould crash if range information is not available.#127091",
            "Fixed a bug where CockroachDB could incorrectly evaluate anIS NOT NULLfilter if it was applied to non-NULLtuples that hadNULLelements, such as(1, NULL)or(NULL, NULL). This bug has existed since v20.2.#126937",
            "In theDB Console event log,ALTER ROLEevents now display correctly even when norole optionsare included in theALTER ROLEstatement.#126565",
            "Fixed a bug whereCREATE TABLEwithindex expressionscould hit undefined column errors ontransaction retries.#126201",
            "Schema changesthat cause a data backfill, such as adding a non-nullable column or changing the primary key, will now split and scatter the temporary indexes used to perform the change. This reduces the chance of causing a write hotspot that can slow down foreground traffic.#126691"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.8",
        "date": "July 15, 2024",
        "changes": [
            "Updated thereplica allocatorwith a small performance win for very large clusters.#126918",
            "Updated thegossip layerto avoid unnecessary mutex contention.#126919,#126920",
            "Fixed a bug where thedisallow_full_table_scanssession variablewas not working for tables withhash-sharded indexes.#126700"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.7",
        "date": "July 2, 2024",
        "changes": [
            "Changefeedscan use the bulk oracle for planning, which distributes work evenly across allreplicasin the locality filter, including followers if enabled. Set thechangefeed.random_replica_selection.enabledcluster settingtotrueto enable this planning behavior. To use the previous bin-packing oracle, set the cluster settingchangefeed.random_replica_selection.enabledtofalse.#124925",
            "ALTER CHANGEFEEDno longer removes theCDC querywhen modifying changefeed properties.#125437",
            "Precision is no longer limited when encodinggeodata types to JSON.#124535",
            "When the newoptimizer_push_offset_into_index_joinsession settingis enabled, theoptimizerattempts to produce more efficient query plans by attempting to push offset expressions into index join expressions to produce more efficient query plans.#124492",
            "CockroachDB v23.2.7 and subsequent v23.2 releases are eligible forlong term support (LTS).",
            "Improved metrics related todisk usagereporting for volumes that dynamically change their size over time.#125107",
            "Improved the automated cleanup when dropping roles inside descriptors.#124665",
            "Fixed a bug where a range with a replication factor of1to be scaled up to a replication factor of2.#124487",
            "Fixed a bug that could cause leases to thrash between nodes when perturbed with a replication factor of1.#124487",
            "Fixed a bug where, when thettl_row_stats_poll_intervalstorage parameter is non-zero, the job to update row statistics for a table withrow-level TTLenabled could be blocked from completing by the queries issued to update the row statistics. Now, if the job completes, these queries are cancelled, and thejobs.row_level_ttl.total_rowsandjobs.row_level_ttl.total_expired_rowsmetrics will report 0 if the job finishes before the queries to update the row statistics complete.#124626",
            "Fixed a bug where theresults_buffer_sizesession settingcould not be configured using theoptionsquery parameter in the connection string, but only as a top-level query parameter. This variable cannot be changed by using theSETcommand after the session begins.#124774",
            "Fixed a bug where dropping a role or user could leave references behind inside types. This in turn could prevent theSHOW GRANTScommand from working correctly.#124644",
            "Fixed a bug where theALTER TABLE ... ALTER PRIMARY KEYcommand could hang for a table if its indexes are referred to by views or functions using theforce syntaxsyntax.#124569",
            "Fixed a bug where theSHOW TYPEScommand omitted user-defined composite types. This bug was introduced in v23.1.#124816",
            "Fixed a bug where if a column name that contains UTF-8 characters is referenced in theSTORING()clause of theCREATE INDEXcommand, thedeclarative schema changercannot detect whether the column is already handled by an existing index.#125211",
            "Fixed a bug where thedeclarative schema changererroneously includes virtual columns that are referenced in theSTORING()clause of theCREATE INDEXcommand.#125211",
            "Fixed a bug introduced in v20.2, where a change to a user-defined type could cause queries against tables using that type to fail with the error likehistogram.go: span must be fully contained in the bucket. This bug could occur if the change was from anALTER TABLEcommand or from anALTER DATABASE ... ADD REGIONorALTER DATABASE ... DROP REGIONcommand, which implicitly change the non-publiccrdb_internal_regiontype.#124853",
            "Fixed a bug where telemetry logs could emit the same statement fingerprint ID for different SQL statements.#125043",
            "Fixed a bug where adding a column with a default value of an empty array could fail.#125326",
            "Fixed a bug where thedeclarative schema changercould erroneously succeed despite a violation of anALTER TABLE ... ADD CONSTRAINT UNIQUEconstraint. Now such a violation results in an error message with the error code42601.#125418",
            "Fixed achangefeedpanic in v24.1, v23.2, and v23.1 when thecluster settingchangefeed.aggregator.flush_jittercluster settingis configured and a changefeed'smin_checkpoint_frequencyoption is set to zero.#125469",
            "Fixed a bug where the public schema was erroneously created with its owner set to theadminrole instead of the database owner. Ownership of the public schema can be altered after the schema is created.#125535",
            "Fixed a bug introduced in v23.2.0 where inserting rows into aREGIONAL BY ROWtablecould cause an internal error if the source was aVALUESclause with a single row and at least one boolean expression.#126208",
            "The optimizer now generates more efficient query plans for some queries withOFFSETclauses.#124492"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.6",
        "date": "June 11, 2024",
        "changes": [
            "Fixed a bug that was present since v22.2 wherechangefeedswith long-runninginitial scansmight incorrectly restore checkpoint job progress and drop events duringchangefeed restartsdue to transient errors or node restarts. The bug was most likely to occur in clusters with the following contributing factors:Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled.The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.There were multiple target tables with significant differences in row counts in one changefeed.The changefeed target tables were large with many ranges.The initial scan took a long time to complete (an hour or longer).#123966",
            "Thechangefeed.shutdown_checkpoint.enabledcluster settingwas enabled.",
            "The cluster settingschangefeed.frontier_checkpoint_frequencyandlow changefeed.frontier_highwater_lag_checkpoint_thresholdwere set low, which resulted in the initial scan taking many multiples of the configured frequency to complete.",
            "There were multiple target tables with significant differences in row counts in one changefeed.",
            "The changefeed target tables were large with many ranges.",
            "The initial scan took a long time to complete (an hour or longer).#123966",
            "Updated theSHOW GRANTSresponses to display theobject_typeandobject_name, which has replaced therelation_namecolumn.#122822",
            "Addedexternal connectiongranted privileges to theSHOW GRANTScommand.#122822",
            "Introduced three newcluster settingsfor controlling table statistics forecasting:sql.stats.forecasts.min_observationsis the minimum number of observed statistics required to produce a forecast.sql.stats.forecasts.min_goodness_of_fitis the minimum R (goodness of fit) measurement required from all predictive models to use a forecast.sql.stats.forecasts.max_decreaseis the most a prediction can decrease, expressed as the minimum ratio of the prediction to the lowest prior observation.#122458",
            "sql.stats.forecasts.min_observationsis the minimum number of observed statistics required to produce a forecast.",
            "sql.stats.forecasts.min_goodness_of_fitis the minimum R (goodness of fit) measurement required from all predictive models to use a forecast.",
            "sql.stats.forecasts.max_decreaseis the most a prediction can decrease, expressed as the minimum ratio of the prediction to the lowest prior observation.#122458",
            "Added a newsession settingoptimizer_use_improved_multi_column_selectivity_estimate, which if enabled, causes theoptimizerto use an improved selectivity estimate for multi-column predicates. This setting will default totrueon v24.2 and later, andfalseon earlier versions.#123100",
            "Theoptimizercan now plan constrained scans over partial indexes in more cases, particularly onpartial indexeswith predicates referencingvirtual computed columns.#123469",
            "The row-level TTL settingttl_delete_rate_limitis now set to100by default, which sets the rate limit for deleting expired rows to100.#124353",
            "Two new metrics track the status of the SQL Activity Update job, which pre-aggregates top K information within the SQL statistics subsytem and writes the results tosystem.statement_activityandsystem.transaction_activity:sql.stats.activity.updates.successful: Number of successful updates made by the SQL activity updater job.sql.stats.activity.update.latency: The latency of updates made by the SQL activity updater job. Includes failed update attempts.#123960",
            "sql.stats.activity.updates.successful: Number of successful updates made by the SQL activity updater job.",
            "sql.stats.activity.update.latency: The latency of updates made by the SQL activity updater job. Includes failed update attempts.#123960",
            "Added a new countermetric,sql.stats.flush.done_signals.ignored, that tracks the number of times the SQL activity update job has ignored the signal that indicates that a flush has completed. This metric may indicate that the SQL activity update job is taking longer than expected to complete.#123960",
            "Added a new countermetric,sql.stats.activity.updates.failed, to measure the number of update attempts made by the SQL activity update job that failed with errors. The SQL activity update job is used to pre-aggregate top K information within the SQL stats subsystem and write the results tosystem.statement_activityandsystem.transaction_activity.#123960",
            "Added a new countermetric,sql.stats.flush.fingerprint.count, that tracks the number of unique statement and transaction fingerprints included in the SQL stats flush.#123960",
            "Added thesql.pgwire.pipeline.countmetric, which measures how many wire protocol commands have been received by the server, but have not yet started processing. This metric will only grow if clients are using thepipeline modeof the PostgreSQL wire protocol.#124260",
            "Theclient_authentication_okandclient_session_endevents are now logged to theSESSIONSlog channelunconditionally. Previously, these would only be logged if theserver.auth_log.sql_sessions.enabledcluster settingwas set totrue. All otherSESSIONSlog messages are still only logged ifserver.auth_log.sql_sessions.enabledorserver.auth_log.sql_connections.enabledare set totrue. To not showclient_authentication_okandclient_session_endevents, disable theSESSIONSlog channel entirely.#124374",
            "TheDatabasedetails andTabledetails pages now display the correct stats in theTable Stats Last Updated.#122815",
            "Viewing theSQL Activitysorted by% of Runtimenow correctly sorts entries by the runtime amount.#123901",
            "Fixed a bug whereclient certificate authenticationcombined withidentity maps(server.identity_map.configuration) did not work. For the feature to work correctly, the client must specify a valid database user in theconnection string.#122749",
            "Fixed a bug where therow-based execution enginecould drop aLIMITclause when there was anORDER BYclause, and the ordering was partially provided by an input operator. For example, this bug could occur with an ordering such asORDER BY a, bwhen the scanned index was only ordered on columna. The impact of this bug was that more rows may have been returned than specified by theLIMITclause. This bug is only present when not using thevectorized execution engine; that is, when running withSET vectorize = off;. This bug has existed since CockroachDB v22.1.#122836",
            "Fixed a bug in the DB Console'sCustom Charttool where store-level metrics were displayed only for the first store ID associated with the node. Now data is displayed for all stores present on a node, and a single time series is shown for each store, rather than an aggregated value for all of the node's stores. This allows finer-grained monitoring of store-level metrics.#122703",
            "Fixed a bug where privileges granted forexternal connectionswere incorrectly showing up inSHOW SYSTEM GRANTS, but were not useful because there was no associated object name. The privileges no longer appear inSHOW SYSTEM GRANTS. Instead, theSHOW GRANTS ON EXTERNAL CONNECTIONstatement should be used.#122905",
            "Statistics forecasts of zero rows can cause suboptimalquery plans. Forecasting will now avoid predicting zero rows for most downward-trending statistics.#122458",
            "Fixed a bug introduced in v23.2 that could cause aPL/pgSQLroutine to return incorrect results when the routine included:At least one parameter.AnIFstatement with one leak-proof branch and one branch with side effects.#120742",
            "At least one parameter.",
            "AnIFstatement with one leak-proof branch and one branch with side effects.#120742",
            "Fixed a bug that could result in an internal error when attempting to create aPL/pgSQLroutine using the (currently unsupported)%ROWTYPEsyntax for a variable declaration.#123010",
            "Fixed a bug where aRESTOREof a backup that itself contained a table created by theRESTOREof a table with an in-progressIMPORT INTOwould fail to restore all rows.#120543",
            "Fixed a bug introduced in v23.2 that could cause aPL/pgSQLvariable assignment to not be executed if the variable was never referenced after the assignment.#123116",
            "Fixed a bug where CockroachDB could run into anattempting to append refresh spans after the tracked timestamp has moved forwardinternal error in some edge cases. The bug had been present since v22.2.#123150",
            "Ajobwill now log rather than fail if it reports an out-of-bound progress fraction.#122964",
            "Fixed a bug that would occur whenALTER TYPE ... DROP VALUEis followed byDROP SCHEMA CASCADE ...in the same transaction. Previously, theALTER TYPEschema change would get queued up to run at commit time, but by that point, the type may have already been removed, so the commit could fail.#123576",
            "Fixed a bug that could lead to descriptors with self references that pointed to incorrect descriptor IDs. Now, tables that see the errorinvalid inbound foreign key ... origin table ID should beorinvalid outbound foreign key ... reference table ID should bewill automatically repair post deserialization.#123681",
            "Fixed a bug where a failedrestorejob could leave the system in a state where re-attempting the restore was not possible without manual intervention.#123463",
            "Index recommendationsin theDB Consolewill now function properly for indexes on tables or columns whose names contain quotation marks or whitespace. For example:CREATE INDEX ON \"my table\" (\"my col\");.#122119",
            "Fixed a crash introduced in v23.2.5 that could occur when planningstatistics collectionon a table with avirtual computed columnusing a user-defined type when the newly introducedcluster settingsql.stats.virtual_computed_columns.enabledis set totrue. (The setting was introduced in v23.2.4 and set tofalseby default.)#124080",
            "Added automated clean up and validation fordropped rolesinside descriptors.#124670",
            "Fixed a bug whereDROP ROLEandDROP USERcould leave references behind inside types, which could preventSHOW GRANTSfrom working.#124668",
            "Fixed a bug where a change to auser-defined typecould cause queries against tables using that type to fail with the errorhistogram.go:694: span must be fully contained in the bucket. The change to the user-defined type could come directly from anALTER TYPEstatement, or indirectly from anALTER DATABASE ADD REGIONorDROP REGIONstatement (which implicitly change thecrdb_internal_regiontype). This was present since user-defined types were introduced in v20.2.#124854",
            "More efficientquery plansare now generated for queries with text similarity filters, for example,text_col % 'foobar'. These plans are generated if theoptimizer_use_trigram_similarity_optimizationsession settingis enabled. It is disabled by default.#122753",
            "Theoptimizernow costsdistinct-onoperators more accurately. It may produce more efficient query plans in some cases.#122844",
            "Added a newsession settingoptimizer_use_improved_zigzag_join_costing. When enabled and when thecluster settingenable_zigzag_joinis also enabled, the cost of zigzag joins is updated such that a zigzag join will be chosen over a scan only if it produces fewer rows than a scan.#123100",
            "Improved the selectivity estimation of multi-column filters when the multi-column distinct count is high. This prevents theoptimizerfrom choosing a bad query plan due to over-estimating the selectivity of a multi-column predicate.#123100",
            "Improved the efficiency of error handling in thevectorized execution engineto reduce the CPU overhead of statement timeout handling and reduce the potential for more statement timeouts.#123502"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.5",
        "date": "May 7, 2024",
        "changes": [
            "The newcluster settingsql.stats.virtual_computed_columns.enabledenables collection oftable statisticson virtualcomputed columns.#120923",
            "The newsession variableoptimizer_use_virtual_computed_column_statsconfigures theoptimizerto consider table statistics on virtual computed columns.#121179",
            "The newFORCE_INVERTED_INDEXhintconfigures theoptimizerto prefer a query plan scan over any inverted index of the hinted table. If no such query plan can be generated, an error is logged.#122300",
            "Theoptimizercan now plan constrained scans overpartial indexesin more cases, particularly on partial indexes with predicates referencing virtualcomputed columns.#123408",
            "A minimumRaftscheduler concurrency is now enforced perstoreso that a node with many stores does not spread workers too thinly. This avoids high scheduler latency acrossreplicason a store when load is imbalanced.#120798",
            "Achangefeedoptimization to reduce duplicates during aggregator restarts has been disabled due to poor performance.#123596",
            "TheCommit Latencychart in theChangefeed Dashboardnow aggregates by max instead of by sum for multi-node changefeeds. This more accurately reflects the amount of time for events to be acknowledged by the downstream sink.#121235",
            "Fixed a slow memory leak when opening many newconnections. This bug was introduced in v22.2.9 and v23.1.0.#121055",
            "Fixed a bug that occurred when usingALTER TABLEto drop and re-add aCHECKconstraintwith the same name.#121055",
            "SequenceoptionsMINVALUEandMAXVALUEautomatically adjust to new types bounds. This mirrors the behavior of PostgreSQL.#121309",
            "Fixed a bug that could prevent timeseries graphs shown on the DB Console SQL ActivityStatement Detailspage from rendering correctly when specifying a custom time range.#121383",
            "Fixed a bug present since at least v21.1 that could lead to incorrect evaluation of anINexpression with:INT2orINT4type on the left side, andValues on the right side that are outside of the range of the left side.#121953",
            "INT2orINT4type on the left side, and",
            "Values on the right side that are outside of the range of the left side.",
            "Fixed a leak in reported memory usage (not the actual memory usage) by the internal memory accounting system, the limit for which is configured via the--max-sql-memoryflag when a long-running sessions issues hundreds of thousands or moretransactions. This reporting bug could causeroot: memory budget exceedederrors for other queries. The bug was introduced in v23.1.17 and v23.2.3.#121950",
            "Fixed a bug introduced in v23.2.4 that could prevent collection oftable statisticson tables that have on virtualcomputed columnsofuser-defined typewhen the newly-introducedcluster settingsql.stats.virtual_computed_columns.enabledis set totrue(defaults tofalse). The setting was introduced in v23.2.4 and is disabled by default.#122319",
            "Fixed a bug where aGRANT ... ON ALL TABLESstatement could fail if a sequence existed that did not support theprivilegebeing granted.#122034",
            "Fixed an existing bug where an unused value cannot be dropped from anENUMif theENUMitself is referenced by auser-defined function. A value can now be dropped from anENUMas long as the value itself is not being referenced by any other data element, including a user-defined function.#121237"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.4",
        "date": "April 11, 2024",
        "changes": [
            "Mutation statements such asUPDATEandDELETEas well as locking statements such asSELECT FOR UPDATEare not allowed inread-only transactionsorAS OF SYSTEM TIMEtransactions. Previously, a bug existed where mutation statements and locking statements in implicit single-statement transactions using AS OF SYSTEM TIME were allowed.#120158",
            "The new cluster settingsql.stats.virtual_computed_columns.enabled, when enabled, allows the collection oftable statisticsonvirtual computed columns.#120933",
            "The newsession variableoptimizer_use_virtual_computed_column_stats, when enabled, configures thecost-based optimizerto usetable statisticsonvirtual computed columns.#121329",
            "Fixed an issue where clusters with multiplestoresper node could list inaccurate region and node information on theDatabasespage.#120212",
            "Users will no longer seeviewsdisplayed on theDatabasespage. Previously views would be listed with no information, only displaying errors.#120214",
            "Previously, on long-runningsessionsthat issue many (hundreds of thousands or more)transactions, CockroachDB's internal memory accounting system, the limit for which is configured via the--max-sql-memoryflag) could leak. This bug, in turn, could result in the error message\"root: memory budget exceeded\"for other queries. The bug was present in v23.2.3 and is now fixed.#121875",
            "Previously,altering a table's localityfromREGIONAL BY ROWtoREGIONAL BY TABLEcould causeleaseholdersto never move to thedatabase's primary region. This is now fixed.#118794",
            "A user with theVIEWACTIVITYREDACTEDprivilegecan no longer see constants inside of queries that originate from other users in theSHOW SESSIONSresult. Previously, this redaction did not occur.#119884",
            "Previously, theSHOW STATEMENTSand theSHOW QUERIEScommands incorrectly required the user to have theVIEWACTIVITYorVIEWACTIVITYREDACTEDprivilege. However, a user always should be able to view their own queries, even without these privileges. This is now fixed.#119884",
            "Fixed a bug whereRESTOREon certainBACKUPswould open a very large number of connections to the backup storage provider.#119883",
            "Fixed a bug that occurred when usingALTER TABLEtodropandaddback aCHECKconstraintwith the same name.#120075",
            "Fixed a bug in which it was possible to setsession variabletransaction_read_onlytofalseduring anAS OF SYSTEM TIMEtransaction.#120158",
            "Fixed a bug where some files were not closed when inspectingbackup metadataduringBACKUPandRESTORE.#119635",
            "Fixed an intermittent page crash on theSchema Insightsview.#120210"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.3",
        "date": "March 20, 2024",
        "changes": [
            "TheDB Consolesessioncookie is now markedHttpOnlyto prevent it from being read by any Javascript code. Cookies are also markedSecurefor the browser when the cluster is running in secure mode.#119259",
            "Clusters usingCluster Single Sign-on (SSO) with JSON web tokens (JWTs)can now optionally fetch signing keys from configured issuers instead of configuring static signing keys for each issuer. When the new cluster settingserver.jwt_authentication.jwks_auto_fetch.enabledis set totrue, signing keys are automatically fetched from the issuer using metadata published in its OpenID configuration. In this case, static signing keys inserver.jwt_authentication.jwksare ignored. When automatic fetching is enabled, there may be a slight increase in network latency for each JWT authentication request, proportional to the latency between the cluster and the issuer's endpoint.#119768",
            "Fixed a bug where creating a changefeed with theformat='avro'anddiffoptions that targeted tables with aDECIMAL(n)column (i.e., zero-scaleDECIMALcolumn) would cause a panic.#118847",
            "Changed thesql.index_recommendation.drop_unused_durationcluster setting topublicso that it is documented on theCluster Settingspage.#118764",
            "Added theserver.max_open_transactions_per_gatewaycluster setting. When set to a non-negative value, non-admin users cannot execute a query if the number of transactions open on the current gateway node is already at the configured limit.#118933",
            "Out-of-process SQL servers will now start exporting a newsql.aggregated_livebytesmetric. This metric gets updated once every 60 seconds by default, and its update interval can be configured via thetenant_global_metrics_exporter_intervalcluster setting.#119371",
            "Added support for index hints withINSERTandUPSERTstatements. This allowsINSERT ... ON CONFLICTandUPSERTqueries to use index hints in the same way they are already supported forUPDATEandDELETEstatements.#119601",
            "Expanded the--include-range-infoflag to include problem ranges. This flag still defaults totrue.#119234",
            "In unredacteddebug zips, thecrdb_internal.transaction_contention_eventstable file has two new columns:waiting_stmt_query: the query of the waiting statement.blocking_txn_queries_unordered: the unordered list of the blocking transaction's queries.#118831",
            "waiting_stmt_query: the query of the waiting statement.",
            "blocking_txn_queries_unordered: the unordered list of the blocking transaction's queries.#118831",
            "Updated the SQL shell help URL to point to thecockroach sqlpage.#118994",
            "cockroach debug tsdumpcreates atsdump.yamlfile. Thetsdumpraw format automatically creates the YAML file in the default location/tmp/tsdump.yaml. Added a new flag--yamlthat allows users to specify the path to createtsdump.yamlinstead of using the default location. For example,cockroach debug tsdump --host <host>:<port> \\ --format raw --yaml=/some_path/tsdump.yaml > /some_path/tsdump.gob.#117741",
            "Fixed a bug where a warning about the need to refresh data would remain displayed on the Active Executions view of theStatementsandTransactionspages despite enablingAuto Refresh.#118703",
            "Updated theStatement Details pageto always show the entire selected period, instead of just the period that had data.#118805",
            "TheOverload dashboardnow includes two additional graphs:Elastic CPU Utilization: displays the CPU utilization by elastic work, compared to the limit set for elastic work.Elastic CPU Exhausted Duration Per Second: displays the duration of CPU exhaustion by elastic work, in microseconds.#118896",
            "Elastic CPU Utilization: displays the CPU utilization by elastic work, compared to the limit set for elastic work.",
            "Elastic CPU Exhausted Duration Per Second: displays the duration of CPU exhaustion by elastic work, in microseconds.#118896",
            "TheFull Table/Index Scanschart in theSQL Metrics dashboardnow shows the non-negative derivative of the number of full scans tracked.#118860",
            "Fixed a bug where achangefeedcould omit events in rare cases, logging the errorcdc ux violation: detected timestamp ... that is less or equal to the local frontier. This could happen in the following scenario:Arangefeedruns on a followerreplicathat lags significantly behind theleaseholder.A transaction commits and removes its transaction record before itsintentresolution is applied on the follower.The follower'sclosed timestamphas advanced past the transaction commit timestamp.The rangefeed attempts to push the transaction to a new timestamp (at least 10 seconds after the transaction began).This may cause the rangefeed to prematurely emit a checkpoint before emitting writes at lower timestamps, which in turn may cause thechangefeedto drop these events entirely, never emitting them.#118413",
            "Arangefeedruns on a followerreplicathat lags significantly behind theleaseholder.",
            "A transaction commits and removes its transaction record before itsintentresolution is applied on the follower.",
            "The follower'sclosed timestamphas advanced past the transaction commit timestamp.",
            "The rangefeed attempts to push the transaction to a new timestamp (at least 10 seconds after the transaction began).",
            "This may cause the rangefeed to prematurely emit a checkpoint before emitting writes at lower timestamps, which in turn may cause thechangefeedto drop these events entirely, never emitting them.#118413",
            "Decommissioning replicas that are part of a mis-replicated range will no longer get stuck on a rebalance operation that was falsely determined to be unsafe. This bug was introduced in v23.1.0.#118343",
            "CockroachDB will no longer spam the logs withunable to get CPU capacityerrors every 10 seconds when running outside of a CPU cgroup.#118672",
            "AUTO CREATE STATSjobs could previously lead to growth in an internal system table resulting in slower job-system related queries.#118942",
            "Fixed a bug that caused an inscrutable error when asequencename allocated bySERIALconflicted with an existing type name.#118947",
            "Fixed an internal error with a message like:LeafTxn ... incompatible with locking requestthat occurs when performing an update underREAD COMMITTEDisolationthat cascades to a table with multiple other foreign keys.#118931",
            "Fixed a bug whereALTER PRIMARY KEYcould fail with an errornon-nullable column <x> with no value! Index scanned ..when validating recreatedsecondary indexes.#118974",
            "Fixed a bug whereCOMMENT ONstatements could fail with anunexpected valueerror if multipleCOMMENTstatements were running concurrently.#119020",
            "Previously, in certain cases, using virtual tables such ascrdb_internal.system_jobscould result in the internal errorattempting to append refresh spans after the tracked timestamp has moved forward. This is now fixed. The bug was introduced in CockroachDB v23.1.#119184",
            "Fixed a bug where operations on thecrdb_internal.leasestable could cause a node to become unavailable due to a deadlock in the leasing subsystem.#119341",
            "Fixed a bug where rangefeed resolved timestamps could get stuck, continually emitting the log messagepushing old intents failed: range barrier failed, range split, typically following arange merge.#119541",
            "Fixed a bug where running achangefeedthat targets a table with a user-defined type column and with theenvelopeoptionset to any value other thanwrappedwould cause a node panic due to a nil dereference.#119738",
            "Fixed a rare panic that could happen during apg_dumpimport that contains a function that has a subquery in one of its arguments, likeSELECT addgeometrycolumn(...). Now, attempting to import apg_dumpwith such a function results in an expected error.#118612",
            "Users with theVIEWACTIVITYprivilege can now request statement bundles usingcrdb_internal.request_statement_bundleor through the DB ConsoleSQL Activitypage.#118809",
            "Fixed a bug in changefeedwebhook sinkswhere the HTTP request body may not be initialized on retries, resulting in the errorhttp: ContentLength=... with Body length 0.#119496",
            "Fixed a bug that caused internal errors when executing anEXPORTstatement.#119711",
            "Fixed a bug that could lead to schema changes with a large number of descriptors doing full table scans onsystem.leases.#119464",
            "Fixed a bug where rangefeed resolved timestamps could get stuck, continually emitting the log messagepushing old intents failed: range barrier failed, range split, typically following a range merge. This bug was introduced in v23.2.1.#119702",
            "Fixed a bug that occurred when usingALTER TABLEto drop and re-add aCHECKconstraint with the same name.#120076",
            "Fixed a bug that caused a slow memory leak that can accumulate when opening many new connections. The bug was present in v22.2.9+ and v23.1+ versions.#120245"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.28",
        "date": "September 4, 2025",
        "changes": [
            "Lookup joins can now be used on tables with virtual columns even if the type of the search argument is not identical to the column type referenced in the virtual column.#152926"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.27",
        "date": "June 25, 2025",
        "changes": [
            "Thegoschedstats.always_use_short_sample_period.enabledcluster setting should be set totruefor any serious production cluster; this will prevent unnecessary queuing in admission control CPU queues.#146742",
            "Fixed a bug that could potentially cause a changefeed to complete erroneously when one of its watched tables encounters a schema change.#147040",
            "Fixed a bug that caused the SQL Activity > Statement Fingerprint page to fail to load details for statements run with application names containing a#character.#147219",
            "Fixed a bug that could cause thecockroachprocess tosegfaultwhen collecting runtime execution traces (typically collected via theAdvanced Debugpage in the Console).#147339",
            "Fixed a bug that could cause stable expressions to be folded in cached query plans. The bug could cause stable expressions likecurrent_settingto return the wrong result if used in a prepared statement. The bug was introduced in v23.2.22, v24.1.14, v24.3.9, v25.1.2, and the v25.2 alpha.#147456",
            "TTL jobs now respond to cluster topology changes by restarting and rebalancing across available nodes.#147224"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.26",
        "date": "May 28, 2025",
        "changes": [
            "Fixed a bug where using values for the cluster settingchangefeed.aggregator.flush_jitterand the changefeed optionmin_checkpoint_frequencyresulting inchangefeed.aggregator.flush_jitter * min_checkpoint_frequency < 1would cause a panic. Jitter will now be disabled in this case.#144423",
            "Improved the performance ofSHOW CREATE TABLEon multi-region databases with a large numbers of objects.#145081",
            "Fixed an internal assertion failure that could occur during operations likeALTER TYPEorALTER DATABASE ... ADD REGIONwhen temporary tables were present.#146200",
            "Fixed a bug that preventedTRUNCATEfrom succeeding if any indexes on the table had back-reference dependencies, such as from a view or function referencing the index.#146322",
            "Fixed a rare corruption bug that impacts import and materialized views.#144659"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.25",
        "date": "April 30, 2025",
        "changes": [
            "Added theWITH IGNORE_FOREIGN_KEYSoption toSHOW CREATE TABLEwhich omits foreign key constraints from the output schema. This option is also allowed inSHOW CREATE VIEW, but has no effect. It cannot be combined with theWITH REDACToption.#142165",
            "Fixed a bug where CockroachDB would encounter an internal error when decoding the gists of plans withCALLstatements. The bug had been present since v23.2.#143312",
            "Fixed a bug that caused changefeeds to fail on startup when scanning a single key.#143147",
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144029",
            "Fixed a bug that could leave behind a dangling reference to a dropped role if that role had default privileges granted to itself. The bug was caused by defining privileges such as:ALTER DEFAULT PRIVILEGES FOR ROLE self_referencing_role GRANT INSERT ON TABLES TO self_referencing_role.#143291",
            "MVCC garbage collection is now fully subject to IO admission control. Previously, it was possible for MVCC GC to cause store overload (such as LSM inversion) when a large amount of data would become eligible for garbage collection. Should any issues arise from subjecting MVCC GC to admission control, thekv.mvcc_gc.queue_kv_admission_control.enabledcluster setting can be set tofalseto restore the previous behavior.#143274"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.24",
        "date": "April 28, 2025",
        "changes": [
            "Fixed a rare corruption bug that impacts import and materialized views.#144659"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.23",
        "date": "April 9, 2025",
        "changes": [
            "Fixed a bug that could cause a stack overflow during execution of a prepared statement that invoked a PL/pgSQL routine with a loop. The bug existed in versions v23.2.22, v24.1.15, v24.3.9, v25.1.2, v25.1.3, and pre-release versions of v25.2 prior to v25.2.0-alpha.3.#144062"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.22",
        "date": "April 2, 2025",
        "changes": [
            "The protected timestamp (PTS) records of running changefeeds are now updated when the set of targets changes, such as when system tables are added to the protected tables list.#141157",
            "Fixed a bug that could cause gateway nodes to panic when performing anUPSERTon a table with aBOOLprimary key column and a partial index that used the primary key column as the predicate expression.#141825",
            "Fixed a rare bug in which a query could fail with the errorcould not find computed column expression for column in tablewhile dropping a virtual computed column from a table. This bug was introduced in v23.2.4.#139874",
            "Fixed a bug that could causenil pointer dereferenceerrors when executing statements with user-defined functions (UDFs). The error could also occur when executing statements with some built-in functions, likeobj_description.#141666",
            "When configuring thesql.ttl.default_delete_rate_limitcluster setting, a notice is displayed informing the user that the TTL rate limit is per leaseholder per table with a link to the docs.#142831"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.21",
        "date": "March 6, 2025",
        "changes": [
            "Since v23.2, table statistics histograms have been collected for non-indexedJSONBcolumns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#140144",
            "Fixed a bug where under rare circumstances draining a node could fail withsome sessions did not respond to cancellation within 1s.#139479",
            "Fixed a bug that prevented theCREATEstatement for a routine from being shown in a statement bundle. This happened when the routine was created on a schema other thanpublic. The bug has existed since v23.1.#136131",
            "Fixed a bounded memory leak that could previously occur when evaluating some memory-intensive queries via the vectorized engine. The leak has been present since v20.2.#139098",
            "Previously, in changefeeds using CDC queries and the Parquet format, the output would include duplicate columns when it contained a user-defined primary key. Now, the columns are de-duplicated in Parquet changefeed messages.#140380"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.20",
        "date": "February 6, 2025",
        "changes": [
            "Since v23.2, table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns if thesql.stats.non_indexed_json_histograms.enabledcluster setting is set tofalse. This reduces memory usage during table statistics collection, for both automatic and manual collection viaANALYZEandCREATE STATISTICS.#140269",
            "Thechangefeed.max_behind_nanosmetric now supports scoping with metrics labels.#139241",
            "Previously,SHOW CREATE TABLEwas showing incorrect data with regards to inverted indexes. It now shows the correct data that can be repeatedly entered back into CockroachDB to recreate the same table.#138167",
            "Fixed a bug where querying thepg_catalog.pg_constrainttable while the schema changer was dropping a constraint could result in a query error.#138286",
            "Fixed a bounded memory leak that could occur when collecting table statistics on a table that had both very wide (10KiB or more) and relatively small (under 400B)BYTES-like values within the same row. This leak had been present since before v19.2.#139177",
            "Fixed a bug where changefeeds using CDC queries could have duplicate columns in the Parquet output.#140155",
            "Fixed a bug that prevented theCREATEstatement for a routine from being included in a statement bundle when the routine was created on a schema other thanpublic. The bug had existed since v23.1.#140260"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.2",
        "date": "February 27, 2024",
        "changes": [
            "Fixed a bug whererangefeedresolved timestamps could get stuck, continually emitting the log messagepushing old intents failed: range barrier failed, range split, typically following arange merge. This bug was introduced in v23.2.1.#119558"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.19",
        "date": "January 9, 2025",
        "changes": [
            "The cluster settingserver.jwt_authentication.issuersnow takes the issuers configuration value from the URI. This can be set to one of the following values:Simple string that can be parsed as a valid issuer URL. For example:'https://accounts.google.com'.String that can be parsed as a valid JSON array of issuer URLs list. For example:['example.com/adfs','https://accounts.google.com'].String that can be parsed as valid JSON and deserialized into a map of issuer URLs to corresponding JWKS URIs. In this case, the JWKS URI present in the issuer's well-known endpoint will be overridden. For example:'{\"issuer_jwks_map\": {\"https://accounts.google.com\": \"https://www.googleapis.com/oauth2/v3/certs\", \"example.com/adfs\": \"https://example.com/adfs/discovery/keys\"}}'. Whenissuer_jwks_mapis set, the JWKS URI is directly used to get the key set. In all other cases whenJWKSAutoFetchEnabledis set, the JWKS URI is obtained first from the issuer's well-known endpoint and then this endpoint is used.#138188",
            "Simple string that can be parsed as a valid issuer URL. For example:'https://accounts.google.com'.",
            "String that can be parsed as a valid JSON array of issuer URLs list. For example:['example.com/adfs','https://accounts.google.com'].",
            "String that can be parsed as valid JSON and deserialized into a map of issuer URLs to corresponding JWKS URIs. In this case, the JWKS URI present in the issuer's well-known endpoint will be overridden. For example:'{\"issuer_jwks_map\": {\"https://accounts.google.com\": \"https://www.googleapis.com/oauth2/v3/certs\", \"example.com/adfs\": \"https://example.com/adfs/discovery/keys\"}}'. Whenissuer_jwks_mapis set, the JWKS URI is directly used to get the key set. In all other cases whenJWKSAutoFetchEnabledis set, the JWKS URI is obtained first from the issuer's well-known endpoint and then this endpoint is used.#138188",
            "In order to improve the granularity of changefeed pipeline metrics, the changefeed metricschangefeed.admit_latencyandchangefeed.commit_latencynow have histogram buckets from5msto60m(previously500msto5m). The changefeed metricschangefeed.parallel_io_queue_nanos,changefeed.parallel_io_result_queue_nanos,changefeed.sink_batch_hist_nanos,changefeed.flush_hist_nanos, andchangefeed.kafka_throttling_hist_nanoshave histogram buckets from5msto10m(previously500msto5m).#136618",
            "Added support for multiple seed brokers in the new Kafka sink.#136745",
            "Added a metricdistsender.rangefeed.catchup_ranges_waiting_client_sidethat counts how many rangefeeds are waiting on the client-side limiter to start performing catchup scans.#136837",
            "Added changefeed support for themvcc_timestampoption with theavroformat. If both options are specified, the Avro schema includes anmvcc_timestampmetadata field and emits the row's MVCC timestamp with the row data.#136018",
            "Added thelegacy_varchar_typingsession setting that reverts the changes of#133037that caused the change in typing behavior described in#137837. Specifically, thelegacy_varchar_typingsession setting makes type-checking and overload resolution ignore the newly added \"unpreferred\" overloads. This setting defaults toon.#137922",
            "Telemetry delivery is now considered successful even in cases where we experience a network timeout. This will prevent throttling in cases outside an operator's control.#136477",
            "When a schema change job completes, rolls back, or encounters a failure, the time taken since the job began is now logged in a structured log in theSQL_SCHEMAlog channel.#136952",
            "CREATE SCHEMAnow returns the correct error if the schema name is missing.#135925",
            "Fixed an issue where corrupted table statistics could cause the CockroachDB process to crash.#136043",
            "Theidle_in_session_timeoutsetting now excludes the time spent waiting for schema changer jobs to complete, preventing unintended session termination during schema change operations.#136508",
            "Fixed a bug that caused the optimizer to use stale table statistics after altering an enum type used in the table.#136832",
            "CockroachDB now better respectsstatement_timeoutlimit on queries involving the top K sort and merge join operations.#136650",
            "Fixed an issue where license enforcement was not consistently disabled for single-node clusters started withstart-single-node. Now, cluster restarts correctly disable licensing.#137009",
            "Fixed a bug that caused queries against tables with user-defined types to sometimes fail with errors after restoring those tables.#137356",
            "Fixed a bug that could cause an internal error if a table with an implicit (rowid) primary key was locked from within a subquery, for example,SELECT * FROM (SELECT * FROM foo WHERE x = 2) FOR UPDATE;. The error could occur either under read-committed isolation, or withoptimizer_use_lock_op_for_serializableenabled.#137130",
            "Fixed an issue where adding an existing column with theIF NOT EXISTSoption could exit too early, skipping necessary handling of the abstract syntax tree (AST). This could lead to failure of theALTERstatement.#137678",
            "CLOSE CURSORstatements are now allowed in read-only transactions, similar to PostgreSQL. The bug has been present since at least v23.1.#137788",
            "Fixed an issue where a schema change could incorrectly cause a changefeed to fail with an assertion error likereceived boundary timestamp ... of type ... before reaching existing boundary of type ....#137703",
            "Internal scans are now exempt from thesql.defaults.disallow_full_table_scans.enabledsetting, allowing index creation even when the cluster setting is enabled.#137720",
            "A new column of typeJSONorJSONBthat has aUNIQUEconstraint will now be blocked from being added to a table if the cluster has not yet finalized the upgrade to v23.2.#137864"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.18",
        "date": "December 26, 2024",
        "changes": [
            "Added thelegacy_varchar_typingsession setting. When set toon, type-checking comparisons involvingVARCHARcolumns behave as they did in all previous versions. When set tooff, type-checking of these comparisons is more strict and queries that previously succeeded may now error with the messageunsupported comparison operator. These errors can be fixed by adding explicit type casts. Thelegacy_varchar_typingsession setting is on by default.#137945"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.17",
        "date": "December 12, 2024",
        "changes": [
            "All cluster settings that accept strings are now fully redacted when transmitted as part of Cockroach Labs' diagnostics telemetry. The payload includes a record of modified cluster settings and their values when they are not strings. If you previously applied the mitigations in Technical Advisory 133479, you can safely set the value of cluster settingserver.redact_sensitive_settings.enabledtofalseand turn on diagnostic reporting via thediagnostics.reporting.enabledcluster setting without leaking sensitive cluster setting values.#134015",
            "COCKROACH_SKIP_ENABLING_DIAGNOSTIC_REPORTINGis no longer mentioned in thecockroach democommand.#134085",
            "Addedsystem.usersto the list of system tables that changefeeds protect with protected timestamps (PTS). This table is required for CDC queries.#134233",
            "Added a new cluster settingui.database_locality_metadata.enabled, which allows operators to disable loading extended database and table region information in the DB Console's Databases and Table Details pages. This information can cause significant CPU load on large clusters with many ranges. Versions of this page from v24.3 onwards do not have this problem. If you require this data, you can use theSHOW RANGES FROM {DATABASE| TABLE}query via SQL to compute on-demand.#134093",
            "Previously, CockroachDB could encounter an internal error of the forminterface conversion: coldata.Column isin an edge case. This is now fixed. The bug was present in versions v22.2.13 and later, v23.1.9 and later, and v23.2 and later.#133759",
            "Fixed a bug that caused incorrectNOT NULLconstraint violation errors onUPSERTandINSERT ... ON CONFLICT ... DO UPDATEstatements when those statements updated an existing row and a subset of columns that did not include aNOT NULLcolumn of the table. This bug had been present since at least v20.1.0.#133823",
            "Fixed an unhandled error that could occur when usingREVOKE ... ON SEQUENCE ... FROM useron an object that was not a sequence.#133707",
            "Addressed a panic that could occur insideCREATE TABLE ASthat occurred if sequence builtin expressions had invalid function overloads.#133867",
            "String constants can now be compared against collated strings.#134114",
            "Previously, when executing queries with index or lookup joins when the ordering needed to be maintained, CockroachDB in some cases could get into a pathological state which would lead to increased query latency, possibly by several orders of magnitude. This bug was introduced in v22.2 and is now fixed.#134364",
            "Addressed a bug withDROP CASCADEthat would occasionally panic with anun-dropped backrefmessage on partitioned tables.#134523",
            "Reduced the duration of partitions in the gossip network when a node crashes. This eliminates false positives in theranges.unavailablemetric.#134602",
            "An error message is no longer returned when a non-admin user runsDROP ROLE IF EXISTSon a user that does not exist.#134967",
            "Fixed a bug that could cause incorrect query results when the optimizer planned a lookup join on an index containing a column of typeCHAR(N),VARCHAR(N),BIT(N),VARBIT(N), orDECIMAL(M, N), and the query held that column constant to a single value (e.g., with an equality filter).#135113",
            "Fixed an unhandled error that would occur ifDROP SCHEMAwas executed on thepublicschema of thesystemdatabase, or on an internal schema likepg_catalogorinformation_schema.#135196",
            "Fixed a bug that caused incorrect evaluation of some binary expressions involvingCHAR(N)values and untyped string literals with trailing whitespace characters. For example, the expression'f'::CHAR = 'f 'now correctly evaluates totrue.#135691",
            "CockroachDB now avoids loading unnecessary file blocks shortly after a rebalance in a rare case.#134526#135303#135577",
            "Reduced the write-amplification impact of rebalances by splitting snapshot sstable files into smaller ones before ingesting them into Pebble.#134526#135303#135577"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.16",
        "date": "November 18, 2024",
        "changes": [
            "Changed the licensecockroachis distributed under to the new CockroachDB Software License (CSL).#131705#131927#131933#131981#131988#131994#131992#132000#132001#131999#132053#132803#132781",
            "The cluster settingdiagnostics.reporting.enabledis now ignored if the cluster has a Enterprise Trial or Enterprise Free license, or if the reporting job is unable to load any license at all.#132461",
            "Added the sink error metric (changefeed.sink_errors) and expanded the reporting of the internal retries metric (changefeed.internal_retry_message_count) to all changefeed sinks that perform internal retries.#132569",
            "Allowed access to DB console APIs via JWT, which can be supplied as a Bearer token in the Authorization header.#133240",
            "DB Console will reflect any throttling behavior from the cluster due to an expired license or missing telemetry data. Enterprise licenses are not affected.#131859",
            "Due to the inaccuracy of theRange Countcolumn on theDatabasespage, and the cost incurred to fetch the correct range count for every database in a cluster, this data will no longer be visible. This data is still available via aSHOW RANGESquery.#133271",
            "Fixed an error that could happen if an aggregate function was used as the value in aSETcommand.#131958",
            "Added automated clean-up/validation for dropped roles inside of default privileges.#132169",
            "Fixed a bug that could causeRESTOREto hang after encountering transient errors from the storage layer.#132260",
            "Fixed a bug that caused incorrect evaluation ofCASE,COALESCE, andIFexpressions with branches producing fixed-width string-like types, such asCHAR. In addition, theBPCHARtype has been fixed so that it no longer incorrectly imposes a length limit of1.#130898",
            "Fixed a bug that could lead to incorrect results in rare cases. The bug requires aJOINbetween two tables, with an equality between columns with equivalent, but not identical types (e.g.,OIDandREGCLASS). In addition, theJOINmust lookup an index that includes a computed column that references one of the equivalent columns. This bug has existed since before v23.1.#132510",
            "Fixed a bug that could lead to incorrect results in rare cases. The bug requires a lookup join into a table with a computed index column, where the computed column expression is composite sensitive. A composite sensitive expression can compare differently if supplied non-identical, but equivalent input values (e.g.2.0::DECIMALvs2.00::DECIMAL). This bug has existed since before v23.1.#132510",
            "Fixed a bug where a span stats request on a mixed-version cluster resulted in an NPE.#132683",
            "Thefranz-golibrary has been updated to fix a potential deadlock on changefeed restarts.#132784",
            "Fixed an issue where changefeeds would fail to update protected timestamp records in the face of retryable errors.#132774",
            "Fixed a bug that could result in changefeeds using CDC queries failing due to a system table being garbage collected.#131655",
            "Fixed a rare bug in which an update of a primary key column that is also the only column in a separate column family can sometimes fail to update the primary index. This bug has existed since v22.2. Requirements to hit the bug are:A table with multiple column families.A column family containing a single primary key column.That column family is not the first column family.That column family existed before its column was in the primary key.That column must be of typeFLOAT4/8,DECIMAL,JSON, collated string type, or array.An update that changes that column from a composite value to a non-composite value.#132123",
            "A table with multiple column families.",
            "A column family containing a single primary key column.",
            "That column family is not the first column family.",
            "That column family existed before its column was in the primary key.",
            "That column must be of typeFLOAT4/8,DECIMAL,JSON, collated string type, or array.",
            "An update that changes that column from a composite value to a non-composite value.#132123",
            "Theproretsetcolumn of thepg_catalog.pg_proctable is now properly set totruefor set-returning builtin functions.#132874",
            "Fixed a bug in the query optimizer that could cause CockroachDB nodes to crash in rare cases. The bug could occur when a query contains a filter in the formcol IN (elem0, elem1, ..., elemN)only whenNis very large, e.g., 1.6+ million, and whencolexists in a hash-sharded index or, exists in a table with an indexed, computed column dependent oncol.#133066",
            "Users with theadminrole can now runALTER DEFAULT PRIVILEGES FOR target_role ...on anytarget_role. Previously, this could result in a privilege error, which is incorrect as admins are allowed to perform any operation.#133069",
            "REASSIGN OWNED BYwill now transfer ownership of thepublicschema. Previously, it would always skip over thepublicschema even if it was owned by the target role.#133069",
            "Added a timer for inner changefeed sink client flushes. Fixed a bug where timers were not correctly registered with the metric system.#133255",
            "Fixed an error that could be caused by using anAS OF SYSTEM TIMEexpression that references a user-defined (or unknown) type name. These kinds of expressions are invalid, but previously the error was not handled properly. This will now return the correct error message.#132453",
            "Fixed a bug where backup schedules could advance a protected timestamp too early, which caused incremental backups to fail.#131389",
            "Performance has been improved during periodic polling of table history when theschema_lockedtable storage parameter is not enabled.#132240",
            "Reduced the write-amplification impact of rebalances by splitting snapshot SSTable files into smaller ones before ingesting them into Pebble.#134526"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.15",
        "date": "November 15, 2024",
        "changes": [
            "Reduced the write-amplification impact of rebalances by splitting snapshotsstablefiles before ingesting them into Pebble.#135123"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.14",
        "date": "October 31, 2024",
        "changes": [
            "Added internal client name options to distinguish backup data transfer bytes from those of other clients, such as changefeeds, for updated CockroachDB Cloudbilling metrics.#133753"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.13",
        "date": "October 17, 2024",
        "changes": [
            "The description for thecluster settingchangefeed.sink_io_workersnow lists allchangefeed sinksthat support the setting.#130372",
            "Network metrics have been added for the followingchangefeed sinks:",
            "Added two network metrics,changefeed.network.bytes_inandchangefeed.network.bytes_out. These metrics track the number of bytes sent by individualchangefeedsto the following sinks:Kafka sinks. If child metrics are enabled, the metric will have akafkalabel.Webhook sinks. If child metrics are enabled, the metric will have awebhooklabel.Pub/Sub sinks. If child metrics are enabled, the metric will have apubsublabel.SQL sink. If child metrics are enabled, the metric will have asqllabel.#130664",
            "Kafka sinks. If child metrics are enabled, the metric will have akafkalabel.",
            "Webhook sinks. If child metrics are enabled, the metric will have awebhooklabel.",
            "Pub/Sub sinks. If child metrics are enabled, the metric will have apubsublabel.",
            "SQL sink. If child metrics are enabled, the metric will have asqllabel.",
            "The newmetricchangefeed.total_rangesallows observation of the number of ranges that are watched by a changefeed aggregator. It uses the same polling interval aschangefeed.lagging_ranges, which is controlled by the changefeed optionlagging_ranges_polling_interval.#130984",
            "The following groups ofmetricsandlogshave been renamed to include the buffer they are associated with. The previous metrics are still maintained for backward compatibility.changefeed.buffer_entries.*changefeed.buffer_entries_mem.*changefeed.buffer_pushback_nanos.*#131417",
            "changefeed.buffer_entries.*",
            "changefeed.buffer_entries_mem.*",
            "changefeed.buffer_pushback_nanos.*",
            "Added timers and corresponding [metrics](/docs/v24.2/metrics.html for key parts of thechangefeedpipeline to help debug issues with feeds. Thechangefeed.stage.{stage}.latencymetrics now emit latency histograms for each stage. The metrics respect the changefeedscopelabel to debug a specific feed.#131428",
            "The newmetricranges.decommissioningshows the number of ranges with a replica on adecommissioning node.#130251",
            "The following newmetricsshow the number of RPC TCP connections established to remote nodes:rpc.connection.connected: the number of gRPC TCP level connections established to remote nodes.rpc.client.bytes.egress: the number of TCP bytes sent over gRPC on connections initiated by the cluster.rpc.client.bytes.ingress: the number of TCP bytes received over gRPC on connections initiated by the cluster.#130521",
            "rpc.connection.connected: the number of gRPC TCP level connections established to remote nodes.",
            "rpc.client.bytes.egress: the number of TCP bytes sent over gRPC on connections initiated by the cluster.",
            "rpc.client.bytes.ingress: the number of TCP bytes received over gRPC on connections initiated by the cluster.",
            "Added a new configuration parameter,server.cidr_mapping_url, which maps IPv4 CIDR blocks to arbitrary tag names.#130528",
            "Themetricssql.bytesinandsql.bytesoutare now aggregate metrics if child metrics are enabled.#130528",
            "The following newmetricstrack the number of bytes sent by an individualchangefeedto each sink:changefeed.network.bytes_inchangefeed.network.bytes_out#130664",
            "changefeed.network.bytes_in",
            "changefeed.network.bytes_out",
            "You can now set the log format for theSTDERRchangefeed sink using theformatfield in thestderrsink section of theloggingconfiguration.#131533",
            "TheDB Consolenow shows a notification if the cluster has no Enterprise license set. Refer toupcoming license changesfor more information.#130425",
            "Fixed a bug where the commandSHOW CLUSTER SETTING FOR VIRTUAL CLUSTERwould erroneously returnNULLfor some settings.#128782",
            "Fixed a bug where a node could fail to start with the errorcould not insert session ...: unexpected valueif an ambiguous result error occurred while inserting data into thesqllivenesstable.#130343",
            "Fixed a bug that could preventupgrade finalizationdue to the upgrade pre-condition for repairing descriptor corruption.#130519",
            "Fixed a rare bug where a lease transfer could lead to aside-transport update saw closed timestamp regressionpanic. The bug could occur when a node was overloaded and failing to heartbeat its node liveness record.#130790",
            "Fixed a bug that could result in the erroneous log messageexpiration of liveness record ... is not greater than expiration of the previous lease ... after liveness heartbeat.#130790",
            "Fixed a bug where queries that are not initiated within a SQL session could fail to respect a statement timeout, includingbackground jobs, queries issued by theDB Consolethat perform introspection, and theCockroachDB Cloud SQL Shell.#130790",
            "Fixed a bug where a connection could be incorrectly dropped if the client was attempting to change a schema at the same time that the same schema's objects were being dropped. [#130964][#130964]",
            "Fixed a bug that could cause the following error to be logged when executing a query underREAD COMMITTEDisolation if it involved a table withNOT NULLvirtual columns:internal error: Non-nullable column ....#131065",
            "Fixed a potential memory leak inchangefeedsthat use a cloud storage sink. The memory leak could occur if both of thecluster settingschangefeed.fast_gzip.enabledandchangefeed.cloudstorage.async_flush.enabledweretrueandif the changefeed received an error while attempting to write to the sink.#130614",
            "Fixed a bug introduced in v23.2.6, wherestatisticsforecasting could predict a result of zero rows for a downward-trending statistic whensql.stats.forecasts.max_decreaseisfalse. The setting is now enabled (set to1/3by default).#131128",
            "Fixed a bug introduced in v23.1 that can cause incorrect results in the following scenario:The query contains a correlated subquery.The correlated subquery has aGroupByorDistinctOnoperator with an outer-column reference in its input.The correlated subquery is in the input of aSELECTorJOINclause that has a filter that sets the outer-column reference equal to an inner column that is in the input of the grouping operator.The set of grouping columns does not include the replacement column explicitly.#130988",
            "The query contains a correlated subquery.",
            "The correlated subquery has aGroupByorDistinctOnoperator with an outer-column reference in its input.",
            "The correlated subquery is in the input of aSELECTorJOINclause that has a filter that sets the outer-column reference equal to an inner column that is in the input of the grouping operator.",
            "The set of grouping columns does not include the replacement column explicitly.",
            "Fixed a bug whereAWS S3 and HTTP client configurationswere not considered when implicit authentication was used.#131201",
            "Fixed a bug that could prevent achangefeedfrom resuming from a prolonged paused state.#130919"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.12",
        "date": "September 25, 2024",
        "changes": [
            "Thesession settingplan_cache_mode=force_generic_plancan now be used to force prepared statements to use a query plan that isoptimizedonce and reused in future executions without re-optimization, as long as the plan does not become stale due toschema changesor a collection of newtable statistics. The setting takes effect duringEXECUTEcommands.EXPLAIN ANALYZEnow includes aplan typefield. If a generic query plan is optimized for the current execution, theplan typewill begeneric, re-optimized. If a generic query plan is reused for the current execution without performing optimization, theplan typewill begeneric, reused. Otherwise, theplan typewill becustom.#128100",
            "Thesession settingplan_cache_mode=autocan now be used to instruct thecost-based optimizerto automatically determine whether to use \"custom\" or \"generic\" query plans for the execution of a prepared statement. Custom query plans are optimized on every execution, while generic plans are optimized once and reused on future executions as-is. Generic query plans are beneficial in cases where query optimization contributes significant overhead to the total cost of executing a query.#128100",
            "There are now structured logging events that report connection breakage duringnode shutdown. Previously, these logs existed but were unstructured. These logs appear in theOPSlogging channel. There are two new events:Thenode_shutdown_connection_timeoutevent is logged after the timeout defined by thecluster settingserver.shutdown.connections.timeouttranspires, if there are still open SQL connections.Thenode_shutdown_transaction_timeoutevent is logged after the timeout defined by thecluster settingserver.shutdown.transactions.timeouttranspires, if there are still opentransactionson those SQL connections.#128710",
            "Thenode_shutdown_connection_timeoutevent is logged after the timeout defined by thecluster settingserver.shutdown.connections.timeouttranspires, if there are still open SQL connections.",
            "Thenode_shutdown_transaction_timeoutevent is logged after the timeout defined by thecluster settingserver.shutdown.transactions.timeouttranspires, if there are still opentransactionson those SQL connections.#128710",
            "Added theranges.decommissioningmetric, representing the number ofrangeswhich have areplicaon adecommissioning node.#130413",
            "Added three new network tracking metrics:rpc.connection.connectedis the number of rRPC TCP-level connections established to remote nodes.rpc.client.bytes.egressis the number of TCP bytes sent via gRPC on connections we initiated.rpc.client.bytes.ingressis the number of TCP bytes received via gRPC on connections we initiated.cockroachdb/cockroach#130712",
            "rpc.connection.connectedis the number of rRPC TCP-level connections established to remote nodes.",
            "rpc.client.bytes.egressis the number of TCP bytes sent via gRPC on connections we initiated.",
            "rpc.client.bytes.ingressis the number of TCP bytes received via gRPC on connections we initiated.cockroachdb/cockroach#130712",
            "Added a new configuration parameterserver.cidr_mapping_url, which maps IPv4 CIDR blocks to arbitrary tag names.#130712",
            "Modified metricssql.bytesinandsql.bytesoutto be aggregation metrics If theserver.child_metrics.enabledcluster setting is enabled.#130712",
            "Added two network metrics,changefeed.network.bytes_inandchangefeed.network.bytes_out. These metrics track the number of bytes sent by individualchangefeedsto the following sinks:Kafka sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have akafkalabel.Webhook sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have awebhooklabel.Pub/Sub sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have apubsublabel.SQL sink. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have asqllabel.#130712",
            "Kafka sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have akafkalabel.",
            "Webhook sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have awebhooklabel.",
            "Pub/Sub sinks. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have apubsublabel.",
            "SQL sink. If theserver.child_metrics.enabledcluster setting is enabled, the metric will have asqllabel.#130712",
            "TheDB Consoletime-series graphs now have hover behavior that focuses on individual lines and shows values under the mouse pointer.cockroachdb/cockroach#128864",
            "Users with theVIEWACTIVITYprivilegecan downloadstatement bundlesfromDB Console.#129502",
            "TheDB Consolenow displays an alert message when thelicense is expiredor if there are fewer than 15 days left before the license expires.#130509",
            "TheDB Consolewill now show a notification alerting customers without an Enterprise license toupcoming license changeswith a link to more information.#130509",
            "Fixed a bug where declarative and legacyschema changeswere incorrectly allowed to be executed concurrently, which could lead to failing or hung schema change jobs.#128838",
            "Fixed a bug that caused errors likeERROR: column 'crdb_internal_idx_expr' does not existwhen accessing a table with anexpression indexwhere the expression evaluates to anENUMtype, e.g.,CREATE INDEX ON t ((col::an_enum)).#129092",
            "Functioninput parameters can no longer have theVOIDtype.#129281",
            "Internally issued queries that are not initiated within aSQL sessionno longer respect a statement timeout. This includes:background jobs, queries issued by theDB Consolethat perform introspection, and the CloudSQL shell.#129517",
            "Fixed a bug where theschema_lockedstorage parameterdid not prevent a table from being referenced by aforeign key.#129753",
            "Users with theVIEWACTIVITYSQL privilegecan now request, view, and cancelstatement bundlesin theDB Console.#129803",
            "Fixed a bug where alease transfercould lead to a panic with the messageside-transport update saw closed timestamp regression. The bug could occur when a node was overloaded and failing toheartbeat its node liveness record.#129808",
            "Thelog messageexpiration of liveness record ... is not greater than expiration of the previous lease ... after liveness heartbeatis no longer generated.#129808",
            "Fixed a bug where therequire_explicit_primary_keyssession variablewould prevent allCREATE TABLEstatements from working.#129906",
            "Fixed a slow-building memory leak when usingKerberos authentication.#130317",
            "Fixed a potential memory leak inchangefeeds using a cloud storage sink. The memory leak could occur if bothchangefeed.fast_gzip.enabledandchangefeed.cloudstorage.async_flush.enabledweretrue, and the changefeed received an error while attempting to write to the cloud storage sink.#130624"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.11",
        "date": "September 16, 2024",
        "changes": [
            "Internally issued queries that are not initiated within aSQL sessionno longer respect astatement timeout. This includes: backgroundjobs, queries issued by theDB Consolethat perform introspection, and theCloud SQL shell.#130525",
            "Fixed a rare bug where alease transfercould lead to aside-transport update saw closed timestamp regressionpanic. The bug could occur when a node wasoverloadedand failing to heartbeat itsnode livenessrecord.#130523",
            "Resolved a concerninglogmessage:expiration of liveness record ... is not greater than expiration of the previous lease ... after liveness heartbeat. This message is no longer possible.#130523"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.10",
        "date": "August 29, 2024",
        "changes": [
            "URLs in the following SQL statements are now sanitized of any secrets, such as keys or passwords, before being written tounredacted logs:ALTER BACKUP SCHEDULEALTER BACKUPALTER CHANGEFEED SET sinkBACKUPCOPYCREATE CHANGEFEEDCREATE EXTERNAL CONNECTIONCREATE SCHEDULE FOR BACKUPCREATE SCHEDULE FOR CHANGEFEEDEXPORTIMPORT INTORESTORESHOW BACKUPSSHOW BACKUP#127509",
            "ALTER BACKUP SCHEDULE",
            "ALTER BACKUP",
            "ALTER CHANGEFEED SET sink",
            "CREATE CHANGEFEED",
            "CREATE EXTERNAL CONNECTION",
            "CREATE SCHEDULE FOR BACKUP",
            "CREATE SCHEDULE FOR CHANGEFEED",
            "IMPORT INTO",
            "SHOW BACKUPS",
            "SHOW BACKUP#127509",
            "Added a newKafka sinkutilizing thefranz-golibrary and our ownbatching_sinkbehind acluster setting(changefeed.new_kafka_sink_enabled, disabled by default).#128048",
            "The v2 Kafka and Google Cloud Pub/Subchangefeed sinksnow display notices indicating the topics they will emit to.#128459",
            "Added thesql.auth.grant_option_for_owner.enabledcluster setting. The default value istrue, which results in behavior that matches the existing behavior of CockroachDB. When set tofalse, then theGRANT OPTIONis not implcitly given to the owner of an object. The object owner still implicitly has all privileges on the object, just not the ability to grant them to other users.#126958",
            "Fixed a bug where theDISCARDstatement was disallowed when thedefault_transaction_read_onlysession setting was set toon.#127548",
            "TheDatabasesandTablespagesin the DB Console now show a loading state while loading information for databases and tables, including size and range counts.#127709",
            "On theDatabasespagein the DB Console, table names will no longer appear with quotes around the schema and table name.#127765",
            "Fixed a bug causing gateway nodes to crash while executingINSERTstatements inREGIONAL BY ROWtables. This bug had been present since v23.2.#127276",
            "Fixed a bug wheredroppingENUMvaluesthat were referenced byindex expressionscould fail with an error.#127453",
            "Fixed a bug that caused a memory leak when executing SQL statements with comments, e.g.,SELECT /* comment */ 1;. Memory owned by a SQL session would continue to grow as these types of statements were executed. The memory would only be released when closing the SQL session. This bug had been present since v23.1.#127758",
            "Fixed a memory leak that could occur when specifying a non-existentvirtual clustername in the connection string.#128104",
            "Fixed a bug whereCREATE INDEX IF NOT EXISTSwould not correctly short-circuit if the given index already existed.#128312",
            "Fixed a bug in overly eager syntax validation, which did not allow theDESCENDINGclause for non-terminal columns of aninverted index. Only the last column of an inverted index should be prevented from beingDESCENDING, and this is now properly checked.#128312",
            "Fixed a bug where anindexcould store a column in the primary index if that column had a mixed-case name.#128312",
            "Fixed small memory leaks that would occur duringchangefeed creation.#128048",
            "Setting or dropping a default value on acomputed columnis now blocked -- even for null defaults. Previously, setting or dropping a default value on a computed column was a no-op; now there will be an error message.#128467",
            "Fixed a bug that could cause spurious user permission errors when multiple databases shared a common schema with a routine referencing a table. The bug had existed sinceuser-defined functionswere introduced in v22.2.#126413",
            "Fixed a bug where a hash-sharded constraint could not be created if it referred to columns that had a backslash in the name.#128676",
            "Fixed a bug whereTYPEDESC SCHEMA CHANGEjobs could end up retrying forever if the descriptor targeted by them was already dropped.#128461",
            "Fixed a bug in which the output ofEXPLAIN (OPT, REDACT)for variousCREATEstatements was not redacted. This bug had existed sinceEXPLAIN (REDACT)was introduced in v23.1 and affects the following statements:EXPLAIN (OPT, REDACT) CREATE TABLEEXPLAIN (OPT, REDACT) CREATE VIEWEXPLAIN (OPT, REDACT) CREATE FUNCTION#128488",
            "EXPLAIN (OPT, REDACT) CREATE TABLE",
            "EXPLAIN (OPT, REDACT) CREATE VIEW",
            "EXPLAIN (OPT, REDACT) CREATE FUNCTION#128488"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.1",
        "date": "February 20, 2024",
        "changes": [
            "Introduced theserver.redact_sensitive_settings.enabledcluster setting, which is false by default. If set totrue, then the values of the following settings will be redacted when accessed throughSHOWcommands or other introspection interfaces. In the future, any other sensitive cluster settings that are added will be redacted as well. Users who have theMODIFYCLUSTERSETTINGprivilegecan always view the unredacted settings.#117729server.oidc_authentication.client_idserver.oidc_authentication.client_secret",
            "server.oidc_authentication.client_id",
            "server.oidc_authentication.client_secret",
            "If theserver.redact_sensitive_settings.enabledcluster settingis set totrue, then theMANAGEVIRTUALCLUSTERprivilegeis required to view the values of the per-virtual-cluster overrides for sensitive cluster settings.#117729",
            "TheDB Consolesessioncookie is now markedHttpOnlyto prevent it from being read by any JavaScript code.#119249",
            "DB Consolecookies are markedSecurefor the browser when the cluster is running in secure mode.#119249",
            "Updated Go version to 1.21.3.#115339",
            "Added a newSQL functionfips_ready, which can be used to verify theFIPSreadiness of thegateway node.#115202",
            "Physical Cluster Replication (PCR)now retries for approximately 3 minutes before failing. This is increased from 20 s.#116402",
            "Fixed a bug wherechangefeedsthat targeted schema-locked tables could fail due to a very old highwater timestamp being incorrectly persisted.#117961",
            "Fixed a bug where creating achangefeedthat targeted tables with aDECIMAL(n)column (i.e., zero-scaleDECIMALcolumn),format='avro', anddiffwould cause a panic.#118895",
            "Added thesql.ttl.default_select_rate_limitcluster settingand thettl_select_rate_limittablestorage parameterto set theTTLselect rate limit. This sets the number of records per table per second per node that can be selected by theTTL job.#115801",
            "Fixed a bug inPL/pgSQLwhere altering the name of asequenceoruser-defined type (UDT)that was used in a PL/pgSQLfunctionorprocedurecould break them. This bug was only present in v23.2 alpha and beta releases.#116419",
            "Added support forIMPORT INTOon a table that has columns typed asarraysofuser-defined types(likeenums). Tables that use multiple user-defined types with the same name but differentschemasare still unsupported.#116359",
            "The newSELECT FOR UPDATEimplementation used underRead Committed isolation(and underSerializable isolationwhen theoptimizer_use_lock_op_for_serializablesession variableistrue) now locks allcolumn familiesinstead of only the first column family.#116826",
            "Fixed a bug whereSELECT FOR UPDATEunderRead Committed isolationon multi-column-family tables was not lockingcolumn familiescontaining only key columns.#116826",
            "It is now possible to runCALLstatements withEXPLAIN. TheEXPLAIN (OPT)variant will show the body of the procedure, while other variants will only show the procedure name and arguments.#116274",
            "EXPLAINoutput now contains detailed information about the plans forCASCADEactions.#117719",
            "Per-nodehot rangeslogging now logs the top 5 hot ranges on the local node instead of the top 5 hot ranges cluster-wide.#118334",
            "Added a new commandcockroach debug enterprise-check-fips, which diagnoses errors inFIPSdeployments.#115202",
            "The new flag--enterprise-require-fips-readycan be added to anycockroachcommandto prevent startup if certain prerequisites forFIPScompliance are not met.#115202",
            "cockroach workloadcommands now appropriately invoke.Closein the case of an error.#116487",
            "Updated the \"CPU Time\" label on theRuntime Dashboardto \"SQL CPU Time\" and added clarifications to its tooltip.#116449",
            "Statement bundlesare now enabled for Serverless clusters.#117529",
            "TheNetworking Dashboardis enhanced with charts that visualize number of packets received, number of receiving packets with error, number of receiving packets that got dropped, number of packets sent, number of sending packets with error, and number of sending packets that got dropped.#116712",
            "TheExplain Planstab is now shown for theStatementsandInsightspages, for Serverless clusters.#118169",
            "Fixed a durability bug inRaft logstorage, caused by incorrect syncing of filesystem metadata. Previously, it was possible to lose writes of a particular kind (AddSSTable) that were used by e.g.RESTORE. This loss was possible only under power-off or operating system crash conditions. Under such conditions, CockroachDB could enter a crash loop on node restart. In the worst case of a coordinated power-off/crash across multiple nodes this could lead to an unrecoverable loss ofRaft quorum.#115709",
            "Fixed a bug where largejobsrunning with execution locality (such as somechangefeeds) could result in thegatewaynode being assigned most of the work, causing performance degradation and cluster instability.#115388",
            "Fixed a bug that caused node crashes and panics when runningINSERTqueries onREGIONAL BY ROWtables withUNIQUEconstraints or indexes. The bug was only present in v23.2.0-beta.1.#115668",
            "Fixed a bug that existed only in v23.2 alpha and beta versions that could have caused side effects to happen out of order forPL/pgSQLroutines in rare cases.#115839",
            "Fixed a bug that existed since v23.1 that prevented naminguser-defined type (UDT)parameters when dropping auser-defined function(or procedure).#115904",
            "Fixed a bug wherescheduled jobsusingexternal storage providerscould fail shortly after node startup.#115693",
            "Locking tables (e.g., withSELECT FOR UPDATE) on the null-extended side ofouter joins(e.g., the right side of aLEFT JOIN) is now disallowed and returns an error. This improves compatibility with PostgreSQL and prevents ambiguity inlocking semantics. This bug has existed since locking withFOR UPDATEwas introduced.#115878",
            "Fixed a display bug in theDB Consolewhere because not all types ofschema changesare setting the value for the mutation ID, the value of the ID could previously show as \"with ID undefined\" on theEvents panel. Now, the notification omits the undefined value (the rest of the event notification is still displayed).#116518",
            "Fixed the formatting forPL/pgSQLroutines, which could prevent creating a routine withloop labels, and could prevent some expressions from beingredactedcorrectly. The bug only existed in v23.2 alpha and beta releases.#116713",
            "Fixed a bug that would cause a syntax error duringredactionof aPL/pgSQLroutine. The bug existed only in v23.2 alpha and beta releases.#116713",
            "Fixed a bug that would cause syntax errors when attempting toRESTOREa database withPL/pgSQLuser-defined functions (UDFs)orstored procedures. This bug only affected v23.2 alpha and beta releases.#116713",
            "UPDATE,UPSERT, andINSERT ON CONFLICTqueries are now disallowed underRead Committed isolationwhen the table contains acheck constraintinvolving acolumn familythat is updated, and the check constraint also involves a column family that isnotupdated, butisread. This is a temporary fix to prevent possible violation of the check constraint, and the restriction will be lifted in the future.#116428",
            "Previously, allAggHistogram-powered metrics were not reporting quantiles properly in theDB Console. This patch fixes the histograms so that the quantiles in DB Console are reported correctly. these histograms were only broken in theDB Console metrics dashboards, but werenotbroken in thePrometheus-compatible endpoint,/_status/vars. The list of affected metrics is shown below.#114506changefeed.message_size_histchangefeed.parallel_io_queue_nanoschangefeed.sink_batch_hist_nanoschangefeed.flush_hist_nanoschangefeed.commit_latencychangefeed.admit_latencyjobs.row_level_ttl.span_total_durationjobs.row_level_ttl.select_durationjobs.row_level_ttl.delete_duration",
            "changefeed.message_size_hist",
            "changefeed.parallel_io_queue_nanos",
            "changefeed.sink_batch_hist_nanos",
            "changefeed.flush_hist_nanos",
            "changefeed.commit_latency",
            "changefeed.admit_latency",
            "jobs.row_level_ttl.span_total_duration",
            "jobs.row_level_ttl.select_duration",
            "jobs.row_level_ttl.delete_duration",
            "Fixed a bug introduced in v23.2 that caused internal errors and panics when certain SQL queries were run with automaticindex recommendationcollection enabled.#117453",
            "Standard indexesandinverted indexesmay no longer be created onPL/pgSQLREFCURSOR[]s columns.REFCURSORcolumns themselves are not indexable.#116071",
            "Fixed a bug that prevented databaseRESTOREwhen the database contained avieworroutinethat referenced auser-defined type (UDT)in the body string. For views, this bug was introduced in v20.2, whenuser-defined types (UDTs)were introduced. For routines, this bug was introduced in v22.2, when user-defined functions (UDFs) were introduced.#116841",
            "Fixed a bug that could cause a function resolution error when attempting to use abuiltin functionlikenow()as a formatting argument to aPL/pgSQLRAISEstatement.#116825",
            "Fixed a bug where CDC custom key columns did not function correctly withCDC queries. For example,CREATE CHANGEFEED WITH key_column=..., unordered AS SELECT * FROM tablenow works correctly instead of retrying forever. Note that some functionalities with CDC custom keys are not fully supported, see#115267for more details.#116967",
            "Fixed a bug inRaft logtruncation that could lead to crash loops, and unrecoverable loss ofquorumin the unlikely worst case that allreplicasenter this crash loop. The bug manifested when a few things coincided: The cluster was running a bulk write workload (e.g.,schema change,import,RESTORE); a log truncation command was running; and the process crashed at an unfortunate moment (e.g., the process was killed, or killed itself for reasons like detecting adisk stall).#116574",
            "Fixed the value used for the total runtime on SQL statistics. This was using the wrong value previously, causing theSQL Activitypage to display values with more than 100%.#117426",
            "Fixed a bug where trying to set an emptysearch_pathsession variableresulted in an error.#117557",
            "It is now possible to assign to the parameter of aPL/pgSQLroutine. Previously, attempts to do this would result in a \"variable not found\" error at routine creation time. In addition, variable shadowing is now explicitly disabled, where previously it would cause an internal error. These bugs existed in the v23.2.0 release and the v23.2 pre-release versions.#117715",
            "Fixed a bug in therow-level TTLjobthat would cause it to skip expired rows if theprimary keyof the table included columns of thecollated stringtype. This bug was present since the initial release of row-level TTL in v22.2.0.#117512",
            "Fixed a bug where concurrentGRANTstatements can cause deadlocks.#117713",
            "CockroachDB can now transparently retry more retryable errors when performing a non-atomicCOPYcommand.#117895",
            "Fixed a bug that causedDML statementsto fail while ahash-sharded indexwas being created. The symptom of this bug was an error likecolumn \"crdb_internal_val_shard_16\" does not exist. This bug was present since v23.1.0.#118215",
            "Previously, CockroachDB could encounter the errorunable to encode table key: *tree.DTSQuerywhen operating on columns with the internalTSQuerytype in some contexts (e.g., when collectingtable statisticsor when performing aDISTINCToperation). This is now fixed. The bug had been present since v23.1 when support for the internalTSQuerytype was added.#118321",
            "Previously, in some cases CockroachDB could incorrectly evaluate queries that scanned aninverted indexand had aWHEREfilterin which two sides of theANDexpression had \"similar\" expressions (e.g.,ARRAY['str1'] <@ col AND (ARRAY['str1'] && col OR ...)); this is now fixed. The bug had been present since prior to v22.2.#118360",
            "Fixed a bug that could causeDELETEqueries sent by therow-level TTLjobto use asecondary indexrather than theprimary indexto find the rows to delete. This could lead to someDELETEoperations taking a much longer time than they should. This bug was present since v22.2.0.#118337",
            "Fixed an issue with missing data on SQL statistics, and consequently missing data on theSQL Activity page, by properly recalculating the value from the current and past hour on the top activity table.#118378",
            "Internal queries issued by therow-level TTLjobsshould now use optimal plans. The bug has been present since at least v22.2.#118494",
            "Fixed a bug where achangefeedcould omit events in rare cases, logging the errorcdc ux violation: detected timestamp ... that is less or equal to the local frontier. This could happen in the following scenario:Arangefeedruns on a followerreplicathat lags significantly behind theleaseholder.A transaction commits and removes itstransaction recordbefore itsintentresolution is applied on the follower.The follower'sclosed timestamphas advanced past the transaction commit timestamp.The rangefeed attempts to push the transaction to a new timestamp (at least 10 seconds after the transaction began).This may cause the rangefeed to prematurely emit a checkpoint before emitting writes at lower timestamps, which in turn may cause thechangefeedto drop these events entirely, never emitting them.#118981",
            "Arangefeedruns on a followerreplicathat lags significantly behind theleaseholder.",
            "A transaction commits and removes itstransaction recordbefore itsintentresolution is applied on the follower.",
            "The follower'sclosed timestamphas advanced past the transaction commit timestamp.",
            "The rangefeed attempts to push the transaction to a new timestamp (at least 10 seconds after the transaction began).",
            "This may cause the rangefeed to prematurely emit a checkpoint before emitting writes at lower timestamps, which in turn may cause thechangefeedto drop these events entirely, never emitting them.#118981"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-rc.2",
        "date": "January 9, 2024",
        "changes": [
            "The ARM image is inLimited Access.",
            "The Intel image isGenerally Availablefor production use.",
            "Fixed a bug introduced in v23.2 that caused internal errors and panics when certain queries ran with automaticindex recommendation collection enabled.#117454",
            "Fixed a bug where mixed-version clusters with both v23.1 and v23.2 nodes could detect a false-positive replica inconsistency inGLOBALtables.#117341"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-rc.1",
        "date": "December 21, 2023",
        "changes": [
            "The ARM image is inLimited Access.",
            "The Intel image isGenerally Availablefor production use.",
            "Added a SQL functioncrdb_internal.fips_ready()that can be used to verify theFIPSreadiness of the gateway node.#116281",
            "Physical cluster replicationnow retries for just over 3 minutes before failing.#116404",
            "CALLstatements can now be run withEXPLAIN. TheEXPLAIN (OPT)variant will show the body of the procedure, while other variants will show only the procedure name and arguments.#116273",
            "Added support forIMPORT INTOa table that has columns typed as arrays of user-defined types (likeENUM). Tables that use multiple user-defined types with the same name but different schemas are still unsupported.#116360",
            "TheSELECT FOR UPDATEimplementation used under Read Committed isolation (and underSerializable isolationwhenoptimizer_use_lock_op_for_serializableis set totrue) now locks allcolumn familiesinstead of only the first column family.#116828",
            "Added the commandcockroach debug enterprise-check-fipsthat diagnoses errors inFIPSdeployments.#116281",
            "Added the flag--enterprise-require-fips-readythat can be run with anyCockroachDB commandto prevent startup if certain prerequisites forFIPScompliance are not met.#116281",
            "Updated theCPU Timelabel toSQL CPU Timeand added clarification to its tooltip on theSQL ActivityandInsightspages.#116450",
            "Removed the ID when it isundefinedfrom the event description in theMetrics Events Panel.#116519",
            "Fixed a bug that caused node crashes and panics when runningINSERTqueries onREGIONAL BY ROWtables withUNIQUEconstraints or indexes. The bug is only present in version v23.2.0-beta.1.#116343",
            "UPDATE,UPSERT, andINSERT ON CONFLICTqueries are now disallowed under Read Committed isolation when the table contains aCHECKconstraintinvolving acolumn familythat is updated, and thatCHECKconstraint also involves a column family that isnotupdated, butisread. This restriction is a temporary fix to prevent possible violation of theCHECKconstraint. However, it is important to note that this restriction will be lifted in the future.#116429",
            "Fixed a bug wherescheduled jobsusingexternal storage providersmay fail shortly after node startup.#116205",
            "Fixed the formatting forplpgsqlroutines, which could prevent the creation of a routine with loop labels and could prevent some expressions from being redacted correctly. The bug only existed in alpha and beta versions of v23.2.#116711",
            "Fixed a bug that would cause a syntax error during redaction of a PL/pgSQL routine. The bug existed only in alpha and beta versions of the v23.2 release.#116711",
            "Fixed a bug that would cause syntax errors when attempting torestore a databasewithPL/pgSQL UDFsor storedprocedures. This bug only affected alpha and beta versions of v23.2.#116711",
            "Fixed a bug in PL/pgSQL where altering the name of asequenceor UDT that was used in aPL/pgSQL functionorprocedurecould break them. This is only present in v23.2 alpha and beta releases.#116420",
            "Fixed a bug whereSELECT FOR UPDATEunder Read Committed isolation on multi-column-family tables was not lockingcolumn familiescontaining only key columns.#116828",
            "Fixed a bug where allAggHistogram-powered metrics were not reporting quantiles properly in theDB Console. The quantiles in the DB Console are now reported correctly. This bug was only present in histograms in theDB Console metricsfeatures, and didnotaffect metrics reporting in thePrometheus-compatibleendpoint,/_status/vars. The affected metrics were:changefeed.message_size_histchangefeed.parallel_io_queue_nanoschangefeed.sink_batch_hist_nanoschangefeed.flush_hist_nanoschangefeed.commit_latencychangefeed.admit_latencyjobs.row_level_ttl.span_total_durationjobs.row_level_ttl.select_durationjobs.row_level_ttl.delete_duration#116871",
            "changefeed.message_size_hist",
            "changefeed.parallel_io_queue_nanos",
            "changefeed.sink_batch_hist_nanos",
            "changefeed.flush_hist_nanos",
            "changefeed.commit_latency",
            "changefeed.admit_latency",
            "jobs.row_level_ttl.span_total_duration",
            "jobs.row_level_ttl.select_duration",
            "jobs.row_level_ttl.delete_duration"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-beta.3",
        "date": "December 13, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "Updated Go version to 1.21.3.#116098",
            "Added thesql.ttl.default_select_rate_limitcluster settingand thettl_select_rate_limittable storage parameterto set the TTL select rate limit. This sets the number of records per table per second per node that can be selected by the TTL job.#115802",
            "Fixed a bug that could result in an incorrecttoo few columnserror for queries that useANY <array>syntax with a subquery.#115592",
            "Fixed a bug that could causetoo few columns/too many columnserrors for queries that usedINorNOT INwith a non-trivial right operand, such as a subquery (rather than a constant tuple).#115592",
            "Fixed a bug whereCREATE INDEXwith expressions could fail on materializedviewswhen the declarative schema changer was used.#115522",
            "Fixed a bug that could cause PL/pgSQL routines withSELECT INTOsyntax to return early. This bug existed only in pre-release versions v23.2.0-beta.1 and v23.2.0-beta.2.#115676",
            "Fixed a bug that could cause side effects to happen out of order for PL/pgSQL routines in rare cases. This bug existed only in v23.2 alpha versions and previous v23.2 beta versions.#115840",
            "Previously, in rare cases, CockroachDB could incorrectly evaluate queries with lookupjoinswhereequality cols are keywhen performing lookups on multiple ranges. This could either manifest as a stuck query or result in incorrect output. The bug was introduced in v22.2 and is now fixed.#115580",
            "Fixed a durability bug in Raft log storage that was caused by incorrect syncing of filesystem metadata. It was possible to lose writes of a particular kind (AddSSTable) used by (e.g.)RESTORE. This loss was possible only under power-off or OS crash conditions. As a result, CockroachDB could enter a crash loop on restart. In the worst case of a coordinated power-off/crash across multiple nodes, this could lead to an unrecoverable loss of quorum.#115841",
            "Fixed a bug where large jobs running withexecution localityoption could result in thegateway nodebeing assigned most of the work causing performance degradation and cluster instability.#115876",
            "Fixed a bug that prevented naming UDT parameters whendropping a user-defined function(or procedure). This bug has existed since v23.1.#115905",
            "Locking tables (e.g., withSELECT ... FOR UPDATE) on the null-extended side of outer joins (e.g., the right side of aLEFT JOIN) is now disallowed and returns an error. This improves compatibility with PostgreSQL and prevents ambiguity in locking semantics. This bug has existed since locking withFOR UPDATEwas introduced.#115879"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-beta.2",
        "date": "December 5, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "CockroachDB now periodically dumps the state of its internal memory accounting system into theheap_profiler/directory when a heap profile is taken. To disable this behavior, set thediagnostics.memory_monitoring_dumps.enabledcluster settingtofalse.#114998",
            "Multi-level compactions have been disabled to investigate possible performance issues with foreground throughput and latency.#115481",
            "When usingPhysical Cluster Replication, you can nowinitiate a cutoveras ofLATESTbefore the initial scan completes.#115101",
            "Sensitive information such asapi_secret,sasl_password,client_cert, andca_cert, is now redacted in output from commandsSHOW CHANGEFEED JOB,SHOW CHANGEFEED JOBS, andSHOW JOBS.#115567",
            "Thephysical_replication.frontier_lag_nanosmetric and the related DB Console graph have been removed because they sometimes display incorrect information. Foralerting, it is recommended to use the new metricphysical_replication.replicated_time_secondsmetric instead.#115234",
            "Fixed a bug inphysical cluster replicationwhere replicating from a primary cluster that is on a version prior to v23.2.x to a standby cluster running on v23.2.x could fail because of an undefined builtin function in the primary cluster.#114257",
            "In theChangeeds dashboard, theMax Checkpoint Latencychart title now refers to \"Lag\" rather than \"Latency\", to better reflect the intention of the underlying metric, which measures how recently the changefeed was last checkpointed.#115003",
            "Times on the X-Axis of bar charts inStatement detailspages are now correctly formatted in UTC.#115220",
            "In theSQL ActivityTransaction Detailspage, you can now view a transaction fingerprint ID across multiple applications by specifying the application name in theappNamesURLGETparameter using a comma-separated encoded string of transaction fingerprint IDs.#115204",
            "Fixed a bug that prevented theNowbutton on time range selectors in the DB Console from working as expected when a custom time period was previously selected.#115514",
            "Fixed a bug that prevented theSQL Activitypage from showing internal statements when thesql.stats.response.show_internal.enabledcluster settingwas set totrue.#114824",
            "Fixed a bug where an active replication report update could get stuck in a retry loop on clusters with over 10000 ranges. This could prevent a node from shutting down cleanly.#114178",
            "Fixed a bug introduced in v23.1 that could cause an internal error when using the text format (as opposed to binary) whenpreparing a statementwith a user-defined composite type.#115064",
            "Fixed a bug that could cause a replica to be stuck processing in a queue's replica set when the replica had recently been removed from purgatory for processing but was destroyed, or the replica's ID changed before being processed. These replicas are now removed from the queue when they are encountered.#115037",
            "Fixed a bug that could cause aprepared statementto fail if it references both anenumand a table that has undergone a schema change.#115132",
            "Fixed a bug that could cause cluster version finalization to contend with descriptor lease renewals on large clusters. Descriptor lease renewals previously had a higher priority than cluster upgrade finalization. Finalization now always has a higher priority than descriptor lease renewal.#115034",
            "Fixed a bug that preventedbackupsfrom distributing work evenly across all replicas, including followers, regardless of leaseholder placement.#115019",
            "Fixed a bug introduced in v23.2.0-beta.1 that could cause a single composite-typed variable to be incorrectly handled as the target of a PostgreSQLINTOclause.#115404",
            "Fixed a bug that could cause aBEGINstatement log to record incorrect information in theAgefield, which could also cause them to appear erroneously in slow-query logs.#115259",
            "Query planning time has been reduced significantly for some queries in which many tables are joined.#114445"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-beta.1",
        "date": "November 27, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "COPYcommands now use thebackgroundquality-of-service levelby default, which makesCOPYcommands subject toadmission control. The new session variablecopy_transaction_quality_of_servicecontrols the quality-of-service level forCOPYcommands. Previously,COPYused the same level as other commands, determined by thedefault_transaction_quality_of_servicesession variable, which is set toregularby default.regularis not subject to admission control.#114535",
            "TheOverview pagenow correctly renders the background color for the email signup, which fixes an issue where it was difficult to read the text.#114547",
            "Fixed a bug where selecting the internal application name prefix$ internalfrom theApplication Namedropdown on theSQL Activity Statementspagewas not showing internal queries. The filtering logic will now show if there are statements with the$ internalapplication name prefix.#114517",
            "Fixed a bug where an emptyrangecorresponding to aDROP TABLEdid not respect system-level span configurations such asprotected timestamps, which potentially caused reads above the protected timestamp to fail.#114833",
            "Fixed error handling forGetFilesso that it does not cause a nil pointer dereference.#114830"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.7",
        "date": "November 20, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "Previously, ifsession variableuse_declarative_schema_changerwas set tooff, thenALTER TABLE ... ALTER COLUMN ... SET NOT NULLwas run on a column which contained a NULL value, an error with code23514(check_violation) would be returned. Now in this scenario the error returned will have code 23502 (not_null_violation) to matchPostgreSQL.#113970",
            "Thesql.txn.read_committed_syntax.enabledcluster settingwas renamed tosql.txn.read_committed_isolation.enabled.#113833",
            "Thecockroach connectfunctionality has been deprecated.#114241",
            "Previously, the forward arrow button on thetime selectorwould not move the time window forward if the current end time was less than \"Now() - time window\". For example, with a 10 minute time window, it was not possible to move forward if current end time is less that \"Now() - 10 minutes\". This caused the forward arrow button to become disabled even though there was more data to display. Now this scenario is handled by the forward arrow button selecting the latest available time window (similar to theNowbutton).#113907",
            "Removed duplication of metrics names onDB Console Metricscharts' tooltips.#113728",
            "Fixed a bug that could causeALTER DATABASE ... ADD/DROP REGIONto hang ifnode localitieswere changed after regions were added.#114102",
            "A bug in thelog configurationcode prevented users from setting thedatetime-formatanddatetime-timezonelog format options(set via theformat-optionsstructure) within their log configuration. Specifically, when users tried to use these options infile-defaultswith anyjsontype log format, the log configuration was previously unable to be parsed due to validation errors. This was because thefile-defaults.format-optionswere propagated to thesinks.stderr.format-options.sinks.stderronly supports a format ofcrdb-v2-tty. Therefore, the incorrectly propagatedformat-options, which are only supported by thejsonlog format, were identified as not being supported when validatingsinks.stderr. This bug is now fixed and thefile-defaults.format-optionsare only propagated tosinks.stderr.format-optionsif both of these conditions are true: 1.file-defaults.formatis one ofcrdb-v2orcrdb-v2-tty. 2.sinks.stderr.format-optionsare not explicitly set in the log configuration.#113684",
            "Previously, when executing queries withindex joinsorlookup joinsor both when the ordering needs to be maintained, CockroachDB in some cases would get into a pathological behavior which would lead to increased query latency, possibly by one or two orders of magnitude. This bug was introduced in v22.2 and is now fixed.#114117",
            "Previously, theSHOW STATISTICS commandincorrectly required the user to have the admin role. Now, it correctly only requires the user to have anyprivilegeon the table being inspected.#114449",
            "Fixed a bug that could cause aquery planto skip scanning rows from the local region when performing alookup joinwith aREGIONAL BY ROWtableas the input.#114458",
            "This change prevents failed requests from being issued on follower nodes that aredraining, decommissioningor unhealthy which prevents latency spikes if those nodes later go offline.#114259"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.6",
        "date": "November 7, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "The CockroachDB Docker image is now based onRed Hat's ubi9/ubi-minimal imageinstead of the ubi8/ubi-minimal image.#112967",
            "Added the built-infunctionjsonb_array_to_string_arraythat convertsJSONBarray toSTRINGarray.#112865",
            "The built-infunctionjsonb_array_to_string_arraycan now returnNULLobjects.#112865",
            "Introduced thecluster settingkv.gc.sticky_hint.enabledthat helps expeditinggarbage collectionafter range deletions. For example, when a SQL table or index is dropped.kv.gc.sticky_hint.enabledis enabled by default in v23.2. The setting has been deprecated in v23.2.#113040",
            "Introduced a newenvironment variablethat allows an operator to configure thecompactionconcurrency.#113313",
            "Debug zipwill now collect the active traces of all running or reverting traceable jobs. This includesrestores,imports,backups, andphysical cluster replication.#113172",
            "Theprivilegethat controls access toCREATE VIRTUAL CLUSTERand other virtual cluster management syntax is now calledMANAGEVIRTUALCLUSTER.#113076",
            "Fixed a bug that could preventRESTOREfrom working if it was performed during a cluster upgrade.#112759",
            "Fixed a bug where the opclass for atrigram indexis not shown if CockroachDB creates a trigram index and later displays it viaSHOW CREATE TABLE.#113071",
            "Fixed a bug where CockroachDB could incorrectly evaluatelookupand indexjoinsinto tables with at least threecolumn families. This would result in either thenon-nullable column with no valueinternal error, or the query would return incorrect results. This bug was introduced in v22.2.#113105",
            "Fixed a bug whereALTER PRIMARY KEYwould incorrectly disablesecondary indexeswhile new secondary indexes were being backfilled when using thedeclarative schema changer.#112627",
            "Fixed a bug where theunique_constraint_catalogandunique_constraint_schemacolumns ininformation_schema.referential_constraintscould be incorrect for cross schema or cross database references.#112739",
            "Fixed a bug in a method that was used by some of thejobsobservability infrastructure. This method could be triggered if a file was overwritten with a different chunking strategy.#113290",
            "Fixed a bug where the result ofSHOW CREATE TABLEfor a table that had acollated string columnwith a default expression was incorrect because the statement could not be parsed.#113119",
            "Fixed the SQL activity update job to: avoid conflicts on update, reduce the amount of data cached to only what the overview page requires, and fix the correctness of the top queries.#112865",
            "Fixed a bug that could preventphysical cluster replicationfrom advancing in the face of some range deletion operations.#113041",
            "Fixed a bug whereALTER TYPEcould get stuck ifDROP TYPEwas executed concurrently.#113644",
            "Fixed a bug that could cause internal errors or panics while attempting to forecaststatisticson a numeric column.#113797",
            "Rolled back deletes no longer cause a discrepancy between computed statistics and the actual stored values.#113766",
            "Addressed a performance regression that can happen when the declarativeschema changeris used to create an index with a concurrent workload.#113725"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.5",
        "date": "October 30, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "Added support for the specialOTHERScondition in PL/pgSQL exception blocks, which allows matching any error code apart fromquery_canceledandassert_failure. Note that Class 40 errors (40000,40001,40003,40002, and40P01) cannot be caught either. This is tracked in#111446.#112817",
            "Previously, queries with theST_Unionaggregate function could produce incorrect results in some cases due to the query optimizer performing invalid optimizations. This is now fixed. This bug had been present since theST_Unionfunction was introduced in v20.2.0.#112780"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.4",
        "date": "October 23, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "Updated thelicenses/CCT.txtfile to reflect the latestCockroachdb Community License.#112494",
            "Renamedcluster settingsrelated tophysical cluster replicationfor consistency. For example,bulkio.stream_ingestion.minimum_flush_intervalis nowphysical_replication.consumer.minimum_flush_interval.#111197",
            "SHOW SCHEDULEShas two columns that surface the schedule options. These columns have been renamed to align with the documented option names:on_previous_runningandon_execution_failure.#111759",
            "Added support for thePLpgSQLCLOSEstatement, which allows a PLpgSQL routine to close a cursor with the name specified by a cursor variable.#111330",
            "When aRESTOREwithremove_regionsis performed, the restore job will now fail if the object contains aREGIONAL BY ROWtable.#111443",
            "It is now possible to open acursorwithin a PLpgSQL function or procedure with an exception block. If an error occurs, creation of the cursor is rolled back before control reaches the exception handler.#111735",
            "If ascheduled backupresumes on a new cluster (e.g., afterphysical cluster replication cutoveror a cluster restore), the backup schedule will pause. The user mayresume the schedulewithout changing it, but should take special care to ensure no other schedule is backing up to the samecollection. The user may also want to cancel the paused schedule and start a new one.#111578",
            "Added support for PLpgSQLFETCHandMOVEstatements. Similar to SQLFETCH/MOVEstatements, commands that would seek thecursorbackward will fail. In addition, expressions other than constant integers are not yet supported for thecountoption.#111318",
            "Added support for theREFCURSORdata type.REFCURSORis a special string type that is used to handle cursors. PLpgSQL cursor declarations are required to use a variable of typeREFCURSOR, and the name of a cursor can be passed to and from a PLpgSQL function or procedure.#111392",
            "Added two changes toFOR UPDATE:MultipleFOR UPDATEclauses on fully parenthesized queries are now disallowed. For example, the following statements are now disallowed:icon/buttons/copy(SELECT1FORUPDATE)FORUPDATE;SELECT*FROM((SELECT1FORUPDATE)FORUPDATE)ASx;Whereas statements like the following are still allowed:icon/buttons/copySELECT*FROM(SELECT1FORUPDATE)ASxFORUPDATE;SELECT(SELECT1FORUPDATE)FORUPDATE;This does not match PostgreSQL, which allows all of these, but does match CockroachDB behavior forORDER BYandLIMIT.FOR UPDATEis now allowed on statements withVALUESin theFROMlist, or as a subquery. For example, the following statements are now allowed:icon/buttons/copySELECT(VALUES(1))FORUPDATE;SELECT*FROM(VALUES(1))ASxFORUPDATE;UsingFOR UPDATEdirectly onVALUESis still disallowed:icon/buttons/copyVALUES(1)FORUPDATE;(VALUES(1))FORUPDATE;INSERTINTOtVALUES(1)FORUPDATE;This matches PostgreSQL.#111258",
            "MultipleFOR UPDATEclauses on fully parenthesized queries are now disallowed. For example, the following statements are now disallowed:icon/buttons/copy(SELECT1FORUPDATE)FORUPDATE;SELECT*FROM((SELECT1FORUPDATE)FORUPDATE)ASx;Whereas statements like the following are still allowed:icon/buttons/copySELECT*FROM(SELECT1FORUPDATE)ASxFORUPDATE;SELECT(SELECT1FORUPDATE)FORUPDATE;This does not match PostgreSQL, which allows all of these, but does match CockroachDB behavior forORDER BYandLIMIT.",
            "FOR UPDATEis now allowed on statements withVALUESin theFROMlist, or as a subquery. For example, the following statements are now allowed:icon/buttons/copySELECT(VALUES(1))FORUPDATE;SELECT*FROM(VALUES(1))ASxFORUPDATE;UsingFOR UPDATEdirectly onVALUESis still disallowed:icon/buttons/copyVALUES(1)FORUPDATE;(VALUES(1))FORUPDATE;INSERTINTOtVALUES(1)FORUPDATE;This matches PostgreSQL.#111258",
            "FOR UPDATEis now permitted on some queries that were previously disallowed. Queries that use the following operations are now allowed to haveFOR UPDATE OFas long as the prohibited operation is in a subquery not locked by theFOR UPDATE OF:UNIONINTERSECTEXCEPTDISTINCTGROUP BYHAVINGAggregationsWindow functionsFor example, the following query is now allowed because the subquery using the prohibited operations is not affected by theFOR UPDATE OF:icon/buttons/copySELECT*FROMt,(SELECTDISTINCT0,0UNIONSELECTa,count(*)FROMtGROUPBYaHAVINGa>0)ASuFORUPDATEOFt;This matches PostgreSQL.#111258",
            "Aggregations",
            "Window functions",
            "Identifiers after numeric constants that are not separated by whitespace are now disallowed to match PostgreSQL 15 behavior.#112021",
            "Added the new columncontention_typeto thecrdb_internal.transaction_contention_eventstable. This column indicates the type oftransaction contentionencountered. Current values areLOCK_WAITandSERIALIZATION_CONFLICT.#111685",
            "Changed the error message:statement error cannot execute FOR UPDATE in a read-only transactiontostatement error cannot execute SELECT FOR UPDATE in a read-only transactionto match PostgreSQL.#112138",
            "Added a newsession variableoptimizer_use_lock_op_for_serializable, which when set enables a new implementation ofSELECT FOR UPDATE. This new implementation ofSELECT FOR UPDATEacquires row locksafterany joins and filtering, and always acquires row locks on the primary index of the table being locked. This more closely matchesSELECT FOR UPDATEbehavior in PostgreSQL, but at the cost of more round trips from gateway node to replica leaseholder. Under read-committed isolation (and other isolation levels weaker than serializable), CockroachDB will always use this new implementation ofSELECT FOR UPDATEregardless of the value ofoptimizer_use_lock_op_for_serializableto ensure correctness.#112138",
            "Added a newcluster settingserver.http.base_paththat controls the redirection of the browser after successful login withOIDC SSO. It is unlikely that this setting would need adjustment. However, it is helpful in cases where CockroachDB is running behind a load balancer or proxy that serves CockroachDB under a subpath, such ashttps:// <hostname>/crdb/. In those cases, it is necessary for the browser to redirect to/ crdbafter login instead of/, which has always been the hard-coded default.#111283",
            "The following settings can now only be set from the system virtual cluster:All thephysical_replication.*settingsserver.rangelog.ttltimeseries.storage.*#111769",
            "All thephysical_replication.*settings",
            "server.rangelog.ttl",
            "timeseries.storage.*",
            "Thecluster settingscluster.organizationandenterprise.licensecan now only be set via the system virtual cluster. Attempting to set them from any other virtual cluster results in an error.#111788",
            "A new flag--internal-rpc-port-rangeallows operators to specify the port range used by virtual clusters for node-to-node communication. Users implementingphysical cluster replicationor cluster virtualization public preview features should use this flag if they require thecockroachprocesses to only communicate using ports in a known port range.#111798",
            "Two guardrails are available to system operators to help with users upgrading from a deployment without cluster virtualization enabled to a deployment using cluster virtualization. This is intended to help in cases where the user is not connected to the correct SQL interface to perform certain configuration operations. There are two guardrails included:Thesql.restrict_system_interface.enabledcluster setting encourages users to use a virtual cluster for their application workload. When set, certain common operations that end users may execute to set up an application workload are disallowed, such as running DDL statements or modifying an application level cluster setting. Users will receive an error similar to:ERROR: blocked DDL from the system interface SQLSTATE: 42501 HINT: Object creation blocked via sql.restrict_system_interface.enabled to prevent likely user errors. Try running the DDL from a virtual cluster instead.Thesql.error_tip_system_interface.enabledcluster setting enhances errors reported when a user mistakenly uses a storage-level SQL feature within any virtual cluster besides the system virtual cluster. For example, when attempting to modify a cluster setting that was previously at the application level, an error like the following occurs:NOTICE: ignoring attempt to modify \"kv.rangefeed.enabled\" HINT: The setting is only modifiable by the operator. Normally, an error would be reported, but the operation is silently accepted here as configured by \"sql.error_tip_system_interface.enabled\".For a cluster setting that was always system-level, an error like the following occurs:ERROR: cannot modify storage-level setting from virtual cluster SQLSTATE: 42501 HINT: Connect to the system interface and modify the cluster setting from there.#111568",
            "Thesql.restrict_system_interface.enabledcluster setting encourages users to use a virtual cluster for their application workload. When set, certain common operations that end users may execute to set up an application workload are disallowed, such as running DDL statements or modifying an application level cluster setting. Users will receive an error similar to:ERROR: blocked DDL from the system interface SQLSTATE: 42501 HINT: Object creation blocked via sql.restrict_system_interface.enabled to prevent likely user errors. Try running the DDL from a virtual cluster instead.",
            "Thesql.error_tip_system_interface.enabledcluster setting enhances errors reported when a user mistakenly uses a storage-level SQL feature within any virtual cluster besides the system virtual cluster. For example, when attempting to modify a cluster setting that was previously at the application level, an error like the following occurs:NOTICE: ignoring attempt to modify \"kv.rangefeed.enabled\" HINT: The setting is only modifiable by the operator. Normally, an error would be reported, but the operation is silently accepted here as configured by \"sql.error_tip_system_interface.enabled\".",
            "For a cluster setting that was always system-level, an error like the following occurs:ERROR: cannot modify storage-level setting from virtual cluster SQLSTATE: 42501 HINT: Connect to the system interface and modify the cluster setting from there.#111568",
            "The predefined config profiles related to cluster virtualization now automatically set the newcluster settingssql.restrict_system_interface.enabledandsql.error_tip_system_interface.enabled.#111568",
            "The hidden--secondary-tenant-port-offsetoption has been removed. Users who were previously using this option should use--internal-rpc-port-rangeinstead.#112050",
            "Added support for automatic finalization of a virtual cluster's version upgrade. A new settingcluster.auto_upgrade.enabledwas added to enable and disable automatic cluster version upgrade (finalization). It will be used in automatic upgrade of both the storage cluster and its virtual clusters.#102427",
            "cockroach debug ziphas an additional flag that is default offinclude-running-job-tracesthat will enable collecting the in-flight traces of traceable jobs, such asbackup,restore,import,physical cluster replicationand dump them in ajobs/subdirectory in the zip.#112644",
            "TheJobstablewill now correctly display timestamps for creation, last modified, and the completed time fields.#110366",
            "Thetransaction insight detailswill show the following details when CockroachDB has information on a transaction execution with a40001error code and it has captured the conflicting transaction meta details (only available if the transaction had not yet committed at the time of execution). A section calledFailed Executionwill appear when this information is available and it will contain:Blocking transaction execution IDBlocking transaction fingerprint IDConflict locationDatabase, table, and index names#111873",
            "Blocking transaction execution ID",
            "Blocking transaction fingerprint ID",
            "Conflict location",
            "Database, table, and index names#111873",
            "Added progressive loading functionality to theDatabases page.#110901",
            "Fixed a bug inphysical cluster replicationwhere the primary cluster would not be able to takebackupswhen a primary cluster node was unavailable.#111337",
            "Fixed a bug intransaction insight detailswhere it was possible to see the contention details of other transactions. Now, CockroachDB will only surface contention details for the current transaction.#111867",
            "Voter constraintswill now be satisfied by promoting existing non-voters. Previously, there was a bug where voter constraints were never satisfied due to all existing replicas being considered necessary to satisfy a replica constraint.#111609",
            "Fixed a bug whereindoptioninsidepg_indexwas not properly encoded causing clients to be unable to decode it asint2vector.#111911",
            "This patch fixes an issue where theoptimizerfails to honor thestatement_timeoutsession setting when generating constrained index scans for queries with largeINlists or= ANYpredicates on multiple index key columns, which may lead to an out of memory condition on the node.#111979",
            "This patch fixes a performance issue in join queries with aLIMITclause, where theoptimizermay fail to push aWHEREclause filter into a join due to how theLIMIToperation is internally rewritten. This causes a full scan of the table referenced in the filter.#110593",
            "Fixed a bug that caused internal errors during query optimization in rare cases. The bug has been present since version v2.1.11, but it is more likely to occur in version v21.2.0 and later, though it is still rare. The bug only presents when a query containsminandmaxaggregate functions.#112255",
            "This patch adds support for insert fast-path uniqueness checks onREGIONAL BY ROWtables where the source is aVALUESclause with a single row. This results in a reduction in latency for single-row inserts toREGIONAL BY ROWtables and hash-shardedREGIONAL BY ROWtables with unique indexes.#111822",
            "Finn Mattis (first-time contributor)"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.3",
        "date": "October 10, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "The direct export of traces to Jaeger and thecluster settingtrace.jaeger.agenthave been removed. The direct export functionality had been obsoleted since 2022; it stopped working altogether sometime in 2023 with the following error:data does not fit within one UDP packet; size 65006, max 65000, spans NN. Since 2022, Jaeger supports ingestion of traces using OTLP; and CockroachDB has supported emitting traces using OTLP since v22.1. Operators and developers who want to inspect traces are thus invited to use the OTLP protocol instead. The corresponding cluster setting istrace.opentelemetry.collector. For a successful deployment, an intermediate OTLP collector/forwarder should be configured.You can orchestrate the OpenTeletry collector and Jaeger together using Docker Compose by adapting the following example:otel-collector:image:otel/opentelemetry-collector-contribcontainer_name:otel-collectorvolumes:-./otel-collector-config.yaml:/etc/otelcol-contrib/config.yamlports:-1888:1888# pprof extension-8888:8888# Prometheus metrics exposed by the collector-8889:8889# Prometheus exporter metrics-13133:13133# health_check extension-4317:4317# OTLP gRPC receiver-4318:4318# OTLP http receiver-55679:55679# zpages extensionjaeger:image:jaegertracing/all-in-onecontainer_name:jaegerports:-\"16685:16685\"-\"16686:16686\"-\"14250:14250\"-\"14268:14268\"-\"14269:14269\"-\"6831:6831/udp\"environment:-COLLECTOR_ZIPKIN_HTTP_PORT=9411-COLLECTOR_OTLP_ENABLED=trueTo configure theotel-collector, you can adapt this example:receivers:otlp:# the OTLP receiver the app is sending traces toprotocols:grpc:http:processors:batch:exporters:otlp/jaeger:# Jaeger supports OTLP directlyendpoint:http://jaeger:4317tls:insecure:trueservice:pipelines:traces/dev:receivers:[otlp]processors:[batch]exporters:[otlp/jaeger]",
            "You can orchestrate the OpenTeletry collector and Jaeger together using Docker Compose by adapting the following example:",
            "To configure theotel-collector, you can adapt this example:",
            "Changefeedsnow support theconfluent-cloud://sink scheme. This scheme can be used to connect to Kafka hosted on Confluent Cloud. The scheme functions identically to Kafka, but it has it's own authentication parameters. Namely, it requiresapi_keyandapi_secretto be passed as parameters in the sink URI. They must be URL encoded. An example URI is:'confluent-cloud://pkc-lzvrd.us-west4.gcp.confluent.cloud:9092?api_key=<KEY>&api_secret=<SECRET>'. By default, the optionstls_enabled=true,sasl_handshake=true,sasl_enabled=true, andsasl_mechanism=PLAINare applied. For more information about authenticating with Confluent Cloud, see https://docs.confluent.io/platform/current/security/security_tutorial.html#overview. The sink scheme still supports non-authentication parameters such astopic_nameandtopic_prefix. It also supports the standard Kafka changefeed options (ex.kafka_sink_config).#111368",
            "TheRESTOREoptionstrip_localities, which was added in#110606, has been renamed toremove_regions. This option will lead to a \"region-less restore\"; it is used to strip the locality and region information from a backup when there are mismatched cluster regions between the backup's cluster and the target cluster. Note that a restore using this option will fail if the backup's cluster hadREGIONAL BY ROWtable localities. This is because theRESTOREstatement has a contract that all tables must be available to serve writes once it finishes.#111356",
            "Added initial support for executing the PLpgSQLOPENstatement, which allows a PLpgSQL routine to create acursor. Currently, opening bound or unnamed cursors is not supported. In addition,OPENstatements cannot be used in a routine with an exception block.#110709",
            "Added support for declaring boundcursors, which associate a query with a cursor in a PLpgSQL routine before it is opened.#111092",
            "TheSELECT FOR SHAREandSELECT FOR KEY SHAREstatements previously did not acquire any locks. Users issuing these statements would expect them to acquire shared locks (multiple readers allowed, but no writers). This patch switches over the behavior to acquire such read locks when the user has selected theREAD COMMITTEDisolation level. For serializable transactions, we default to the previous behavior, unless theenable_shared_locking_for_serializablesession settingis set totrue.#109638",
            "When a PLpgSQL exception handler catches an error, it now rolls back any changes to database state that occurred within the block. Exception blocks are not currently permitted to catch40001and40003errors.#110998",
            "Added support for unnamed PLpgSQLcursors, which generate a unique name when no cursor name was specified.#111329",
            "Fixed a bug that caused CockroachDB to stop collecting new statistics aboutStatement fingerprintsandTransaction fingerprints.#111613",
            "Make themax_event_frequencymetricvisible for public documentation and usage. This is the maximum event frequency at which we sample executions for telemetry.#111594",
            "Added the followingmetricsforRaftproposals and reproposals:raft.commands.proposed,raft.commands.reproposed.unchanged, andraft.commands.reproposed.new-lai.#111272",
            "Removed thecluster settingspanconfig.store.enabledand the ability to use theCOCKROACH_DISABLE_SPAN_CONFIGSenvironment variable.#110253",
            "Renamed themetricfluent.sink.conn.errorstolog.fluent.sink.conn.errors. The addition of thelog.prefix was to better group together logging-related metrics. The behavior and purpose of the metric remains unchanged.#111126",
            "Set the Metric Type metadata on themetriclog.fluent.sink.conn.errors. Previously, the Metric Type was incorrectly left unset. Note that this is an update to the metric's metadata; the behavior and purpose of the metric remains unchanged.#111126",
            "Added a newmetriclog.buffered.messages.dropped. Buffered network logging sinks have amax-buffer-sizeattribute, which determines, in bytes, how many log messages can be buffered. Anyfluent-serverorhttp-serverlog sink that makes use of abufferingattribute in its configuration (enabled by default) qualifies as a buffered network logging sink. If this buffer becomes full, and an additional log message is sent to the buffered log sink, the buffer would exceed thismax-buffer-size. Therefore, the buffered log sink drops older messages in the buffer to handle, in order to make room for the new.log.buffered.messages.droppedcounts the number of messages dropped from the buffer. Note that the count is shared across all buffered logging sinks.#111126",
            "Added themetriclog.messages.count. This metric measures the count of messages logged on the node since startup. Note that this does not measure the fan-out of single log messages to the various configuredlogging sinks. This metric can be helpful in understanding log rates and volumes.#111126",
            "Added thefile-based-headersfield found in thehttp-defaultssection of the log config, which accepts 'key-filepath' pairs. This allows values found at filepaths to be updated without restarting the cluster by sendingSIGHUPto notify that values need to be refreshed.#111235",
            "Added thecluster settingkv.snapshot.ingest_as_write_threshold, which controls the size threshold below which snapshots are converted to regular writes. It defaults to100KiB.#110943",
            "The name of the virtual cluster that the SQL client is connected to can now be inspected via the SQLsession variablevirtual_cluster_name.#111565",
            "The followingcluster settingshave been renamed; the previous names remain available for backward-compatibility.#109415Previous nameNew Nameserver.shutdown.drain_waitserver.shutdown.initial_waitserver.shutdown.lease_transfer_waitserver.shutdown.lease_transfer_iteration.timeoutserver.shutdown.query_waitserver.shutdown.transactions.timeoutserver.shutdown.connection_waitserver.shutdown.connections.timeoutserver.shutdown.jobs_waitserver.shutdown.jobs.timeout",
            "Fixed an error on theSQL Activity pagewhen there was a workload, and then the workload stopped so that no queries ran against the database in the last hour.#111420",
            "On theMetrics page, now the information about which metric is used to create each chart is available on the chart's tooltip.#111469",
            "Fixed the error message that is returned when the user attempts to drop anENUMvalue that is used at least twice in anARRAYcolumn.#111354",
            "Added a check for values before usingmeanon thePlan Details page, fixing a crash.#111472",
            "Fixed the metric name forSchema Registry Registrationson theMetrics page.#111469",
            "Fixed a panic that could occur if a query used astringlarger than 2^31-1 bytes. This was triggered by attempting toimporta 2.7 GiB CSV file.#111627",
            "Fixed a bug whereatttypmodinpg_attributewas not populated forTIMESTAMP/INTERVALtypes, which meant that ORMs could not know the precision of these types properly.#111400"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.2",
        "date": "October 2, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "TheSIGHUPsignal now clears the cached expiration times forclient certificatesthat are reported by thesecurity.certificate.expiration.clientmetric.#110726",
            "Increased the maximum permitted value of theCOCKROACH_RPC_INITIAL_WINDOW_SIZEenvironment variable to 64MB. In conjunction with tuning your operating system's maximum TCP window size, this can increase the throughput that Raft replication can sustain over high latency network links.#111255",
            "Thediscardlog messageis now limited to once per minute by default. The message now includes both the number of transactions and the number of statements that were discarded.#110805",
            "Thecluster settingkv.rangefeed.enabledno longer controls access toRANGEFEED SQLcommands. Instead, usefeature.changefeed.enabled.#110676",
            "SQL commands that were previously limited to theadminsystem privilegecan now be used by users with theVIEWCLUSTERMETADATAorREPAIRCLUSTERMETADATAsystem privilege, depending on whether the operation is read-only or modifies state.#110084",
            "Added alast_errorcolumn to thecluster_execution_insights,node_execution_insights,cluster_txn_execution_insights, andnode_txn_execution_insightstables. These columns contain error messages for failed executions.#110565",
            "The new backup optionupdates_cluster_monitoring_metricstracks the timestamp of the last backup failure due to a KMS error. This option is disabled by default.#104634",
            "The new restore optionstrip_localitiesoptionally strips the locality information from a backup when restoring to a cluster with different regions than the source cluster.",
            "To restore a cluster with regional-by-row tables, you must drop the zone config of the database, then drop the typed.public.crdb_internal_region.",
            "To restore a database that contains regional-by-row tables, or to restore a regional-by-row table, you must drop the typed.public.crdb_internal_region.",
            "You must alter thecrdb_regioncolumn to set the default region for newly-written rows.",
            "You must discard the previous zone config, which contains outdated information, such as that related to the partitions and constraints after the restore. This column specifies each row's home region and is a prefix to the table's primary key. Stripping localities does not modify this column, because it would require the entire table to be written.",
            "Added a check to disallow queries that use predicate locking, since explicit uniqueness checks are not yet supported under Read Committed isolation.INSERT,UPDATE, andUPSERTstatements against someREGIONAL BY ROWtables will fail under Read Committed isolation with the following error:",
            "Removed the node-levelengine.stallstimeseries metric. This metric has not been updated for several releases.#110936",
            "The legend is now always displayed on charts in DB Console Metrics pages. In addition, when you select an item from the legend that represents a single line in the chart, that line is selected in the chart.#110809",
            "When collecting astatement bundle, you can now filter by a specificplan gistor collect diagnostics for all plan gists.#110931",
            "StatementandTransactiondetail pages now include anError Messagerow. Users with theVIEWACTIVITYsystem privilegecan view the full error message, and users with theVIEWACTIVTYREDACTEDsystem privilege can view the redacted error message. If a user has both privileges,VIEWACTIVITYTREDACTED` takes precedence.#110849",
            "A new dashboard in theSQL Dashboard pagetracks how often distributed queries with errors were rerun using the \"rerun as local\" mechanism, as well as how often those reruns failed. the number of times distributed queries that resulted in errors were rerun as local as well as when those reruns failed. The \"rerun as local\" mechanism is new in v23.2 and is enabled by default. For more information, contact your Cockroach Labs account representative.#110619",
            "The DB ConsoleInsights pagenow shows the error message when a transaction fails at theCOMMITstage.#110898",
            "TheOverload Dashboard pagenow includes the following graphs to monitoradmission control:IO Overload- Charts normalized metric based on admission control target thresholds. ReplacesLSM L0 Healthgraph which used raw metrics.KV Admission Slots Exhausted- ReplacesKV Admission Slotsgraph.Flow Tokens Wait Time: 75th percentile- Use to monitor the new replication admission control feature.Requests Waiting For Flow Tokens- Use to monitor the new replication admission control feature.Blocked Replication Streams- Use to monitor the new replication admission control feature.#110135",
            "IO Overload- Charts normalized metric based on admission control target thresholds. ReplacesLSM L0 Healthgraph which used raw metrics.",
            "KV Admission Slots Exhausted- ReplacesKV Admission Slotsgraph.",
            "Flow Tokens Wait Time: 75th percentile- Use to monitor the new replication admission control feature.",
            "Requests Waiting For Flow Tokens- Use to monitor the new replication admission control feature.",
            "Blocked Replication Streams- Use to monitor the new replication admission control feature.#110135",
            "Fixed a race condition in theReplica lifecyclethat could result in a failed SQL request when the request could have been successfully retried.#110806",
            "Fixed a bug where aCREATE TABLEcommand with anIDENTITYcolumn did not properly propagate the type of the column into the sequence.#110621",
            "Fixed a panic when decoding a gist in a foreign database that does not contain a table referred to by the gist.#110966",
            "A syntheticdroppedcolumn have been added to thepg_attributetable. This column tracks the attribution numbers for dropped attributions, to work around issues with ORMs that are not designed to handle gaps in attribution numbering in thepg_attributetable.#111019",
            "Fixed a rare internal error in theunnestandinformation_schema._pg_expandarraybuilt-in functionswhere passed string arguments could be cast to an array.#110956",
            "External connection URLs now accept the schemeazure-blobfor connections to Azure Blob Storage and the schemeazure-kmsfor connections to Azure KMS. For backward compatibility, schemesazureandazure-storageschemes continue to work for connections to Azure Blob Storage.#111217",
            "Fixed a bug where vectorizedCOPY FROMcould produce a plan with more than one RenderNodes, when only zero or one should be allowed. This could result in multiple render nodes in a table with a hash sharded primary key.#111284",
            "Fixed a bug in DB Console's Statement Diagnostic page that could cause the page to crash if the response was larger than 50 KB. The page now keeps pulling results until no maximum size errors are encountered.#111128",
            "Fixed a bug where DB Console instances proxied at different subpaths that use OIDC pointed to an incorrect relative OIDC login path.#111240",
            "Fixed a bug where changing the settingserver.telemetry.hot_ranges_stats.intervalhad no effect.#111305",
            "Fixed a performance bug that could result in rewriting a 128-MB file each time a store file is created, renamed, or removed whenEncryption At Restis enabled on a large store with many small files.#111069",
            "Improved compaction heuristics to mitigate read amplification growth and admission control throttling when processing large deletes, such as during node decommissioning, replica rebalancing, or when dropping tables.#111277"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0-alpha.1",
        "date": "September 26, 2023",
        "changes": [
            "The ARM image isExperimentaland not yet qualified for production use and not eligible for support or uptime SLA commitments.",
            "The Intel image isGenerally Availablefor production use.",
            "The pre-v23.1 output produced bySHOW RANGES,crdb_internal.ranges, andcrdb_internal.ranges_no_leaseswas deprecated in 23.1 and is now replaced by default with output that's compatible with coalesced ranges (i.e., ranges that pack multiple tables/indexes/partitions into individual ranges). See thev23.1 release notesforSHOW RANGESfor more details.#102961",
            "When a deployment is configured to use a time zone (new feature) for log file output using formatscrdb-v1orcrdb-v2, it becomes impossible to process the new output log files using thecockroach debug merge-logscommandfrom a previous version. The newestcockroach debug merge-logscode must be used instead.#104265",
            "When customizing theSQL shell's interactive prompt, the special sequence%Mnow expands to the full host name instead of the combination of host name and port number. To include the port number explicitly, use%>. The special sequence%mnow expands to the host name up to the first period.#105137",
            "Thecockroach debug zipcommand stores data retrieved from SQL tables in the remote cluster using the TSV format by default.#107474",
            "Thechangefeed.protect_timestamp.max_agecluster settingwill only apply to newly created changefeeds in v23.2. For existing changefeeds, you can set theprotect_data_from_gc_on_pauseoption so that changefeeds do not experience infinite retries and accumulate protected change data. You can use theALTER CHANGEFEEDstatement to addprotect_data_from_gc_on_pauseto existing changefeeds.#103539",
            "Thechangefeed.new_pubsub_sink_enabledcluster setting is now enabled by default, which improves changefeed throughput. With this setting enabled, the top-level fields in JSON-encoded messages are capitalized:{Key: ..., Value: ..., Topic: ...}. After upgrading to CockroachDB v23.2, you may need to reconfigure downstream systems to parse the new message format. If you disable this setting, changefeeds emitting to Pub/Sub sinks with JSON-encoded events have the top-level message fields all lowercase:{key: ..., value: ..., topic: ...}.",
            "Users who have theCREATEROLErole optioncan now grant and revoke role membership in any non-admin role. This change also removes thesql.auth.createrole_allows_grant_role_membership.enabledcluster setting, which was added in v23.1. In v23.2, the cluster setting is effectively always true.#104376",
            "You can now setDockercommand arguments using theCOCKROACH_ARGSenvironment variable.#98899",
            "Extended the/api/v2/nodesAPI endpointwith astoreMetricsfield.#98208",
            "CockroachDB would previously use separaterangesfor each table, index, or partition. This is no longer true. It is possible now to have multiple tables, indexes, and partitions get packed into the same range. For users with many of these schema objects, this will reduce the total range count in their clusters. This is especially true if individual tables, indexes, or partitions are smaller than the default configured maximum range size (controlled usingzone configs, specifically therange_max_bytesparameter). We made this change to improve scalability with respect to the number of schema objects, since the underlying range count is now no longer a bottleneck. Users upgrading from v22.2, when finalizing their upgrade, may observe a round of range merges and snapshot transfers (to power said range merges) as a result of this change. If users want to opt-out of this optimization, they can configure the following cluster setting:SET CLUSTER SETTING spanconfig.storage_coalesce_adjacent.enabled = false;#98820",
            "EXPORT INTO PARQUETwill now use a new internal implementation for writing Parquet files using the Parquet spec version 2.6. There should be no significant impact to the structure of files being written. There is one minor change: all columns written to Parquet files will be nullable (i.e., the Parquet repetition type isOPTIONAL).#104234",
            "Spatial librariesfor CockroachDB now rely on GEOS 3.11 instead of GEOS 3.8.#106642",
            "CockroachDB no longer distributeslibgeosfor the experimentalWindows build. Users can instead install GEOS directly from the source:https://libgeos.org/usage/download/.#106642",
            "The Formatting of byte figures in Pebble logs has been improved. Tools that parse these logs might need updating.#107392",
            "CockroachDB now has a newCLI option,--experimental-shared-storageto rebalance data faster from node to node.#105839",
            "Fixed a bug where, internally, if we print a 0 decimal with a very low exponent we use excessive memory. This is not possible when using theDECIMALtype, but may be possible when usingcrdb_internalfunctions.#110527",
            "Thekafka_sink_configCompressionandRequiredAcksoptions are now case-insensitive.#100929",
            "Changefeedsemit significantly fewer duplicate messages during node and cluster restarts.#102717",
            "CockroachDB has a newchangefeed.protect_timestamp.max_agesetting (by default 4 days), which will cancel running changefeed jobs if they fail to make forward progress for a period of time. This setting is used if the explicitgc_protect_expires_afteroption is not set. In addition, theprotect_data_from_gc_on_pauseoption has been deprecated. This option is no longer needed since changefeed jobs always protect data.#103539",
            "Changefeeds now officially support the Parquet format using specification version 2.6. It is only usable with thecloud storage sink. The syntax to use Parquet is:CREATE CHANGEFEED FOR foo INTO ... WITH format=parquet. It supports all standard changefeed options and features including CDC transformations, except it does not support thetopic_in_valueoption.#104528",
            "Changefeeds that create files over an HTTP connection may now be specified usingINTO 'file-https://'to disambiguate withwebhook-https.#107572",
            "Thepgcryptofunctionsencrypt,encrypt_iv,decrypt, anddecrypt_ivare now implemented. These functions require an enterprise license on a CCL distribution.#105654",
            "CockroachDB now paces the rangefeed goroutine creation rate to improve scheduler latency. This improves observability by adding an additional column in thecrdb_internal.active_rangefeedtable to indicate if the range is currently in catchup scan mode.#109346",
            "Fixed the helper message onUPDATESQL statements to include the optional FROM cause.#98709",
            "CockroachDB now supports enabling forwardindexesand ordering onJSONvalues.#99275",
            "Added a new columnvisibilitytocrdb_internal.table_indexesandinformation_schema.statistics. Also added a new columnvisibilityto the output of following SQL statements:icon/buttons/copySHOWINDEXFROM(table_name);SHOWINDEXESFROM(table_name);SHOWKEYSFROM(table_name);SHOWINDEXFROMDATABASE(database_name);SHOWINDEXESFROMDATABASE(database_name);SHOWKEYSFROMDATABASE(database_name);This new column contains a floating point number specifying the level of visibility of the index, from 0 (not visible) to 1 (fully visible). If the value is between 0 and 1, the index will be visible to the corresponding fraction of queries.#101334",
            "ALTER INDEX ... VISIBILITY ...is now supported. It can change an index visibility to any visibility between 0.0 and 1.0. Visibility 0.0 means the index is not visible to theoptimizer, while visibility 1.0 means the index is fully visible. A value in the range between 0.0 and 1.0 means the index will be visible to the corresponding fraction of queries.#87301",
            "CockroachDB now has support for non-aggregate expressions involving columns outside of the grouping columns when the grouping columns include all key columns of a unique index and those key columns are not nullable.#101675",
            "CockroachDB now supportsCREATE INDEX ... VISIBILITY ...andCREATE TABLE ... (... INDEX (...) VISIBILITY ...). This allows users to set the index visibility to any visibility between 0.0 and 1.0. Visibility 0.0 means the index is not visible to the optimizer, while visibility 1.0 means the index is fully visible. A value in the range between 0.0 and 1.0 means the index will be visible to the corresponding fraction of queries.#101812",
            "Row level TTLnow supportsDESCorder primary key columns.#101869",
            "Added theST_BdPolyFromTextbuilt-inwhich copies the behavior of the PostGIS function. Takes in only a multilinestring geometry and returns a polygon. It will return an error if anything other than a multilinestring is input, and will return an error if internally a multipolygon is created for some reason.NULLinputs also returnNULL.#102708",
            "SHOW SCHEDULESnow shows the schedule options with which the schedules were created.SHOW SCHEDULES FOR BACKUPadditionally shows if the schedule is a full or incremental backup schedule.#102890",
            "You can no longer usePREPAREwithEXPLAIN ANALYZEstatements. Previously, this was allowed, but attempts toEXECUTEthe preparedEXPLAIN ANALYZEstatements would result in an error.#103259",
            "ttl_expiration_expressionnow allows stable operators and functions. This allows intervals to be directly added toTIMESTAMPTZexpressions. Seehttps://www.postgresql.org/docs/15/xfunc-volatility.html.#102974",
            "CockroachDB now allowsINSERTcommands inUDFstatement bodies.#102773",
            "CockroachDB now allowsUPDATEandUPSERTcommands in UDF statement bodies.#102773",
            "TheREAD COMMITTEDisolation levelis now supported. It can be used in the following ways:When starting a transaction, useBEGIN ISOLATION LEVEL READ COMMITTED.After starting a transaction, but before performing reads or writes, useSET TRANSACTION ISOLATION READ COMMITTED.Configure it as the default isolation level using thedefault_transaction_isolationsession variable. To see the isolation level of the currently running transaction, use eitherSHOW TRANSACTION ISOLATION LEVELorSHOW transaction_isolation.#103482",
            "When starting a transaction, useBEGIN ISOLATION LEVEL READ COMMITTED.",
            "After starting a transaction, but before performing reads or writes, useSET TRANSACTION ISOLATION READ COMMITTED.",
            "Configure it as the default isolation level using thedefault_transaction_isolationsession variable. To see the isolation level of the currently running transaction, use eitherSHOW TRANSACTION ISOLATION LEVELorSHOW transaction_isolation.",
            "Added version gates which require all nodes in a given cluster to have a minimum binary version number, which in turn is required for creating forward indexes on JSON columns and for ordering JSON columns.#101932",
            "CockroachDB now allowsDELETEcommands in UDF statement bodies.#103531",
            "Added a new cluster settingsql.auth.public_schema_create_privilege.enabledwhich controls whether users receiveCREATEprivilegeson the public schema or not. The setting applies at the time that the public schema is created, which happens whenever a database is created. The setting istrueby default.#103598",
            "EXPLAIN (DDL)statements now have descriptor, index, column, constraint, and other ID values decorated with names when available. There is now also a newEXPLAIN (DDL, SHAPE)statement that provides information on costly operations planned by the declarative schema changer, like which index backfills and validations will get performed.#103930",
            "A new statisticKV pairs readis now exposed onEXPLAIN ANALYZEoutput in some cases (when this number is different from theKV rows readstatistic or when theVERBOSEoption is requested). This new statistic is also added to the telemetry sampled query events.#104079",
            "TheKV rows readstatistic inEXPLAIN ANALYZEoutput has been renamed toKV rows decodedto better reflect its meaning.#104079",
            "Table names are now allowed inSELECTlists insideviewand UDF definitions.#104929",
            "SHOW JOB WITH EXECUTION DETAILSfor a backup job will regenerate the DistSQL plan diagram with per-node and per-processor progress information. This will help users better understand the state of a running backup job.#103145",
            "Thecrdb_internal.node_transactionsandcrdb_internal.cluster_transactionstables now have columns forisolation_level,priority, andquality_of_service.#105009",
            "TheSHOW RANGEScommand will now emit span statistics when theDETAILSoption is specified. The statistics are included in a new column namedspan_stats, as aJSONobject. The statistics are calculated for the identifier of each row.SHOW RANGES WITH DETAILSwill compute span statistics for each range.SHOW RANGES WITH TABLES, DETAILSwill compute span statistics for each table, and so on. Thespan_statsJSONobject has the following keys:approximate_disk_bytes[key|val|sys|live|intent]_count[key|val|sys|live|intent]_bytesapproximate_disk_bytesis an approximation of the total on-disk size of the given object.key_countis the number of meta keys tracked underkey_bytes.key_bytesis the number of bytes stored in all non-system point keys, including live, meta, old, and deleted keys. Only meta keys really account for the \"full\" key; value keys only for the timestamp suffix.val_countis the number of meta values tracked underval_bytes.val_bytesis the number of bytes in all non-system version values, including meta values.sys_countis the number of meta keys tracked undersys_bytes.sys_bytesis the number of bytes stored in system-local key-value pairs. This tracks the same quantity as (key_bytes+val_bytes), but for system-local metadata keys (which aren't counted in eitherkey_bytesorval_bytes).live_countis the number of meta keys tracked underlive_bytes.live_bytesis the number of bytes stored in keys and values which can in principle be read by means of a Scan or Get in the far future, including intents but not deletion tombstones (or their intents). Note that the size of the meta key-value pair (which could be explicit or implicit) is included in this. Only the meta key-value pair counts for the actual length of the encoded key (regular pairs only count the timestamp suffix).intent_countis the number of keys tracked underintent_bytes. It is equal to the number of meta keys in the system with a non-empty Transaction proto.intent_bytesis the number of bytes in intent key-value pairs (without their meta keys).#103128",
            "approximate_disk_bytes",
            "[key|val|sys|live|intent]_count",
            "[key|val|sys|live|intent]_bytes",
            "Introduced thepg_lsndata type, which is used to store thelsnassociated with replication.#105031",
            "Users now can issue oneALTER TABLEstatementwith a combination of any number ofADD COLUMN, any number ofDROP COLUMN, oneALTER PRIMARY KEY, and any number ofADD CONSTRAINTclauses. For example, with this PR, we now support statements like:icon/buttons/copyCREATETABLEt(iINTPRIMARYKEY,jINTNOTNULL,kINTNOTNULL);ALTERTABLEtADDCOLUMNpINTDEFAULT30,ALTERPRIMARYKEYUSINGCOLUMNS(j),DROPCOLUMNk,ADDCHECK(i>0);#99526",
            "Added the ability to add numeric values to LSNs, or sub a decimal value from a LSN.#105326",
            "Implemented thepg_lsn - pg_lsn = decimalbuilt-in function, which subtracts 2 LSNs to return a decimal.#105326",
            "Added limited support for scalar PL/pgSQL functions. Supported statements are variable declarations, variable assignments,IFstatements, simpleLOOPstatements (with no conditions),EXITandCONTINUEstatements, andRETURNstatements.#104755",
            "Implemented the spatial built-inST_AsMVTGeom.#105530",
            "Pg_class'srelreplidentfield was previously unpopulated. It is now populated withdfor all tables (as each table has a primary key) andnotherwise.#106242",
            "Added thepg_sequence_last_valuebuilt-in function, which returns the last value generated by the sequence.#106445",
            "RESTOREcan now be passed aWITH EXECUTION LOCALITYoption similar toBACKUP, to restrict execution of the job to nodes with matching localities.#104439",
            "Added theREPLICATIONuser role option, which allows a user to use the streaming replication protocol. There is a correspondingREPLICATIONsystem privilege.#106082",
            "A new view-onlysession variable,max_connectionswas added. This can be used withSHOWto view the maximum amount of non-superuser SQL connections allowed at a given time.#106952",
            "Added thenameconcatoidbuilt-in function, which concatenates a name with an OID.#105944",
            "Thepg_catalog.pg_languagetable is now populated with data about the languages used to define functions.#105944",
            "Theinformation_schema.routinesview is now populated with information about functions.#105944",
            "Theinformation_schema.parameterstable is now populated with information about function parameters.#105944",
            "Added support for the PLpgSQLRAISEstatement, which allows sending notices to the client and raising errors. Currently the notice is only sent to the client. Support for logging notices will be added in a future release.#106351",
            "Thepublicpseudo-role now receives theEXECUTEprivilege by default for all user-defined functions that are created. This can be adjusted by usingALTER DEFAULT PRIVILEGES.#107317",
            "Thecrdb_interanal.node_statement_statisticstable redacts the error message if the user has theVIEWACTIVITYREDACTEDprivilege, and does not redact the error message if the user hasVIEWACTIVITY. If the user has both,VIEWACTIVITYREDACTEDtakes precedence and the last error is redacted.#107076",
            "Thecrdb_internal.cluster_lockstable now has aisolation_levelcolumn indicating the isolation level.#107309",
            "InCommonSQLExecDetails, which is emitted as part of the SQL audit logs, SQL exec logs, and telemetry events, there is a new field:StmtPosInTxn. It represents the statement's index in the transaction, starting at 1.#107081",
            "cluster_logical_timestampnow returns an error when called at isolation levels lower thanSERIALIZABLE.#107090",
            "EXPLAIN ANALYZEoutput now includes:The isolation level of the statement's transaction.The priority of the statement's transaction.The quality of service level of the statement's transaction.#105857",
            "The isolation level of the statement's transaction.",
            "The priority of the statement's transaction.",
            "The quality of service level of the statement's transaction.",
            "Added a new session variable,enable_implicit_fk_locking_for_serializable, which controls locking during foreign key checks underSERIALIZABLEisolation. With this set totrue, foreign key checks of the referenced (parent) table, such as those performed during anINSERTorUPDATEof the referencing (child) table, will lock the referenced row usingSELECT FOR SHARElocking. This is somewhat analogous to the existingenable_implicit_select_for_updatevariable but applies to the foreign key checks of a mutation statement instead of the initial row fetch. Under weaker isolation levels such as read committed,SELECT FOR SHARElocking will always be used to ensure the database maintains the foreign key constraint, regardless of the current setting ofenable_implicit_fk_locking_for_serializable.#105857",
            "Add a new session variable,enable_durable_locking_for_serializable, which controls locking durability underSERIALIZABLEisolation. With this set to true,SELECT FOR UPDATElocks,SELECT FOR SHAREDlocks, and constraint check locks (e.g., locks acquired during foreign key checks ifenable_implicit_fk_locking_for_serializableis set totrue) will be guaranteed-durable under serializable isolation, meaning they will always be held to transaction commit. These locks are always guaranteed-durable under weaker isolation levels. By default, under serializable isolation these locks are best-effort rather than guaranteed-durable, meaning in some cases (e.g., leaseholder transfer, node loss, etc.) they could be released before the transaction commits. Serializable isolation does not rely on locking for correctness, only using it to improve performance under contention, so this default is a deliberate choice to avoid the performance overhead of lock replication.#107749",
            "The cluster settingserver.cpu_profile.enabledhas been removed.server.cpu_profile.cpu_usage_combined_thresholdcan enable and disable CPU profiling.#107717",
            "Added support forCONSTANTvariable declarations in PLpgSQL routines. Any assignment to a variable declared with theCONSTANTkeyword will raise a compile-time error.#107682",
            "Added a new syntax toSHOW DEFAULT PRIVILEGES,SHOW DEFAULT PRIVILEGES FOR GRANTEE <grantee>, that shows the default privileges that a grantee received.#107953",
            "The Statement diagnostics feature has been extended to support collecting a bundle for a particular plan. Namely, the existing fingerprint-based matching has been extended to also include plan-gist-based matching. Such bundles will miss a couple of things:plan.txtfile as well as the tracing of the optimizer. At the moment, the feature is only exposed via an overload to thecrdb_internal.request_statement_bundlebuilt-in function. We now also support \"anti-match\": collecting a bundle for any plan other than the provided plan gist.#105477",
            "SHOW BACKUP's timestamp columns are nowTIMESTAMPTZ, meaning they render in the session offset.#108290",
            "Attempting todrop a columnwhen safe updates are enabled (sql_safe_updates = on) now additionally warns users that indexes referencing that column will be automatically dropped.#108047",
            "NOTICEs are now emitted for each index dropped by anALTER TABLE ... DROP COLUMN ...statement.#108047",
            "SHOW JOBSnow returns times (created,last_run, and so on) using theTIMESTAMPTZcolumn type instead of theTIMESTAMPtype, meaning they are now rendered using the session offset.#108353",
            "Added a cluster settingsql.schema.force_declarative_statementsto enable/disable DDL in thedeclarative schema changer.#107815",
            "Added the new built-in functionsworkload_index_recs()andworkload_index_recs(TIMESTAMPTZ), which return workload level index recommendations (columns of string, each string represent an index recommendation) from statement level index recommendations (as candidates) insystem.statement_statistics. If theTIMESTAMPTZis given, it will only consider those candidates generated after thatTIMESTAMPTZvalue.#106525",
            "Added support for specifying PLpgSQLIFstatements withELSIFbranches.#108211",
            "The admin API database details endpoint now returns authoritative range statistics.#108037",
            "Added themax_retries_for_read_committedsession variable. It defaults to 10, and determines the number of times an individual statement in an explicitREAD COMMITTEDtransaction will be retried if it encounters a retryable transaction error.#107044",
            "Added support for the execution of PLpgSQL functions with exception blocks. This allows a PLpgSQL function to catch and handle arbitrary errors it encounters during its execution.#107601",
            "Added the built-in functionsbitmask_or,bitmask_andandbitmask_xorfor variable-length input bitwiseOR,AND, andXORoperations, respectively.#107863",
            "Theoidvectortypesbuilt-in has been implemented, which can formatoidvector.#108467",
            "Added support for executing SQL statements directly within PLpgSQL routines. Note that this currently only applies to the subset of statements that can be executed within SQL UDFs, soCREATE TABLEis not supported, for example.INTOsyntax is also supported. For example,SELECT * INTO a, b FROM xy;.#107920",
            "A SQL client can now request strict atomicity for mixed DDL/DML transactions with the new session variablestrict_ddl_atomicity, which defaults tofalse. When this variable is set totrue, CockroachDB will refuse to accept processing those specific DDL statements insideBEGIN...COMMITfor which it cannot guarantee atomic processing (other DDL statements are still allowed). Note that schema changes implicit in certain operations (e.g.,IMPORT) are not protected via the new mechanism and can still fail withXXA00errors.#42063",
            "Fixed an issue where the UI was missing query text and details on the SQL ActivityTransactions pageif there were more than 500 transactions or statements. Thestatement_activitytable now includes all statements for a transaction that are in thetransaction_activitytable.#109424",
            "Added theVIEWSYSTEMTABLEsystem privilege. Users with this privilege haveSELECTprivileges for all tables in the system database.#109474",
            "Thestatement_activityandtransaction_activitytables columnexecution_total_cluster_secondsis now accurate. Thecombinedstmtsendpoint returns the correct value for theStmtsTotalRuntimeSecsandTxnsTotalRuntimeSecsproperties.#109592",
            "Thepersistedsqlstatstable maximum size check is now done once an hour instead of every 10 minutes. This reduces the risk of serialization errors on the statistics tables.#109696",
            "The deprecated session variableidle_in_session_timeoutis now hidden from introspection. It was previously changed toidle_session_timeout.#109872",
            "The session variablesslis now visible through introspection for better compatibility with PostgreSQL.#109872",
            "The session variablesession_useris now invisible through introspection, in a way consistent withsession_authorizationand PostgreSQL.#109872",
            "There is now aCREATEROLEsystem privilege, which is analogous to the existingCREATEROLErole option, but can also be inherited by role membership.#109258",
            "Added thegen_random_bytesbuilt-in function, which generates cryptographically secure random bytes.#110107",
            "The hash function used byhash-sharded indexeswas changed tomod(fnv32(md5(crdb_internal.datums_to_bytes(columns))), bucket_count). Previously, it did not usemd5. This change was made to enhance the uniformity of bucket distribution in cases when the bucket count is a power of 2, and the columns being sharded have numerical properties that make thefnv32function return values with a non-uniformly distributed modulus.#109374",
            "New datetime built-ins (make_date,make_timestamp, andmake_timestamptz) have been added, allowing for the creation of timestamps, timestamps with time zones, and dates. In addition,date_truncnow allows for a timestamp to be truncated in a specified timezone (to a specified precision).#108824",
            "There is now aCREATELOGINsystem privilege, which is analogous to the existingCREATELOGINrole option, but can also be inherited by role membership.#110220",
            "There is now aCREATEDBsystem privilege, which is analogous to the existingCREATEDBrole option, but can also be inherited by role membership.#110220",
            "There is now aCONTROLJOBsystem privilege, which is analogous to the existingCONTROLJOBrole option, but can also be inherited by role membership.#110220",
            "Thepersistedsqlstatstable maximum size check is now done once an hour instead of every 10 minutes. This reduces the risk of serialization errors on the statistics tables.#110173",
            "The newcluster settingsql.txn.read_committed_syntax.enabled, controls whether transactions run underREAD COMMITTEDorSERIALIZABLEisolation. It defaults tofalse. When set totrue, the following statements will configure transactions to run underREAD COMMITTEDisolation:BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTEDSET TRANSACTION ISOLATION LEVEL READ COMMITTEDSET default_transaction_isolation = 'read committed'SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL READ COMMITTED#110624",
            "BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "SET TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "SET default_transaction_isolation = 'read committed'",
            "SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "Thecluster settingsql.metrics.statement_details.gateway_node.enablednow defaults to false, to reduce the number of rows generated in SQL Statistics pages.#107788",
            "The default value for thettl_job_crontable storage parameter is now@dailyrather than@hourly. This parameter controls the default recurrence of the row-level TTL job. As part of this change, the output of theSHOW CREATE TABLEstatements now include thettl_cron_jobparameter only if it is explicitly set.#110623",
            "Removed a timeseries metric that has not been reported for several versions.#100524",
            "Added two new metrics,range.snapshots.(send|recv)-queue-bytes, to track the total size of all snapshots waiting in the snapshot queue.#100942",
            "Exposed a new metricstorage.compactions.duration, computed by the storage engine, that provides the cumulative time the storage engine has spent in compactions. This duration may exceed time elapsed, because of concurrent compactions, and may be useful in monitoring compaction concurrency.#103670",
            "Two new store metrics,range.snapshots.cross-region.sent-bytesandrange.snapshots.cross-region.rcvd-bytes, were added to track the aggregate of snapshot bytes sent from and received at a store across different regions. Note that these metrics require the nodes' localities to include a region tier key. If a node lacks this key but is involved in cross-region batch activities, an error message will be logged.#104111",
            "Added new store metrics to track the aggregate of snapshot bytes sent from and received at a store across different zones.range.snapshots.cross-zone.sent-bytesrange.snapshots.cross-zone.rcvd-bytesFor accurate metrics, follow these recommendations: - Configure region and zone tier keys consistently across nodes. - Within a node locality, ensure unique region and zone tier keys. - Maintain consistent configuration of region and zone tiers across nodes.#104417",
            "range.snapshots.cross-zone.sent-bytes",
            "range.snapshots.cross-zone.rcvd-bytes",
            "Added new store metrics:raft.rcvd.bytesraft.sent.bytesraft.rcvd.cross_region.bytesraft.sent.cross_region.bytesraft.rcvd.cross_zone.bytesraft.sent.cross_zone.bytes#105122",
            "raft.rcvd.bytes",
            "raft.sent.bytes",
            "raft.rcvd.cross_region.bytes",
            "raft.sent.cross_region.bytes",
            "raft.rcvd.cross_zone.bytes",
            "raft.sent.cross_zone.bytes",
            "Added new DistSender metrics:distsender.batch_requests.replica_addressed.bytesdistsender.batch_responses.replica_addressed.bytesdistsender.batch_requests.cross_region.bytesdistsender.batch_responses.cross_region.bytesdistsender.batch_requests.cross_zone.bytesdistsender.batch_responses.cross_zone.bytes.#103963",
            "distsender.batch_requests.replica_addressed.bytes",
            "distsender.batch_responses.replica_addressed.bytes",
            "distsender.batch_requests.cross_region.bytes",
            "distsender.batch_responses.cross_region.bytes",
            "distsender.batch_requests.cross_zone.bytes",
            "distsender.batch_responses.cross_zone.bytes.",
            "Added new Node metrics:batch_requests.bytesbatch_responses.bytesbatch_requests.cross_region.bytesbatch_responses.cross_region.bytesbatch_requests.cross_zone.bytesbatch_responses.cross_zone.bytes#104585",
            "batch_requests.bytes",
            "batch_responses.bytes",
            "batch_requests.cross_region.bytes",
            "batch_responses.cross_region.bytes",
            "batch_requests.cross_zone.bytes",
            "batch_responses.cross_zone.bytes",
            "Added new RPC metrics to help you to diagnose RPC connection issues:grpc.connection.avg_round_trip_latencyrpc.connection.failuresrpc.connection.healthyrpc.connection.healthy_nanosrpc.connection.heartbeatsrpc.connection.unhealthyrpc.connection.unhealthy_nanos#99191",
            "grpc.connection.avg_round_trip_latency",
            "rpc.connection.failures",
            "rpc.connection.healthy",
            "rpc.connection.healthy_nanos",
            "rpc.connection.heartbeats",
            "rpc.connection.unhealthy",
            "rpc.connection.unhealthy_nanos",
            "Added a new metricchangefeed.lagging_rangesthat shows the number of ranges which are behind in changefeeds. This metric can be used with themetrics_labelchangefeed option. Added a newchangefeed optionlagging_ranges_threshold, which is the amount of time a range needs to be behind to be considered lagging. By default this is 3 minutes. Added a new optionlagging_ranges_polling_interval, which controls how often the lagging ranges calculation is done. This setting defaults to polling every 1 minute. Note that polling adds latency to the metric being updated. For example, if a range falls behind by 3 minutes, the metric may not update for an additional minute afterwards. Also note that ranges undergoing an initial scan for longer than the threshold are considered to be lagging. Starting a changefeed with an initial scan on a large table will likely increment the metric for each range in the table. However, as ranges complete the initial scan, the number of ranges will decrease.#109835",
            "A histogram metricraft.replication.latencywas added. It tracks the time between evaluation and application of the command. This includes time spent in the quota pool, in replication (including re-proposals) as well as log application, but notablynotsequencing latency (i.e., contention and latch acquisition).#106094",
            "The default Raft scheduler concurrency cap has been increased from 96 to 128 workers, scaling with 8 workers per CPU up to the cap. The scheduler concurrency can be controlled using theCOCKROACH_SCHEDULER_CONCURRENCYenvironment variable.#105521",
            "The new cluster settingserver.hot_ranges_request.node.timeoutcontrols the maximum amount of time that a hot ranges request will spend waiting for a node to provide a response. It defaults to 5 minutes. To disable timeouts, set it to0.#107796",
            "Two new cluster settings control whether intent resolution is subject to admission control:kv.intent_resolver.send_immediately.bypass_admission_control.enabledandkv.intent_resolver.batch.bypass_admission_control.enabled.#109932",
            "The new cluster settingadmission.l0_min_size_per_sub_levelreduces the probability ofadmission controlthrottling when there is a sequence of smallmemtableflushes or small files ingested into L0.#109332",
            "The new cluster settingkv.intent_resolver.batcher.in_flight_backpressure_limit.enabledcontrols whether an in-flight RPC limit is enforced on intent resolution RPCs. It defaults tofalse.#109899",
            "BACKUPnow skips contacting the ranges for tables on whichexclude_data_from_backupis set, and can thus succeed even if an excluded table is unavailable.#108627",
            "Span stats requests will return a partial result if the request encounters any errors. Errors that would have previously terminated the request are now included in the response.#108456",
            "The rangefeed closed timestamp interval controlled bykv.rangefeed.closed_timestamp_refresh_intervalnow defaults to 3 seconds. This affects how often rangefeeds emit resolved timestamps, and thus how often changefeeds can emit checkpoints. Previously, its default value of 0 would fall back tokv.closed_timestamp.side_transport_interval, which defaults to 200 milliseconds. Users who rely on the settingkv.closed_timestamp.side_transport_intervalto control the rangefeed closed timestamp interval should make sure they either setkv.rangefeed.closed_timestamp_refresh_intervalto 0 to retain the old behavior (preferably before upgrading), or to an appropriate value.#108667",
            "The default value oftimeoutforhttp-serverslogging sinkshas been changed from0(i.e., \"no timeout\") to2s. This is reflected in thehttp-defaultssection of the log configuration. Users still maintain the ability to override the timeout, or disable it by explicitly setting it to0(e.g.timeout: 0).#109264",
            "Changefeedmetrics now include achangefeed.checkpoint_progressmetric which is similar tochangefeed.max_behind_nanosbut supports metrics labels, as well as achangefeed.aggregator_progressmetric which can track the progress of individual aggregators (the lowest timestamp for which all aggregators with the label have emitted all values they're responsible for).#108757",
            "Added support for Prometheus native histograms behind an environment variable flag.#104302",
            "Requests for database details or table details from the UI, or usages of [SHOW RANGES WITH DETAILS]/docs/v23.2/show-ranges.html are no longer subject to errors if the number of requested spans is too large.#109464",
            "Thecockroach debug zipcommand now has an option to omit goroutine stack dumps. This impacts the creation ofnodes/*/stacks.txtandnodes/*/stacks_with_labels.txtwithin debug ZIP bundles. Users can opt to exclude these goroutine stacks by using the--include-goroutine-stacks=falseflag. Note that fetching stack traces for all goroutines is a \"stop-the-world\" operation, which can momentarily have negative impacts on SQL service latency. Note also that any periodic goroutine dumps previously taken on the node will still be included innodes/*/goroutines/*.txt.gz, as these would have already been generated and don't require any stop-the-world operations.#110177",
            "New rangefeed metrics help to troubleshoot rangefeed restarts. The metric names have the formatdistsender.rangefeed.retry.{reason}.#109346",
            "Rangefeeds regularly attempt to push long-running transactions to a future timestamp in order to emit checkpoints. The interval at which this is attempted has been increased from 250 milliseconds to 1 seconds. This is now configurable via the environment variableCOCKROACH_RANGEFEED_PUSH_TXNS_INTERVAL.#110332",
            "A selection box displays in DB Console Metrics pages when you are connected to the system virtual cluster, and allows you to view metrics for a specific virtual cluster.#103308",
            "A \"no data\" empty graph state has been added when switching to a virtual cluster with no data.#103971",
            "A selection box displays on custom charts in the DB Console and allows you to select a specific virtual cluster.#103780",
            "The name of the virtual cluster, when known, is now reported in logging events.#108807",
            "Whencockroach debug zipis run for a cluster with virtualization enabled, data about virtual clusters is now stored in avirtualsubdirectory rather than atenantssubdirectory.#106117",
            "When cluster virtualization is enabled, the following closed timestamp side-transport settings can be set only from the system virtual cluster:kv.closed_timestamp.target_duration,kv.closed_timestamp.side_transport_interval, andkv.closed_timestamp.lead_for_global_reads_override.#108678",
            "The CLI commands that output SQL data now support the JSON output format (--format=json), in addition to newline-delimited JSON (ND-JSON,--format=ndjson) that had been supported since v22.2.#102595",
            "cockroach debug zipnow supports the command-line flag--formatto select the format used to store SQL table data, in the same way ascockroach sql. In contrast tocockroach sqlhowever, its default value isjson(resulting in files named.json) and the default is not dependent on whether the terminal is interactive.#102607",
            "The SQL shell now supports argument quoting for client-side commands in a similar way topsql: inside single quotes,\\can escape characters and recognize octal/hexadecimal sequences; and inside double quotes characters are passed through. The quote characters themselves, when doubled, result in themselves as part of the string.For example, the following commands both result in a SQL prompt that saysgo \"world\":icon/buttons/copy\\set prompt1'go \"world\"'\\set prompt1 go' '\"world\"To add color to the prompt:icon/buttons/copy\\set prompt1'\\033[34mmydb>\\033[m'These quoting rules are similar to PostgreSQL, but are different from the rules used by POSIX shells and of other programming languages like Python or Go. For example, octal and hex escape sequences support a variable number of digits, and double quoted strings preserve the surrounding quotes. When in doubt, refer to the PostgreSQL documentation.#104610",
            "The configuration for log output sinks now accepts a newformat-optionsfield. This can be used to customize the output of a given format. Each format accepts different options. One available option for thejsonoutput format isdatetime-format.For example:icon/buttons/copysinks:fluent-groups:custom-json:format:jsonformat-options:{datetime-format:rfc3339}This introduces a (new) fielddatetimein each output JSON event, with the format specified by the option. As of this writing, the following values are documented:none: disable the creation of thedatetimefield. This is the default value.iso8601/rfc3339: format the time stamp like \"2006-01-02T15:04:05.999999999Z\".rfc1123: format the time stamp like \"Mon, 02 Jan 2006 15:04:05 +0000\".Enabling thedatetimefield introduces CPU overhead and is not recommended. When using output to a log collector such as Fluent or Datadog, the log collector can be configured to transform the timestamp provided by CockroachDB without requiring participation from CockroachDB itself. When inspecting a log file containing JSON output produced by CockroachDB, the commandcockroach debug merge-logcan consume the JSON data and reformat it using thecrdb-v2format which also includes the date and time using the RFC3339 format.#104265",
            "none: disable the creation of thedatetimefield. This is the default value.",
            "iso8601/rfc3339: format the time stamp like \"2006-01-02T15:04:05.999999999Z\".",
            "rfc1123: format the time stamp like \"Mon, 02 Jan 2006 15:04:05 +0000\".",
            "Thejsonlog output format now recognizes the extra format optiondatetime-timezonewhich selects which timezone to use when formatting thedatetimefield.datetime-timezonemust be combined withdatetime-formatbecause the default value for the latter option isnone(i.e.,datetimeis not produced by default). For example:icon/buttons/copysinks:fluent-groups:custom-json:format:jsonformat-options:{datetime-format:rfc3339,datetime-timezone:America/New_York}#104265",
            "Thejsonlog format now recognizes the format optionstag-styleandfluent-tag. The existing formatsjson-compact,json-fluent,json-fluent-compacthave been redefined to become aliases forjsonwith different defaults for the two new options.#104265",
            "Thecrdb-v1log format now recognizes the format optionsshow-counterandcolors. The existing formatscrdb-v1-tty,crdb-v1-count,crdb-v1-tty-counthave been redefined to become aliases forcrdb-v1with different defaults for the two new options.#104265",
            "Thecrdb-v2log format now recognizes the format optioncolors. The existing formatscrdb-v2-ttyhas been redefined to become aliases forcrdb-v2with a different default for the new option.#104265",
            "The log output formatscrdb-v1andcrdb-v2now support the format optiontimezone. When specified, the corresponding time zone is used to produce the timestamp column. For example:icon/buttons/copyfile-defaults:format:crdb-v2format-options:{timezone:america/new_york}Example logging output:I230606 12:43:01.553407-040000 1 1@cli/start.go:575  [n?] 4 soft memory limit of Go runtime is set to 35 GiB ^^^^^^^ indicates GMT-4 was usedThe timezone offset is also always included in the format if it is not zero (e.g., for non-UTC time zones). This is necessary to ensure that the times can be read back precisely.#104265",
            "The commandcockroach debug merge-logwas adapted to understand time zones in input files read with formatcrdb-v1orcrdb-v2.#104265",
            "When customizing the SQL interactive prompt,%Mand%mnow behave more likepsqlwhen connecting over a Unix datagram socket.#105137",
            "The default value of the--formatparameter tocockroach debug zipistsv, like other CLI commands that can extract SQL data.#107474",
            "Thedebug.zipnow includes thecrdb_internal.probe_rangetable with a limit of 100 rows to prevent the query from taking too long.#107720",
            "The default value for the--max-sql-memoryparameter of thecockroach democommandhas been increased from 128 MiB to 256 MiB.#103642",
            "The command\\demo recommissionhas been removed fromcockroach demo. It had been obsolete and non-functional ever since v20.2.#108566",
            "Added limitedstatement_statisticsto the debug ZIP file.#108210",
            "The following user-visible cluster settings have been renamed. The previous name is still available for backward compatibility.Previous nameNew nameserver.web_session_timeoutserver.web_session.timeoutkv.closed_timestamp.follower_reads_enabledkv.closed_timestamp.follower_reads.enabledkv.range_split.by_load_enabledkv.range_split.by_load.enabledchangefeed.balance_range_distribution.enablechangefeed.balance_range_distribution.enabledchangefeed.batch_reduction_retry_enabledchangefeed.batch_reduction_retry.enabledserver.clock.forward_jump_check_enabledserver.clock.forward_jump_check.enabledserver.oidc_authentication.autologinserver.oidc_authentication.autologin.enabledsql.metrics.statement_details.dump_to_logssql.metrics.statement_details.dump_to_logs.enabledsql.trace.log_statement_executesql.log.all_statements.enabledtrace.debug.enabletrace.http_debug_endpoint.enabled#109074",
            "The following cluster settings have been renamed. The previous names are available for backward-compatibility.Previous nameNew namespanconfig.tenant_coalesce_adjacent.enabledspanconfig.range_coalescing.application.enabledspanconfig.storage_coalesce_adjacent.enabledspanconfig.range_coalescing.system.enabled#109077",
            "The newcockroach gen metric-listcommand generates metadata that describes the various metrics collected by an idle server. The list does not include dynamic metric names whose names are generated based on the workload.#109042",
            "The time window selection for metrics charts is now encoded in the URL via query params.#101258",
            "TheJob Details pagenow has a tabbed UI that will allow users to toggle between the Overview and other future views for advanced debugging and observability.#102737",
            "Renamed \"recent executions\" to \"active executions\" in the UI.#103784",
            "TheChangefeed Dashboardhas been updated with new graphs to track backfill progress, protected timestamps age, and the number of schema registry registrations. The updates include renaming theSink Byte Trafficgraph toEmitted Bytesand theMax Changefeed Latencygraph toMax Checkpoint Latency.#101790",
            "A newNetworkingtab has been added to the DB Console metrics dashboard. Metrics for network bytes sent and received are now displayed in theNetworkingtab rather than theHardwaretab. In addition, the following metrics have been added:cr.node.round-trip-latency-p50cr.node.round-trip-latency-p99cr.node.rpc.connection.unhealthy",
            "cr.node.round-trip-latency-p50",
            "cr.node.round-trip-latency-p99",
            "cr.node.rpc.connection.unhealthy",
            "The Job Details page now has a profiler tab for more advanced observability into a job's execution. Currently, we support collecting a cluster-wide CPU profile of the job.#103945",
            "The active executions views in the SQL Activity pages now support toggling between automatic and manual refresh. A manual refresh button was also added along with a timestamp indicating when the last refresh was performed.#103786",
            "The visibility of the cluster settingui.display_timezonehas been set to public. Documentation of the cluster setting has been added. No functionality has been changed.#106530",
            "Added a table in the Profiler job details page that lists all the available files describing a job's execution details#106879",
            "Add columns for p50, p90, p99 percentiles and latency min and max on Explain Plan tab on theStatement Execution Details page.#107719",
            "Fixed a broken query for the database details page that was causing an infinite loading state.#107893",
            "Added summary cards with total/average values for statistics on the Statement Execution Details page.#109056",
            "The DB Console now Shows a warning when the time period selected on SQL Activity pages is older than the oldest data available.#109164",
            "Users without theVIEWCLUSTERSETTINGSpermission but withVIEWACTIVITYorVIEWACTIVITYREDACTEDcan now see index recommendations.#109047",
            "The DB Console now allows non-admin users to view theDatabases page.#109245",
            "Non-admin users are able to use the Database Details page.#109432",
            "Non-admin users are able to use the Database Table page.#109521",
            "The \"SQL Connection Rate\" metric on theSQL Dashboardis downsampled using the MAX function instead of SUM. This improves situations where zooming out would cause the connection rate to increase for downsampled data.#110391",
            "Fixed an internal error that can occur whenCREATE OR REPLACE VIEWreplaces a view with fewer columns and another entity depended on the view.#99057",
            "If views are created with circular dependencies, CockroachDB now returns an error (cyclic view dependency for relation) instead of crashing the node. This bug was present since at least 21.1.#99174",
            "Fixed a potential bug whereby a failed or cancelledIMPORTcould in some cases leave some of the imported rows behind after it was cancelled, in the rare event that the writing processes were slow enough to continue writing after the cleanup process started.#97071",
            "Fixed a very rare bug that could cause keys to get unexpectedly deleted when rebalances occurred in a write-heavy workload.#102164",
            "It is now possible to properly redirect the output of SQL queries using thendjsonoutput table format incockroach sql. This bug had been introduced in v22.2.#102595",
            "Theunaccentbuilt-infunctionno longer removes spaces.#103819",
            "The details of errors pertaining to invalid descriptors are not included any more in redacted debug ZIP files.#104050",
            "Fixed a bug where join expressions were processed incorrectly.#103782",
            "Fixed a bug that could cause aUDFto return a value that does not conform to the return type of the UDF. This bug was only present for UDFs that return user-defined types. The bug was present since v23.1.#104151",
            "Fixed a bug where if a user was logged in while a different session dropped that user, the dropped user would still inherit privileges from thepublicrole. Now, CockroachDB checks that the user exists before allowing it to inherit privileges from thepublicrole. In addition, any active web sessions are now revoked when a user is dropped.#104215",
            "Fixed a bug in upstreametcd-io/raftwhich could result in pulling unlimited amount of logs into memory, and lead to out-of-memory errors. Now the log scan has a limited memory footprint.#104483",
            "Fixed a bug where, in rare circumstances, areplicationcould get stuck when proposed near lease or leadership changes, especially under overload, and the [replica circuit breakers](../v23.2could trip. A previous attempt to fix this issue has been reverted in favor of this fix.#106515",
            "CockroachDB now automatically deletes statistics for dropped tables from thesystem.table_statisticstable.#105364",
            "Fixed a rare internal error which occurs when a query uses a \"project set\" operation involving simple column expressions.#104756",
            "TheRaftPreVoteandCheckQuorummechanisms are now fully enabled. These prevent spurious elections when followers already have an active leader, and cause leaders to step down if they don't hear back from a quorum of followers. This improves reliability under partial and asymmetric network partitions, by avoiding spurious elections and preventing unavailability where a partially partitioned node could steal leadership away from an established leaseholder who would then no longer be able to reach the leader and submit writes.#104042",
            "Fixed a bug that could produce incorrect values forvirtual computed columnsin rare cases. The bug only occurred when the virtual column expression's type did not match the type of the virtual column.#105736",
            "Fixed a rounding error that could cause distributed execution for some decimal aggregate functions to return slightly inaccurate results in rare cases.#105694",
            "Fixed theStatementStatistics.Nodesto contain all of the nodes involved in the query. Fixed the region info inEXPLAIN ANALYZE (DISTSQL)for virtual clusters.#106587",
            "Fixed a bug that causedbackupsto fail if there are tables and functions of the same name.#106626",
            "Fixed edge cases in decimal and float evaluation for division operators.'NaN'::DECIMAL / 0will now returnNaNinstead of a division-by-zero error, and0 / 'inf'::DECIMALwill return0instead of0E-2019.#106472",
            "Fixed a bug present since before v22.2 that could cause a query withLIMITandORDER BYto return results in the wrong order. This bug could cause incorrect results as well if theLIMITwas nested within an outer query (e.g., under anotherLIMIT).#106717",
            "Added missingSQLInstanceIDsused to execute the statement to the telemetrySampledQueryevent.#106753",
            "Fixed a bug where inserting geometries into a table with an inverted index involving a NaN coordinate could result in a panic. This now produces errors instead.#106671",
            "Avoid displayingundefinedregions on theDatabases page.#106778",
            "Thecockroach userfile uploadcommanduses less memory when uploading a file.#106056",
            "CASE,IF,COALESCE, andIFNULLexpressions now return an error when passed a generator function as an argument. This mirrors the behavior of PostgreSQL.#105582",
            "Fixed a bug that allowed views created withCREATE OR REPLACE VIEWto reference user-defined types in other databases, even withsql.cross_db_views.enabledset tofalse. This bug was present since user-defined types were introduced in v20.1.#106869",
            "Removed a source of unnecessary Raft snapshots during replica movement.#106793",
            "Fixed a bug where in rare situations nodes would get stuck during start-up. It would manifest itself through a stack frame sitting on a select inwaitForAdditionalStoreInitfor extended periods of time (i.e., minutes).#107124",
            "Fixed a bug that caused internal errors when using an aggregate function in anORDER BYclause of aDELETEorUPDATEstatement. Aggregate functions are no longer allowed in these contexts. The bug has been present since at least v20.2.#107641",
            "The filter on theStatements pageworks when application name is an empty string.#107750",
            "TheTransaction Details pagenow loads with the fingerprint details even if no application is specified in the URL.#107742",
            "TheSchema Insights pageno longer times out.#107292",
            "The last SQL statement in a user-defined function with aVOIDreturn type can now produce any number of columns of any type. This bug was present since UDFs were introduced in v22.2.#108299",
            "Fixed a bug that caused nodes to crash when attempting toEXECUTEa prepared statement with an argument that referenced a user-defined function. This bug was present since user-defined functions were introduced in v22.2.#108213",
            "Fixed a bug where a releasesave pointcould incorrectly emit a \"cannot publish new versions for descriptors\" error instead of a retryable error.#108133",
            "Users with theVIEWACTIVITYprivilege now are able to see other users sessions from both the CLI and the DB Console.#106590",
            "Fixed a bug incockroach demowhereby\\demo addcould sometimes crash with an error \"index out of range [...] with length ...\". This bug had been introduced in v19.x.#108566",
            "Fixed a bug introduced in v20.2 where the command\\demo decommissionincockroach democould leave the demo cluster in a broken state.#108566",
            "Fixed a bug wherecockroach startwould sometimes incorrectly hang upon shutting down a server after encountering an internal error. This bug had been introduced some time in v22.x.#108612",
            "Fixed a bug in the index recommendations provided in theEXPLAINoutput whereALTER INDEX ... VISIBLEindex recommendations may suggest making the wrong index visible when there are multiple invisible indexes in a table.#108576",
            "Users with theVIEWACTIVITYprivilegecan now view correct values for timezones.#108486",
            "Fixed a bug present since v23.1.0 that would cause queries on thepg_catalog.pg_statistic_exttable to fail if a table was dropped recently. This bug also caused the\\dCLI shortcut to encounter errors.#108818",
            "Fixed a bug wherepg_attributeandpg_attrdefdid not properly return results for generated columns.#108964",
            "Fixed a bug where aSpanStatsRequestwould return post-replicated MVCC stats. Now, aSpanStatsRequestreturns the logical MVCC stats for the requested span.#108852",
            "Fixed the column name on the selects on the tablescrdb_internal.node_txn_execution_insightsandcrdb_internal.cluster_txn_execution_insightsupon the creation ofdebug.zip.#109444",
            "Fixed the type resolution logic forCASEstatements to more closely match Postgres' logic. In particular, we now adhere to rule 5 listed in thePostgreSQL documentation, which requires that we select the first non-unknown input type as the candidate type, then consider each other non-unknown input type, left to right (CASEtreats itsELSEclause (if any) as the \"first\" input, with theTHENclauses(s) considered after that). If the candidate type can be implicitly converted to the other type, but not vice-versa, select the other type as the new candidate type. Then continue considering the remaining inputs. If, at any stage of this process, a preferred type is selected, stop considering additional inputs (note that CockroachDB does not yet support the concept of a \"preferred type\").#108387",
            "Fixed an issue on theMetrics pagewhere no metrics would load when viewing metrics for a virtual cluster with a hyphenated name in a global context.#109174",
            "Fixed a potential livelock between a high-priority transactional read and a normal-priority write. The read pushes the timestamp of the write, but if the read gets pushed as well, it may repeatedly fail to refresh because it keeps encountering the intent of the write.#108190",
            "Fixed a nil dereference panic during node startup that could be caused by an incorrect initialization order.#109659",
            "Thedifferencebuilt-in had its return type incorrectly set to a string instead of an integer.#109731",
            "Fixed a bug that could cause a transaction performing multiple parallel foreign key checks to return aconcurrent txn use detectederror.#109510",
            "Fixed a bug causing performance regression when disablingsql.metrics.statement_details.enabledwhich caused execution stats to be collected for all queries instead of the default one percent.#109785",
            "Fixed a bug where certain SQL session variables meant to be hidden from introspection were showing up ininformation_schema.session_variables, which was incoherent with the handling inpg_catalog.pg_settings.#109872",
            "CockroachDB now properly handles RPC failures on writes using the parallel commit protocol that execute in parallel to the commit operation, avoiding incorrect retryable failures andtransaction unexpectedly committedassertions by detecting when writes cannot be retried idempotently, instead returning anAmbiguousResultError.#107658",
            "Fixed a bug where dependencies on sequences from tables would be reported with the wrong value for theclassidcolumn in thepg_catalog.pg_dependtable.#110144",
            "TwoALTER RANGE default CONFIGURE ZONEstatements on the same line no longer displays an error.#109774",
            "Fixed a DB Console issue where theDROP_UNUSEDindex recommendations produced by the table details page produced an invalidDROP INDEXstatement.#110429",
            "Removed buggyTTLdescriptor repair. Previously, upgrading from v22.2.X to v23.1.9 incorrectly removed TTL storage parameters from tables (visible by running aSHOW CREATE TABLE <ttl-table>;statement) while attempting to repair table descriptors. This resulted in the node that attempted to run the TTL job crashing due to a panic caused by the missing TTL storage parameters.#110364",
            "cockroach debug pebblecommands now work correctly with encrypted stores which don't use the defaultcockroach-datapath without having to also pass--store.#110150",
            "Fixed a bug whereCREATE INDEXforpartial indexescould fail withERROR: duplicate key value violates unique constraintif concurrent inserts happened simultaneously.#110216",
            "Observability pages no longer crash when they encounter zeros (e.g., a session with no memory allocated).#108752",
            "Removed thecluster settingkv.snapshot_recovery.max_rate:In v23.2, this setting is disabled; it is a no-op. If you previously setkv.snapshot_recovery.max_rateon a cluster running v23.1 and upgraded to v23.2, the setting is ignored, and thekv.snapshot_rebalance.max_ratesetting is used instead.In v24.1 and later, this setting is removed entirely. If you had previously setkv.snapshot_recovery.max_rateprior to upgrade, it will be cleared, and any attempts to set it will fail with the error message:ERROR: unknown cluster setting 'kv.snapshot_recovery.max_rate'.#102596",
            "In v23.2, this setting is disabled; it is a no-op. If you previously setkv.snapshot_recovery.max_rateon a cluster running v23.1 and upgraded to v23.2, the setting is ignored, and thekv.snapshot_rebalance.max_ratesetting is used instead.",
            "In v24.1 and later, this setting is removed entirely. If you had previously setkv.snapshot_recovery.max_rateprior to upgrade, it will be cleared, and any attempts to set it will fail with the error message:ERROR: unknown cluster setting 'kv.snapshot_recovery.max_rate'.#102596",
            "Fixed a bug in which aCREATE FUNCTIONmay produce a syntax error if the UDF body wrapped in tagged dollar quotes (e.g.,$func$), contains two consecutive dollar signs$$. If the UDF body is known to contain dollar signs, then the caller should use tagged dollar quotes or single quotes when defining the UDF. For example:icon/buttons/copyCREATEFUNCTIONf(aSTRING)RETURNSSTRINGLANGUAGESQLAS$func$SELECTconcat('$$',a);$func$#101352",
            "CockroachDB now prevents settingmax_range_sizebelow theCOCKROACH_MIN_RANGE_MAX_BYTESenvironment variable, which defaults to 64 MiB (half of the default minimum range size).#96725",
            "Fixed a bug that could occasionally cause schema change jobs, such as table or index drops, to appear stuck in state \"waiting for MVCC GC\" for much longer than expected. The fix only applies to future schema changes. To process existing stuck jobs, manually force-enqueue the relevant ranges in the MVCC GC queue from the DB Console'sAdvanced Debugpage.#110078",
            "Fixed a bug introduced when theChartCatalogAPI endpoint was introduced, where the endpoint did not correctly report the unit of metrics.#109042",
            "Fixed a bug that could occur when the \"multiple active portals\" execution mode (Preview) was enabled to evaluate queries such as lookup joins. The bug could result in an internal error likeunexpected 40960 leftover bytesif the portal was not fully consumed.#110625",
            "Fixed a bug where anALTER TABLE ... ADD CONSTRAINT CHECK ...statement that utilized a user-defined function in theCHECKcould cause a validation error.#110130",
            "Fixed a bug whereRESET (ttl_expire_after)could incorrectly removettl_expiration_expression.#110252",
            "Fixed a bug where theformat_typebuilt-in did not honortypemodinformation for array types, leading to incorrect output.#110900",
            "Fixed a bug introduced in v22.2 that incorrectly allowed users without theEXECUTEprivilege to execute a user-defined function.#107587",
            "Theoptimizernow plans inverted index scans for queries usingINor the=operators without the fetch val (->) operator. For example:json_col = '{\"b\":\"c\"}' OR json_col IN ('\"a\"', '1')#101178",
            "Queries that have subqueries in equality expressions are now more efficiently planned by the optimizer.#100881",
            "Query planning time has been reduced for some queries with multiplejoins.#102011",
            "CockroachDB now enables the pacing mechanism in rangefeed closed timestamp notifications, by setting the defaultkv.rangefeed.closed_timestamp_smear_intervalcluster setting to 1ms. This makes rangefeed closed timestamp delivery more uniform and less spikey, which reduces its impact on the Go scheduler and, ultimately, foreground SQL latencies.#103006",
            "Some large, long-runningINSERTstatements now perform less work during their commit phase and can run faster.#103241",
            "Ranges now only quiesce after 3 seconds without proposals, to avoid frequent unquiescence which incurs an additional Raft proposal. This is configurable via theCOCKROACH_QUIESCE_AFTER_TICKSenvironment variable, which defaults to 6.#103266",
            "SQL statements that must clean up intents from many different previously abandoned transactions now do so moderately more efficiently.#103265",
            "The optimizer can now avoid a grouping stage in more cases when de-duplicating the input to anUPSERTorINSERT ... ON CONFLICTstatement.#105206",
            "The optimizer can now eliminate joins in more cases.#105214",
            "CockroachDB now improves the time to disk space reclamation when deleting rows. Previously, in scenarios where rows had large variations in row size, it was possible for disk space to not be reclaimed after MVCC garbage collection deleted the rows.#104539",
            "CockroachDB now has improved disk space reclamation heuristics, making disk space reclamation more timely.#106177",
            "bool_andandbool_oraggregates will now scale linearly instead of quadratically when used as a window function with a non-shrinking window,#106477",
            "CockroachDB now has reduced lock contention onssmemstorage.RecordStatement. This is useful for workloads that execute the same statement concurrently on the same SQL instance.#106860",
            "The optimizer now produces more efficient query plans in some cases for queries with subqueries and user-defined functions.#107133",
            "The default Raft entry cache size has been increased from 16 MB to 1/256 of system memory with a minimum of 32 MB, divided evenly between all stores. This can be configured using theCOCKROACH_RAFT_ENTRY_CACHE_SIZEenvironment variable.#107424",
            "CockroachDB now automatically collects table statistics on thesystem.jobstable, which will enable the optimizer to produce better query plans for internal queries that access thesystem.jobstable. This may result in better performance of the system.#108139",
            "The impact of high concurrency blind writes to the same key on goroutine scheduling latency was reduced.#109349",
            "Changefeedsto Webhook or Pub/Sub endpoints now support much higher throughput#109351",
            "This release improved the cost of resolving a user-defined enum type that has many values.#109394",
            "Queries that compare collated strings now use less memory and may execute faster.#110066",
            "Added a scheduler based rangefeed processor which improves rangefeed and changefeed performance for very large tables. The new processor is disabled by default, but can be enabled by settingkv.rangefeed.scheduler.enabledcluster setting totrue.#107553",
            "This release disablessql.defaults.zigzag_join.enabledby default.#110214",
            "Go has been upgraded to 1.20.8.#109773",
            "The top-levelMakefilewas replaced by a stubGNUmakefilewhich defers its behavior todev. The common targetsmake [all],make test, andmake installremain for compatibility with most UNIX installation guides. The previousmakerules remain available viamake -C build/GNUmakefile.obsolete.#84565",
            "View Page Source",
            "Edit This Page",
            "Report Doc Issue",
            "CockroachDB",
            "CockroachDB Cloud",
            "Get CockroachDB",
            "Architecture Overview",
            "Support Portal",
            "Terms of Use",
            "CockroachDB Docs",
            "Cockroach University",
            "Community Forums",
            "CockroachDB Support"
        ]
    },
    {
        "database": "CockroachDB",
        "major_version": "23.2",
        "patch_version": "23.2.0",
        "date": "February 5, 2024",
        "changes": [
            "Feature categoriesObservabilityMigrationsSecurity and complianceDisaster recoveryDeployment and operationsSQL",
            "Observability",
            "Security and compliance",
            "Disaster recovery",
            "Deployment and operations",
            "Additional informationBackward-incompatible changesDeprecationsKnown limitationsAdditional resources",
            "Backward-incompatible changes",
            "Deprecations",
            "Known limitations",
            "Additional resources",
            "The pre-v23.1 output produced bySHOW RANGES,crdb_internal.ranges, andcrdb_internal.ranges_no_leaseswas deprecated in v23.1 and is now replaced by default with output that's compatible with coalesced ranges (anges that pack multiple tables/indexes/partitions into individual ranges). See thev23.1 release notesforSHOW RANGESfor more details.#102961",
            "When a deployment is configured to use a time zone for log file output using formatscrdb-v1orcrdb-v2, new output log entries cannot be processed by nodes that have not been upgraded to v23.2.#104265",
            "When customizing theSQL shell's interactive prompt, the special sequence%Mnow expands to the full host name instead of the combination of host name and port number. To include the port number explicitly, use%>. The special sequence%mnow expands to the host name up to the first period.#105137",
            "Thecockroach debug zipcommand stores data retrieved from SQL tables in the remote cluster using the TSV format by default.#107474",
            "Thechangefeed.protect_timestamp.max_agecluster settingwill only apply to newly created changefeeds in v23.2. For existing changefeeds, you can set theprotect_data_from_gc_on_pauseoption so that changefeeds do not experience infinite retries and accumulate protected change data. You can use theALTER CHANGEFEEDstatement to addprotect_data_from_gc_on_pauseto existing changefeeds.#103539",
            "The direct export of traces to Jaeger and thecluster settingtrace.jaeger.agenthave been removed. The direct export functionality had been obsoleted since 2022; it stopped working altogether sometime in 2023 with the following error:data does not fit within one UDP packet; size 65006, max 65000, spans NN. Since 2022, Jaeger supports ingestion of traces using OTLP; and CockroachDB has supported emitting traces using OTLP since v22.1. Operators and developers who want to inspect traces are thus invited to use the OTLP protocol instead. The corresponding cluster setting istrace.opentelemetry.collector. For a successful deployment, an intermediate OTLP collector/forwarder should be configured. For an example of how to orchestrate the OpenTelemetry collector and Jaeger together using Docker Compose, or how to configure theotel-collector, see the more-detailed entry inv23.2-alpha.3 backward-incompatible changes.#111342",
            "The newcluster settingsql.txn.read_committed_syntax.enabled, controls whether transactions run underREAD COMMITTEDorSERIALIZABLEisolation. It defaults tofalse. When set totrue, the following statements will configure transactions to run underREAD COMMITTEDisolation:BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTEDSET TRANSACTION ISOLATION LEVEL READ COMMITTEDSET default_transaction_isolation = 'read committed'SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL READ COMMITTED#110624",
            "BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "SET TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "SET default_transaction_isolation = 'read committed'",
            "SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL READ COMMITTED",
            "Thesql.txn.read_committed_syntax.enabledcluster settingwas renamed tosql.txn.read_committed_isolation.enabled.#113833",
            "Users who have theCREATEROLErole optioncan now grant and revoke role membership in any non-admin role. This change also removes thesql.auth.createrole_allows_grant_role_membership.enabledcluster setting, which was added in v23.1. In v23.2, the cluster setting is effectively always true.#104376",
            "Thecluster settingsql.metrics.statement_details.gateway_node.enablednow defaults to false to reduce the number of rows generated in SQL Statistics pages.#107788",
            "Thecluster settingkv.rangefeed.enabledno longer controls access toRANGEFEED SQLcommands. Instead, usefeature.changefeed.enabled.#110676",
            "Thecluster settingsrelated tophysical cluster replicationhave been renamed for consistency. For example,bulkio.stream_ingestion.minimum_flush_intervalis now namedphysical_replication.consumer.minimum_flush_interval.#111197",
            "CockroachDB now periodically dumps the state of its internal memory accounting system into theheap_profiler/directory when a heap profile is taken. To disable this behavior, set thediagnostics.memory_monitoring_dumps.enabledcluster settingtofalse.#114998",
            "Introduced thecluster settingkv.gc.sticky_hint.enabledin v23.1.13. This setting helps expeditegarbage collectionafter range deletions. For example, when a SQL table or index is dropped.kv.gc.sticky_hint.enabledis enabled by default and deprecated in v23.2.#113040",
            "CockroachDB now enables the pacing mechanism in rangefeed closed timestamp notifications, by setting the defaultkv.rangefeed.closed_timestamp_smear_intervalcluster setting to 1ms. This makes rangefeed closed timestamp delivery more uniform and less spikey, which reduces its impact on the Go scheduler and, ultimately, foreground SQL latencies.#103006",
            "Theprotect_data_from_gc_on_pauseoption has been deprecated. This option is no longer needed since changefeed jobs always protect data.#103539",
            "Thecockroach connectfunctionality has been deprecated.#114241"
        ]
    }
]